{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamish-haggerty/AI-hacking/blob/master/new_idea.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0\n",
        "# !pip install fastai==2.6.3 --no-deps\n",
        "!pip install self_supervised\n",
        "\n",
        "!pip install pytest\n",
        "!pip install ipytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8jFsEXz_61O",
        "outputId": "2898c4fa-fda4-404d-fc78-c653f415b003",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:58:53.640553Z",
          "iopub.execute_input": "2022-10-14T06:58:53.640973Z",
          "iopub.status.idle": "2022-10-14T06:59:52.496698Z",
          "shell.execute_reply.started": "2022-10-14T06:58:53.640943Z",
          "shell.execute_reply": "2022-10-14T06:59:52.494991Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting self_supervised\n",
            "  Downloading self_supervised-1.0.4-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 538 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from self_supervised) (21.3)\n",
            "Requirement already satisfied: fastai>=2.2.7 in /usr/local/lib/python3.7/dist-packages (from self_supervised) (2.7.9)\n",
            "Collecting timm>=0.4.5\n",
            "  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting kornia>=0.5.0\n",
            "  Downloading kornia-0.6.8-py2.py3-none-any.whl (551 kB)\n",
            "\u001b[K     |████████████████████████████████| 551 kB 87.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from self_supervised) (21.1.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (3.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (6.0)\n",
            "Requirement already satisfied: torch<1.14,>=1.7 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (1.12.1+cu113)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (1.3.5)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (1.5.27)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (0.0.7)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (0.13.1+cu113)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (1.0.3)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (1.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (1.7.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (8.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.0.8)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.6.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.4.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.0.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (4.64.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.4.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4->fastai>=2.2.7->self_supervised) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->self_supervised) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4->fastai>=2.2.7->self_supervised) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.2.7->self_supervised) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.2.7->self_supervised) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.2.7->self_supervised) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.2.7->self_supervised) (2022.9.24)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai>=2.2.7->self_supervised) (0.7.8)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai>=2.2.7->self_supervised) (0.0.3)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 70.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai>=2.2.7->self_supervised) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm>=0.4.5->self_supervised) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm>=0.4.5->self_supervised) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4->fastai>=2.2.7->self_supervised) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.2.7->self_supervised) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.2.7->self_supervised) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.2.7->self_supervised) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai>=2.2.7->self_supervised) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai>=2.2.7->self_supervised) (2022.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai>=2.2.7->self_supervised) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai>=2.2.7->self_supervised) (3.1.0)\n",
            "Installing collected packages: huggingface-hub, timm, kornia, self-supervised\n",
            "Successfully installed huggingface-hub-0.10.1 kornia-0.6.8 self-supervised-1.0.4 timm-0.6.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (22.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.15.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.4.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (8.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest) (57.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest) (0.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipytest\n",
            "  Downloading ipytest-0.12.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ipytest) (21.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipytest) (7.9.0)\n",
            "Collecting pytest>=5.4\n",
            "  Downloading pytest-7.1.3-py3-none-any.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (22.1.0)\n",
            "Collecting iniconfig\n",
            "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (1.11.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (2.0.1)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (5.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (3.9.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (57.4.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 88.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->ipytest) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipytest) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipytest) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ipytest) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipytest) (0.7.0)\n",
            "Installing collected packages: pluggy, jedi, iniconfig, pytest, ipytest\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed iniconfig-1.1.1 ipytest-0.12.0 jedi-0.18.1 pluggy-1.0.0 pytest-7.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BOv4kkJDag8r",
        "outputId": "2ce3b423-77b7-4604-b7d8-24ab0b7136f2",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:52.508711Z",
          "iopub.execute_input": "2022-10-14T06:59:52.520730Z",
          "iopub.status.idle": "2022-10-14T06:59:52.536979Z",
          "shell.execute_reply.started": "2022-10-14T06:59:52.509088Z",
          "shell.execute_reply": "2022-10-14T06:59:52.535865Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fastai\n",
        "import self_supervised\n",
        "import torch\n",
        "if torch.cuda.is_available():device='cuda'\n",
        "else:device='cpu'\n",
        "#assert(fastai.__version__ == '2.6.3') #Check that version is 2.6.3"
      ],
      "metadata": {
        "id": "Pk01WY_Dag8s",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:52.542798Z",
          "iopub.execute_input": "2022-10-14T06:59:52.549078Z",
          "iopub.status.idle": "2022-10-14T06:59:54.598151Z",
          "shell.execute_reply.started": "2022-10-14T06:59:52.549042Z",
          "shell.execute_reply": "2022-10-14T06:59:54.597112Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "from self_supervised.augmentations import *\n",
        "from self_supervised.layers import *\n",
        "from torchvision import transforms\n",
        "import inspect\n",
        "import warnings\n",
        "import random\n",
        "import math\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import ipytest\n",
        "ipytest.autoconfig()\n",
        "import pytest"
      ],
      "metadata": {
        "id": "AOjr_YCLag8t",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:54.600866Z",
          "iopub.execute_input": "2022-10-14T06:59:54.601996Z",
          "iopub.status.idle": "2022-10-14T06:59:57.011402Z",
          "shell.execute_reply.started": "2022-10-14T06:59:54.601948Z",
          "shell.execute_reply": "2022-10-14T06:59:57.010146Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Like most other SSL algorithms BT's model consists of an encoder and projector (MLP) layer.\n",
        "#Definition is straightforward:\n",
        "#https://colab.research.google.com/github/KeremTurgutlu/self_supervised/blob/master/nbs/14%20-%20barlow_twins.ipynb#scrollTo=1M6QcUChcvpz\n",
        "class BarlowTwinsModel(Module):\n",
        "    \"\"\"An encoder followed by a projector\n",
        "    \"\"\"\n",
        "    def __init__(self,encoder,projector):self.encoder,self.projector = encoder,projector\n",
        "        \n",
        "    def forward(self,x): return self.projector(self.encoder(x))"
      ],
      "metadata": {
        "id": "XTSdKC6bag8t",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:57.016179Z",
          "iopub.execute_input": "2022-10-14T06:59:57.019468Z",
          "iopub.status.idle": "2022-10-14T06:59:57.031223Z",
          "shell.execute_reply.started": "2022-10-14T06:59:57.019424Z",
          "shell.execute_reply": "2022-10-14T06:59:57.029999Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#HOWEVER instead of directly using the above, by passing both an encoder and a projector, create_barlow_twins_model\n",
        "#function can be used by minimally passing a predefined encoder and the expected input channels.\n",
        "\n",
        "#In the paper it's mentioned that MLP layer consists of 3 layers... following function will create a 3 layer\n",
        "#MLP projector with batchnorm and ReLU by default. Alternatively, you can change bn and nlayers. \n",
        "\n",
        "#Questions: Why torch.no_grad() when doing this?\n",
        "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
        "    \"Create Barlow Twins model\"\n",
        "    n_in  = in_channels(encoder)\n",
        "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
        "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
        "    apply_init(projector)\n",
        "    return BarlowTwinsModel(encoder, projector)\n",
        "\n",
        "#Similar to above. Simple API to make the BT model:"
      ],
      "metadata": {
        "id": "ZL3EE07Pag8u",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:57.036318Z",
          "iopub.execute_input": "2022-10-14T06:59:57.039176Z",
          "iopub.status.idle": "2022-10-14T06:59:57.070362Z",
          "shell.execute_reply.started": "2022-10-14T06:59:57.039065Z",
          "shell.execute_reply": "2022-10-14T06:59:57.069354Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BarlowTwins Callback\n",
        "#The following parameters can be passed:\n",
        "# - aug_pipelines\n",
        "# Imb lambda is the weight for redundancy reduction term in the loss function\n",
        "\n",
        "@delegates(get_multi_aug_pipelines)\n",
        "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(n=2,size=size,**kwargs)"
      ],
      "metadata": {
        "id": "DFjGL-COag8v",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:57.075268Z",
          "iopub.execute_input": "2022-10-14T06:59:57.077715Z",
          "iopub.status.idle": "2022-10-14T06:59:57.085697Z",
          "shell.execute_reply.started": "2022-10-14T06:59:57.077678Z",
          "shell.execute_reply": "2022-10-14T06:59:57.084670Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uniform random number between a and b\n",
        "def Unif(a,b):\n",
        "    return (b-a)*torch.rand(1).item()+a"
      ],
      "metadata": {
        "id": "xx4KsywAag8v",
        "execution": {
          "iopub.status.busy": "2022-10-11T12:39:03.961155Z",
          "iopub.execute_input": "2022-10-11T12:39:03.961709Z",
          "iopub.status.idle": "2022-10-11T12:39:03.968681Z",
          "shell.execute_reply.started": "2022-10-11T12:39:03.961668Z",
          "shell.execute_reply": "2022-10-11T12:39:03.967474Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_sinusoid(x,std=0.1,seed=0):\n",
        "    \n",
        "    seed_everything(seed=seed)    \n",
        "    t=(std) * torch.randn(1,500).to(device)\n",
        "    s=(std) * torch.randn(1,500).to(device)\n",
        "    \n",
        "    u=torch.randn(1,500).to(device)\n",
        "    v=torch.randn(1,500).to(device)\n",
        "\n",
        "    a=(0.2) * torch.randn(1,500).to(device)\n",
        "    b=(0.2) * torch.randn(1,500).to(device)\n",
        "    # N = torch.abs(a) + torch.abs(b)\n",
        "    # a = a/N\n",
        "    # b = b/N\n",
        "\n",
        "    return a*torch.sin(t*x[:,]*math.pi+u) + b*torch.cos(s*x[:,]*math.pi+v)\n",
        "\n",
        "\n",
        "    \n",
        "    #return torch.sin(t*math.pi*x+u) + torch.cos(s*math.pi*x + v)"
      ],
      "metadata": {
        "id": "zU4GwLruU5AD",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:57.090396Z",
          "iopub.execute_input": "2022-10-14T06:59:57.092958Z",
          "iopub.status.idle": "2022-10-14T06:59:57.104415Z",
          "shell.execute_reply.started": "2022-10-14T06:59:57.092921Z",
          "shell.execute_reply": "2022-10-14T06:59:57.103431Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#New stuff\n",
        "class Cdiff_Rand:\n",
        "    \n",
        "    def __init__(self,seed,bs,std=0.1,K=2):\n",
        "        self.seed=seed\n",
        "        self.std=std\n",
        "        self.K=2\n",
        "        self.bs=bs\n",
        "\n",
        "    def __call__(self,z1norm,z2norm):\n",
        "        \n",
        "        cdiff_rand=0\n",
        "        for i in range(self.K):\n",
        "\n",
        "            z1norm_2,z2norm_2 = random_sinusoid(z1norm,std=self.std,seed=self.seed+i), random_sinusoid(z2norm,std=self.std,seed=2*self.seed+i)\n",
        "            cdiff_rand = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,bs=bs)\n",
        "\n",
        "        cdiff_rand=(1/self.K)*cdiff_rand\n",
        "    \n",
        "        return cdiff_rand\n",
        "  "
      ],
      "metadata": {
        "id": "Xej8_KxJ71Sl",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:57.109007Z",
          "iopub.execute_input": "2022-10-14T06:59:57.111579Z",
          "iopub.status.idle": "2022-10-14T06:59:57.122207Z",
          "shell.execute_reply.started": "2022-10-14T06:59:57.111543Z",
          "shell.execute_reply": "2022-10-14T06:59:57.121109Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#New stuff\n",
        "def C_z1z2(z1norm,z1norm_2,z2norm,z2norm_2,bs):\n",
        "    \n",
        "    Ctem1 =  (z1norm.T @ z2norm_2) / bs\n",
        "    Ctem2 = (z1norm_2.T @ z2norm) / bs\n",
        "    cdiff_2 = (0.5*Ctem1.pow(2) + 0.5*Ctem2.pow(2))\n",
        "\n",
        "    return cdiff_2\n",
        "\n",
        "class Max_Corr(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(ps,ps)\n",
        "        self.fc2 = nn.Linear(ps,ps)\n",
        "\n",
        "        self.fc3 = nn.Linear(ps,ps)\n",
        "        self.fc4 = nn.Linear(ps,ps)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self,x,y):\n",
        "\n",
        "        x=self.sigmoid(self.fc1(x)) #when (sigmoid,relu) GREAT results, with (sigmoid,sigmoid) TERRIBLE. Currently testing (relu,relu)\n",
        "        x=self.fc2(x)\n",
        "       \n",
        "        y=self.relu(self.fc3(y)) #originally had relu and got really good results. If we can't reproduce those results, possible reasons:\n",
        "                                    #results were due to chance; or having relu on one branch (and sigmoid on the other) helps via breaking\n",
        "                                      #the symmetry! Other idea: set fc1=fc3, fc2=fc4. \n",
        "        y=self.fc4(y)\n",
        "\n",
        "        return x,y\n",
        "\n",
        "class Cdiff_Sup:\n",
        "    \n",
        "    def __init__(self,I,inner_steps,bs):\n",
        "        \n",
        "        self.I=I\n",
        "        self.inner_steps=inner_steps\n",
        "        self.bs=bs\n",
        "        self.max_corr = Max_Corr()\n",
        "        if device == 'cuda':\n",
        "            self.max_corr.cuda()\n",
        "        \n",
        "    def inner_step(self,z1norm,z2norm):\n",
        "    \n",
        "        max_corr=self.max_corr\n",
        "        I=self.I\n",
        "        bs=self.bs\n",
        "        inner_steps=self.inner_steps\n",
        "\n",
        "        z1norm=z1norm.detach()\n",
        "        z2norm=z2norm.detach()\n",
        "\n",
        "        # z1norm=z1norm[:,0]\n",
        "        # z2norm=z2norm[:,0]\n",
        "\n",
        "        max_corr = Max_Corr()\n",
        "        max_corr.cuda()\n",
        "    \n",
        "        # for p in max_corr.parameters():\n",
        "        #     p.requires_grad=True]\n",
        "\n",
        "        optimizer = torch.optim.Adam(list(max_corr.parameters()),lr=0.001)\n",
        "        for i in range(inner_steps):\n",
        "            z1norm_2,z2norm_2=max_corr(z1norm,z2norm)\n",
        "            #z1norm_2 = (z1norm_2 - z1norm_2.mean(0)) / z1norm_2.std(0, unbiased=False)\n",
        "        \n",
        "            assert (z1norm_2.shape,z2norm_2.shape) == (z1norm.shape,z2norm.shape)\n",
        "\n",
        "            # Ctem1 =  (z1norm.T @ z2norm_2) / bs\n",
        "            # Ctem2 = (z1norm_2.T @ z2norm) / bs\n",
        "            # cdiff_2 = (0.5*Ctem1.pow(2) + 0.5*Ctem2.pow(2))\n",
        "\n",
        "            cdiff_2 = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,bs=bs)\n",
        "            #cdiff_2=Ctem.pow(2)\n",
        "\n",
        "            inner_loss=-1*(cdiff_2*(1-I)).mean()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            inner_loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        for p in max_corr.parameters():\n",
        "            p.requires_grad=False\n",
        "            \n",
        "        return max_corr\n",
        "    \n",
        "    def __call__(self,z1norm,z2norm):\n",
        "        \n",
        "            max_corr =  self.inner_step(z1norm,z2norm)\n",
        "            z1norm_2,z2norm_2 = max_corr(z1norm,z2norm)\n",
        "      \n",
        "            cdiff_sup = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,bs=bs)\n",
        "    \n",
        "            return cdiff_sup\n"
      ],
      "metadata": {
        "id": "XsNBXcIjyjD2",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:57.129667Z",
          "iopub.execute_input": "2022-10-14T06:59:57.132492Z",
          "iopub.status.idle": "2022-10-14T06:59:57.156823Z",
          "shell.execute_reply.started": "2022-10-14T06:59:57.132455Z",
          "shell.execute_reply": "2022-10-14T06:59:57.155768Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Like most other SSL algorithms BT's model consists of an encoder and projector (MLP) layer.\n",
        "#Definition is straightforward:\n",
        "#https://colab.research.google.com/github/KeremTurgutlu/self_supervised/blob/master/nbs/14%20-%20barlow_twins.ipynb#scrollTo=1M6QcUChcvpz\n",
        "class BarlowTwinsModel(Module):\n",
        "    \"\"\"An encoder followed by a projector\n",
        "    \"\"\"\n",
        "    def __init__(self,encoder,projector,projector2):self.encoder,self.projector,self.projector2 = encoder,projector,projector2\n",
        "        \n",
        "    def forward(self,x): \n",
        "        # print('BarlowTwinsModel...')\n",
        "        # print(x.shape)\n",
        "        # print('shape of x')\n",
        "        # input()\n",
        "\n",
        "        # print(self.encoder(x).shape)\n",
        "        # print('shape of encoder(x)')\n",
        "        # input()\n",
        "        # print(self.projector(self.encoder(x)).shape)\n",
        "        \n",
        "        # input('shape of z')\n",
        "        tem = self.encoder(x)\n",
        "        \n",
        "        return self.projector(tem),self.projector2(tem)\n",
        "    \n",
        "    \n",
        "#HOWEVER instead of directly using the above, by passing both an encoder and a projector, create_barlow_twins_model\n",
        "#function can be used by minimally passing a predefined encoder and the expected input channels.\n",
        "\n",
        "#In the paper it's mentioned that MLP layer consists of 3 layers... following function will create a 3 layer\n",
        "#MLP projector with batchnorm and ReLU by default. Alternatively, you can change bn and nlayers. \n",
        "\n",
        "#Questions: Why torch.no_grad() when doing this?\n",
        "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
        "    \"Create Barlow Twins model\"\n",
        "    n_in  = in_channels(encoder)\n",
        "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
        "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
        "    apply_init(projector)\n",
        "    \n",
        "    projector2 = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
        "    apply_init(projector2)\n",
        "    \n",
        "    return BarlowTwinsModel(encoder, projector,projector2)\n",
        "\n",
        "#Similar to above. Simple API to make the BT model:"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:57.182110Z",
          "iopub.execute_input": "2022-10-14T06:59:57.184742Z",
          "iopub.status.idle": "2022-10-14T06:59:57.197928Z",
          "shell.execute_reply.started": "2022-10-14T06:59:57.184706Z",
          "shell.execute_reply": "2022-10-14T06:59:57.196883Z"
        },
        "trusted": true,
        "id": "zeEsdKZffCb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class BarlowTwins(Callback):\n",
        "    order,run_valid = 9,True\n",
        "    def __init__(self, aug_pipelines, lmb=5e-3, print_augs=False):\n",
        "        assert_aug_pipelines(aug_pipelines)\n",
        "        self.aug1, self.aug2 = aug_pipelines\n",
        "        if print_augs: print(self.aug1), print(self.aug2)\n",
        "        store_attr('lmb')\n",
        "        self.index=-1\n",
        "\n",
        "        self.inner_steps=4\n",
        "        \n",
        "    def before_fit(self): \n",
        "        self.learn.loss_func = self.lf\n",
        "        nf = self.learn.model.projector[-1].out_features\n",
        "        self.I = torch.eye(nf).to(self.dls.device)\n",
        "\n",
        "    def update_seed(self):\n",
        "        \n",
        "        indexmod=2\n",
        "        if self.index%indexmod == 0: #every `indexmod` index update the seed (best we have found so far)\n",
        "            self.seed = np.random.randint(0,10000)\n",
        "\n",
        "    def before_epoch(self):\n",
        "        self.index=-1\n",
        "\n",
        "        if self.epoch%10==0:\n",
        "            self.inner_steps += 1\n",
        "            \n",
        "    def before_batch(self):\n",
        "    \n",
        "        xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
        "        self.learn.xb = (torch.cat([xi, xj]),)\n",
        "\n",
        "        self.index=self.index+1\n",
        "        self.update_seed()\n",
        "\n",
        "\n",
        "\n",
        "    #Uncomment to run standard BT\n",
        "    def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n",
        "        #bs,nf = pred.size(0)//2,pred.size(1)\n",
        "        bs,nf = pred[0].size(0)//2,pred[0].size(1)\n",
        "        seed=self.seed\n",
        "\n",
        "        pred1=pred[0]\n",
        "        pred2=pred[0]\n",
        "\n",
        "        z1, z2 = pred1[:bs],pred1[bs:] #so z1 is bs*projection_size, likewise for z2\n",
        "\n",
        "        #Used to encode, primarily invariance\n",
        "        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
        "        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
        "\n",
        "\n",
        "        #Used to encode, primarily redundancy-reduction\n",
        "        z1_two,z2_two = pred2[:bs],pred2[bs:]\n",
        "        z1norm_two = (z1_two - z1_two.mean(0)) / z1_two.std(0, unbiased=False)\n",
        "        z2norm_two = (z2_two - z2_two.mean(0)) / z2_two.std(0, unbiased=False)\n",
        "\n",
        "        #The invariance term\n",
        "        Invar = (z1norm-z2norm).pow(2) #add to loss\n",
        "\n",
        "\n",
        "        #The redundancy reduction term\n",
        "        CdiffRand = Cdiff_Rand(seed=self.seed,bs=bs,std=0.2,K=2)\n",
        "        cdiff = CdiffRand(z1norm_two,z2norm_two)\n",
        "\n",
        "        #New\n",
        "        CdiffSup = Cdiff_Sup(I=self.I,inner_steps=5,bs=bs)\n",
        "        cdiff_2 = CdiffSup(z1norm_two,z2norm_two)\n",
        "\n",
        "        cdiff = 0.5*cdiff + 0.5*cdiff_2\n",
        "\n",
        "        redun_reduc = self.lmb*cdiff #add to loss\n",
        "\n",
        "        # #The `make the reps different` term\n",
        "        # C1 = (z1norm.T @ z1norm_two) / bs\n",
        "        # C2 = (z2norm.T @ z2norm_two) / bs\n",
        "        \n",
        "        # cdiff1 = 0.5*C1.pow(2)\n",
        "        # cdiff2 = 0.5*C2.pow(2)\n",
        "\n",
        "        # cdiff = self.lmb*(cdiff1+cdiff2) #add to loss\n",
        "\n",
        "        CdiffRand = Cdiff_Rand(seed=self.seed,bs=bs,std=0.2,K=2)\n",
        "        cdiff1  = CdiffRand(z1norm,z1norm_two)\n",
        "        CdiffSup = Cdiff_Sup(I=self.I,inner_steps=5,bs=bs)\n",
        "        cdiff11 = CdiffSup(z1norm,z1norm_two)\n",
        "        cdiff1 = 0.5*cdiff1 + 0.5*cdiff11\n",
        "\n",
        "        # CdiffRand = Cdiff_Rand(seed=self.seed,bs=bs,std=0.2,K=2)\n",
        "        # cdiff2  = CdiffRand(z2norm,z2norm_two)\n",
        "        # CdiffSup = Cdiff_Sup(I=self.I,inner_steps=5,bs=bs)\n",
        "        # cdiff22 = CdiffSup(z2norm,z2norm_two)\n",
        "        # cdiff2 = 0.5*cdiff2 + 0.5*cdiff22\n",
        "        #cdiff = self.lmb*(0.5*cdiff1 + 0.5*cdiff2)\n",
        "        cdiff = self.lmb*cdiff1\n",
        "\n",
        "        # #The `prevent collapse to zero` term. Unnecessary given independence?\n",
        "        # relu = nn.ReLU()\n",
        "        # eps=1e-7\n",
        "        # #C = (z1norm.T @ z1norm) / bs\n",
        "\n",
        "        # cdiffa=relu(1-(z1.var(0,unbiased=False)+eps).pow(0.5))\n",
        "        # cdiffb=relu(1-(z1_two.var(0,unbiased=False)+eps).pow(0.5))\n",
        "\n",
        "        #loss = (1/nf)*Invar.sum() + 0.5*(cdiffa + cdiffb).sum()+ (redun_reduc + cdiff).sum()\n",
        "        loss = (1/nf)*Invar.sum() + (redun_reduc + cdiff).sum()\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    # def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n",
        "        \n",
        "    #     bs,nf = pred.size(0)//2,pred.size(1)\n",
        "\n",
        "    #     #All standard, from BT\n",
        "    #     z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
        "    #     z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
        "    #     z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
        "        \n",
        "    #     C = (z1norm.T @ z2norm) / bs \n",
        "    #     cdiff = (C - self.I)**2\n",
        "\n",
        "\n",
        "    #     # #Let's change this block to rewritten (should do same thing)\n",
        "    #     # max_corr = inner_step(z1norm,z2norm,I=self.I,inner_steps=5)#,inner_steps=self.inner_steps)\n",
        "    #     # z1norm_2,z2norm_2 = max_corr(z1norm,z2norm)\n",
        "    #     # Ctem1 =  (z1norm.T @ z2norm_2) / bs\n",
        "    #     # Ctem2 = (z1norm_2.T @ z2norm) / bs\n",
        "    #     # #Ctem = (z1norm_2.T @ z2norm_2) / bs\n",
        "    #     # #cdiff_2 = Ctem.pow(2)\n",
        "    #     # cdiff_2 = (0.5*Ctem1.pow(2) + 0.5*Ctem2.pow(2)) #+ 0.1*Ctem.pow(2)\n",
        "\n",
        "\n",
        "    #     CdiffSup = Cdiff_Sup(I=self.I,inner_steps=5,bs=bs)\n",
        "    #     cdiff_2 = CdiffSup(z1norm,z2norm)\n",
        "\n",
        "    #     CdiffRand = Cdiff_Rand(seed=self.seed,bs=bs,std=0.2,K=2)\n",
        "    #     cdiff_2_2 = CdiffRand(z1norm,z2norm)\n",
        "\n",
        "    #     cdiff_2 = 0.5*cdiff_2_2 + 0.5*cdiff_2\n",
        "            \n",
        "    #     l2 = cdiff_2*(1-self.I)*self.lmb #Is either the standard term - or not.\n",
        "\n",
        "    #     loss = (cdiff*self.I + l2).sum()\n",
        "    #     torch.cuda.empty_cache()\n",
        "    #     return loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def show(self, n=1):\n",
        " \n",
        "        bs = self.learn.x.size(0)//2\n",
        "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]\n",
        "        #x1 = TensorImageBW(x1)\n",
        "        #x2 = TensorImageBW(x2)\n",
        "        idxs = np.random.choice(range(bs),n,False)\n",
        "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
        "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
        "        images = []\n",
        "        for i in range(n): images += [x1[i],x2[i]]\n",
        "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
      ],
      "metadata": {
        "id": "a2Exs2s3ag8z",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:57.202861Z",
          "iopub.execute_input": "2022-10-14T06:59:57.205619Z",
          "iopub.status.idle": "2022-10-14T06:59:57.240313Z",
          "shell.execute_reply.started": "2022-10-14T06:59:57.205582Z",
          "shell.execute_reply": "2022-10-14T06:59:57.239167Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Debugging cell - delete later (similar to cell below)\n",
        "ps=500\n",
        "hs=500\n",
        "#So I think I just just replace this line:\n",
        "#fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
        "#with this one:\n",
        "fastai_encoder = create_fastai_encoder(xresnet18(),pretrained=False,n_in=1)\n",
        "\n",
        "#fastai_encoder = create_body(xresnet18(n_out=512),n_in=1,pretrained=False)\n",
        "\n",
        "model = create_barlow_twins_model(fastai_encoder, hidden_size=hs,projection_size=ps)# projection_size=1024)\n",
        "\n",
        "#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n",
        "#values for these which is tantamount to doing nothing\n",
        "#So if we choose resize_scale=(1,1) then the images look the same.\n",
        "#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\n",
        "aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=True)\n",
        "\n",
        "#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwRMSProp(model.parameters(),lr=0.1, mom=0.9)ins(aug_pipelines, print_augs=True)])\n",
        "opt = torch.optim.RMSprop\n",
        "#partial(OptimWrapper, opt=opt)\n",
        "learn = Learner(dls,model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
        "#learn = Learner(dls, model,opt_func=opt_func, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
        "\n",
        "learn.fit(100) #300                            "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vbS1WtLiag80",
        "outputId": "b712835f-53cb-4473-bec0-3801f30921b1",
        "execution": {
          "iopub.status.busy": "2022-10-14T07:00:50.284139Z",
          "iopub.execute_input": "2022-10-14T07:00:50.284905Z",
          "iopub.status.idle": "2022-10-14T07:44:48.132313Z",
          "shell.execute_reply.started": "2022-10-14T07:00:50.284864Z",
          "shell.execute_reply": "2022-10-14T07:44:48.131283Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n",
            "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>405.067322</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>262.857819</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>197.098358</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>160.893448</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>145.362030</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>125.808556</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>106.886230</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>96.317924</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>87.775414</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>80.581673</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>79.478394</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>73.779785</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>73.015083</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>72.439865</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>68.923302</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>61.858841</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>58.961021</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>54.705330</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>53.724396</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>51.100479</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>46.772800</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>46.161247</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>50.376808</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>50.550400</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>46.883743</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>43.587551</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>41.742165</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>40.062653</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>41.853306</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>37.907528</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>36.089336</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>38.998539</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>40.462021</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>38.019501</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>34.726231</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>34.726894</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>34.464466</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>36.777939</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>32.830101</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>29.390123</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>28.436312</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>30.168859</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>31.654688</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>30.454935</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>28.181326</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>27.920736</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>26.483959</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>25.909006</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>24.436539</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>23.867680</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>26.389784</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>29.545002</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>28.555408</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>25.444862</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>23.998676</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>24.442564</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>25.938293</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>23.976074</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>22.413301</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>22.696314</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>23.647570</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>25.782698</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>24.869698</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>24.410776</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>23.630186</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>22.303833</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>21.030651</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>19.877472</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>19.694059</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>20.401293</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>22.567554</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>21.694542</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>21.195585</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>21.049494</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>20.896128</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>21.498167</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>19.704687</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>18.627365</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>18.804371</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>19.185038</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>21.253393</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>20.508797</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>19.808155</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>19.795797</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>22.420696</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>21.145279</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>19.162603</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>18.204021</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>18.770838</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>20.615185</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>19.758579</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>18.122087</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>18.075571</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>19.109091</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>19.730595</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>17.900293</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>17.308167</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>17.646933</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>18.457750</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>18.967197</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#new\n",
        "def seed_everything(seed=42):\n",
        "    \"\"\"\"\n",
        "    Seed everything.\n",
        "    \"\"\"   \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def tune_set(items0,seed=None,bs_tune=20):\n",
        "    \n",
        "    seed_everything(seed=seed)\n",
        "    \n",
        "    items0=items0.shuffle()\n",
        "    d = {'0':0,'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0,'8':0,'9':0}\n",
        "    ITEMS=[]\n",
        "    for i in items0:\n",
        "        s=str(i).split('/training/')[1][0]\n",
        "        if d[s] is 0 or d[s] is 1:\n",
        "            ITEMS.append(i)\n",
        "            d[s]+=1\n",
        "    #items0=ITEMS\n",
        "\n",
        "    for i in items0:\n",
        "        if i not in ITEMS:\n",
        "            ITEMS.append(i)\n",
        "            \n",
        "    split = IndexSplitter(list(range(bs_tune)))\n",
        "\n",
        "    tds_tune = Datasets(ITEMS, [PILImageBW.create, [parent_label, Categorize()]], splits=split(ITEMS)) #Or do we want this?\n",
        "    dls_tune = tds_tune.dataloaders(bs=bs_tune,num_workers=6, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n",
        "    \n",
        "    return dls_tune\n"
      ],
      "metadata": {
        "id": "Fdbbd-uV8Ltr",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:57.266185Z",
          "iopub.execute_input": "2022-10-14T06:59:57.268904Z",
          "iopub.status.idle": "2022-10-14T06:59:57.282921Z",
          "shell.execute_reply.started": "2022-10-14T06:59:57.268868Z",
          "shell.execute_reply": "2022-10-14T06:59:57.281869Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_items(items,seed):\n",
        "    \"\"\"Helper function to sort a list according to given random seed\n",
        "    \"\"\"\n",
        "    items.sort()\n",
        "    \n",
        "    if seed !=None:\n",
        "        seed_everything(seed=seed)\n",
        "        items=items.shuffle()\n",
        "    \n",
        "    return items\n",
        "\n",
        "class BT_Data:\n",
        "    \n",
        "    def __init__(self,items,seed=42,ts=16384,bs=512,tune_s=2000,bs_tune=20,bs_test=578):\n",
        "        \n",
        "        self.ts=ts\n",
        "        self.bs=bs\n",
        "        self.tune_s=tune_s\n",
        "        self.bs_tune=bs_tune\n",
        "        self.bs_test=bs_test\n",
        "        \n",
        "        self._seed=seed\n",
        "        self.seed=seed\n",
        "        items=shuffle_items(items,seed)\n",
        "        self.items=items\n",
        "\n",
        "    @property\n",
        "    def seed(self):\n",
        "        return self._seed\n",
        "    \n",
        "    @seed.setter #When we update the seed, we update the datasets (so items and dls objects) accordingly\n",
        "    def seed(self,val):\n",
        "        self._seed=val\n",
        "        self.items = shuffle_items(items,val)\n",
        "        self.build_items_i()\n",
        "        self.build_dls()\n",
        "        \n",
        "    def build_items_i(self):\n",
        "        self.items1 = self.items[0:ts] #train BT on these guys\n",
        "        self.items0 = self.items[self.ts:self.ts+self.tune_s] #for fine tuning - just choose 2000 guys to extract 20 for fine tuning \n",
        "        self.items2 = self.items[self.ts+self.tune_s:] #test on remainder\n",
        "        \n",
        "    def build_dls(self):\n",
        "        \n",
        "        split = RandomSplitter(valid_pct=0.0)\n",
        "        tds = Datasets(self.items1, [PILImageBW.create, [parent_label, Categorize()]], splits=split(self.items1))\n",
        "        self.dls = tds.dataloaders(bs=self.bs,num_workers=6, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n",
        "\n",
        "        #Evaluate linear classifier on this guy\n",
        "        split = RandomSplitter(valid_pct=0.0) #randomly split training set into training and validation\n",
        "        tds_test = Datasets(self.items2, [PILImageBW.create, [parent_label, Categorize()]], splits=split(self.items2)) #Or do we want this?\n",
        "        self.dls_test = tds_test.dataloaders(bs=self.bs_test,num_workers=6, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n",
        "\n",
        "\n",
        "def build_BT_Data(items,seed,tune_seed):\n",
        "    ts=16384\n",
        "    bs=512\n",
        "    tune_s=2000\n",
        "    bs_tune=20\n",
        "    bs_test=578\n",
        "    \n",
        "    k=dict(seed=seed,ts=ts,bs=bs,tune_s=tune_s,bs_tune=bs_tune,bs_test=bs_test)\n",
        "    bt_dataset = BT_Data(items=items,**k)\n",
        "\n",
        "    items = bt_dataset.items\n",
        "    items1 = bt_dataset.items1\n",
        "    items0 = bt_dataset.items0\n",
        "    items2 = bt_dataset.items2\n",
        "\n",
        "    dls = bt_dataset.dls\n",
        "    dls_test = bt_dataset.dls_test\n",
        "\n",
        "    dls_tune=tune_set(items0=items0,seed=seed,bs_tune=bs_tune)\n",
        "    \n",
        "    return dict(seed=seed,tune_seed=tune_seed,items=items,items1=items1,items0=items0,items2=items2,dls=dls,dls_test=dls_test,dls_tune=dls_tune)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "89bdbbno8TNf",
        "execution": {
          "iopub.status.busy": "2022-10-14T06:59:57.287546Z",
          "iopub.execute_input": "2022-10-14T06:59:57.289993Z",
          "iopub.status.idle": "2022-10-14T06:59:57.323284Z",
          "shell.execute_reply.started": "2022-10-14T06:59:57.289957Z",
          "shell.execute_reply": "2022-10-14T06:59:57.322282Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bt_data.seed"
      ],
      "metadata": {
        "id": "q4YR-kCR09dw",
        "outputId": "16981c0a-8738-4972-e772-cd6bfa5f3298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "420"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#new\n",
        "\n",
        "path = untar_data(URLs.MNIST)\n",
        "items = get_image_files(path/'training') #i.e. NOT testing!!!\n",
        "items.sort()\n",
        "\n",
        "seed=420\n",
        "tune_seed=100\n",
        "ts=16384\n",
        "bs=512\n",
        "tune_s=2000\n",
        "bs_tune=20\n",
        "bs_test=578\n",
        "\n",
        "bt_data = BT_Data(items=items,seed=seed,ts=ts,bs=bs,tune_s=tune_s,bs_tune=bs_tune,bs_test=bs_test)\n",
        "\n",
        "items1=bt_data.items1\n",
        "items0=bt_data.items0\n",
        "items2=bt_data.items2\n",
        "\n",
        "dls=bt_data.dls\n",
        "dls_test=bt_data.dls_test\n",
        "\n"
      ],
      "metadata": {
        "id": "7gKpW58J8oiU",
        "execution": {
          "iopub.status.busy": "2022-10-14T07:00:10.018450Z",
          "iopub.execute_input": "2022-10-14T07:00:10.018939Z",
          "iopub.status.idle": "2022-10-14T07:00:50.281671Z",
          "shell.execute_reply.started": "2022-10-14T07:00:10.018898Z",
          "shell.execute_reply": "2022-10-14T07:00:50.280455Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "#TODO: Rewrite so works for both (seed,tune_seed) = (42,10) and (420,100). At the moment \n",
        "\n",
        "labeller = using_attr(RegexLabeller(pat = r'(\\d+).png$'), 'name')\n",
        "convert_tensor = transforms.ToTensor()\n",
        "Expected_first_item = {42:{'items1':'19825','items0':'40684','items2':'43064'},420:{'items1':'44942','items0':'23821','items2':'908'}}\n",
        "Expected_first_dls = {42:{'dls':0.085169,'dls_test':0.099924},420:{'dls':0.183678,'dls_test':0.162825}}\n",
        "Expected_first_dls_tune = {(42,55):0.093707,(420,55):0.1513355}\n",
        "\n",
        "bt_data_42 = build_BT_Data(items=items,seed=42,tune_seed=10)\n",
        "bt_data_420 = build_BT_Data(items=items,seed=420,tune_seed=100)\n",
        "\n",
        "def verify_DatasetShape(dls_obj,batch_size,ds_settype='train'):\n",
        "    \"\"\"\"Helper function to verify shape of a dls object given the batch size; ds_settype is either `train` or \n",
        "        `valid`. The idea is we want the batch_size to divide the length of the dlsobj.\n",
        "    \"\"\"\n",
        "    \n",
        "    tem = len(getattr(dls_obj,ds_settype)) #length of dlsobj.train or dlsobj.valid depending on settpe\n",
        "    return tem*batch_size == len(getattr(dls_obj,ds_settype+'_ds'))\n",
        "\n",
        "def verify_first_item(items,expected):\n",
        "    \"\"\"Helper function to verify first element of items is as expected, given random seed of 42\n",
        "    \"\"\"\n",
        "        \n",
        "    return labeller(items[0]) == expected\n",
        "        \n",
        "def verify_first_dls(dls_obj,expected,ds_settype='train'):\n",
        "    \"\"\"Helper function to verify first element of the given dls object is as expected, given random seed of 42.\n",
        "        Note that ds_settype is either `train` or `valid\n",
        "    \"\"\"\n",
        "    \n",
        "    #All we are doing here is getting the first tensor in, for example e.g. dls_obj.train_ds and computing\n",
        "    #the mean of all the elements. If random seed is same, then it should give the same results\n",
        "    z=convert_tensor(next(iter(getattr(dls_obj,ds_settype+'_ds')))[0]).mean().item()\n",
        "    \n",
        "    #logging.debug(f'with {ds_settype} has: {z}')\n",
        "    assert z-expected < 0.0001\n",
        "\n",
        "    \n",
        "@pytest.mark.parametrize('bt_dataset',[bt_data_42,bt_data_420])\n",
        "class Test_shapes:\n",
        "    \n",
        "    def test_shape_dlsobjects(self,bt_dataset):\n",
        "        \"\"\"\"Test the shape of each dlsobj\n",
        "        \"\"\"\n",
        "    \n",
        "        assert verify_DatasetShape(bt_dataset['dls'],batch_size=bs,ds_settype='train')\n",
        "\n",
        "        assert verify_DatasetShape(bt_dataset['dls_tune'],batch_size=bs_tune,ds_settype='valid')\n",
        "\n",
        "        assert verify_DatasetShape(bt_dataset['dls_test'],batch_size=bs_test,ds_settype='train')\n",
        "    \n",
        "    def test_length_dlsobjects(self,bt_dataset):\n",
        "        \"\"\"\"Test the length of each dlsobj that we use\n",
        "        \"\"\"\n",
        "        assert len(bt_dataset['dls'].train_ds) == ts and len(bt_dataset['dls_tune'].valid_ds) == bs_tune and len(bt_dataset['dls_test'].train_ds)==41616\n",
        "    \n",
        "    \n",
        "@pytest.mark.parametrize('bt_dataset',[bt_data_42,bt_data_420])   \n",
        "class Test_first:\n",
        "    \n",
        "    def test_first_item(self,bt_dataset):\n",
        "        \"\"\"\"Verify that the first item of each items is as expected\n",
        "        \"\"\"\n",
        "\n",
        "        seed = bt_dataset['seed']\n",
        "\n",
        "        assert verify_first_item(bt_dataset['items1'],Expected_first_item[seed]['items1'])\n",
        "\n",
        "        assert verify_first_item(bt_dataset['items0'],Expected_first_item[seed]['items0'])\n",
        "\n",
        "        assert verify_first_item(bt_dataset['items2'],Expected_first_item[seed]['items2'])\n",
        "\n",
        "    def test_first_dlsobj(self,bt_dataset):\n",
        "        \"\"\"Verify that the first item of each dlsobj is as expected\n",
        "        \"\"\"\n",
        "        seed = bt_dataset['seed']\n",
        "        dls = bt_dataset['dls']\n",
        "        dls_test = bt_dataset['dls_test']\n",
        "        items0 = bt_dataset['items0']\n",
        "\n",
        "        verify_first_dls(dls,ds_settype='train',expected=Expected_first_dls[seed]['dls'])\n",
        "        verify_first_dls(dls_test,ds_settype='train',expected=Expected_first_dls[seed]['dls_test'])\n",
        "\n",
        "        tune_seed=55\n",
        "        dls_tune=tune_set(items0,seed=tune_seed,bs_tune=bs_tune)\n",
        "\n",
        "        verify_first_dls(dls_tune,ds_settype='valid',expected=Expected_first_dls_tune[(seed,tune_seed)])\n",
        "\n",
        "\n",
        "@pytest.mark.parametrize('bt_dataset',[bt_data_42,bt_data_420])\n",
        "def test1_tune_set(bt_dataset):\n",
        "    \"\"\"Check whether the function `tune_set` gives us the expected values\"\"\"\n",
        "    \n",
        "\n",
        "    seed=bt_dataset['seed']\n",
        "    tune_seed=bt_dataset['tune_seed']\n",
        "    items0 = bt_dataset['items0']\n",
        "    \n",
        "    if tune_seed==10 and seed==42:\n",
        "        expected = {10:0.12255,11:0.153564,12:0.12781,13:0.129523,14:0.13019}\n",
        "    \n",
        "    elif tune_seed==100 and seed==420:\n",
        "        expected={100:0.136104,101:0.120989,102:0.1381390,103:0.1380412,104:0.14285138}\n",
        "        \n",
        "    for i in range(5):\n",
        "        #seed_everything(seed=seed)\n",
        "        dls_tune=tune_set(items0,seed=tune_seed+i,bs_tune=20)\n",
        "        x_mean=0\n",
        "        for x,y in dls_tune.valid:\n",
        "            x_mean += x.mean()\n",
        "\n",
        "        assert abs(x_mean-expected[tune_seed+i])<0.0001\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z3pyrAB8rpN",
        "outputId": "cd025c63-661c-491b-c55c-5f2ef538225e",
        "execution": {
          "iopub.status.busy": "2022-10-14T07:58:53.425520Z",
          "iopub.execute_input": "2022-10-14T07:58:53.425893Z",
          "iopub.status.idle": "2022-10-14T07:59:19.459517Z",
          "shell.execute_reply.started": "2022-10-14T07:58:53.425863Z",
          "shell.execute_reply": "2022-10-14T07:59:19.458440Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                   [100%]\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A \"reasonable\" composite augmentation: initially copy pasted BT. We run this cell a few times to check it makes sense\n",
        "#Also define encoder and model\n",
        "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
        "model = create_barlow_twins_model(fastai_encoder, hidden_size=10,projection_size=10)# projection_size=1024)\n",
        "#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n",
        "#values for these which is tantamount to doing nothing\n",
        "#So if we choose resize_scale=(1,1) then the images look the same.\n",
        "#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\n",
        "aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=False)\n",
        "#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
        "learn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
        "\n",
        "#dls.valid.bs = len(dls.valid_ds) #Set the validation dataloader batch size to be the length of the validation dataset\n",
        "\n",
        "b = dls.one_batch()\n",
        "learn._split(b)\n",
        "learn('before_batch')\n",
        "axes = learn.barlow_twins.show(n=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "AKbw2pxMag82",
        "outputId": "ad338376-6361-44a8-afcd-4c1cbc00eb5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n\nPipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple linear classifier\n",
        "class LinearClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self,zdim):\n",
        "            \n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(zdim,10) #As 10 classes for mnist\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = cast(self.fc1(x),Tensor) #so we have to use cross entropy loss. cast is because using old version fastai \n",
        "        return x\n",
        "\n",
        "def turnoffgrad_model(fastai_encoder):\n",
        "    for p in fastai_encoder.parameters():\n",
        "        p.requires_grad=False\n",
        "        \n",
        "    return fastai_encoder\n",
        "\n",
        "#NB: Will give same random 20-tune set (for fixed random seed), only if the cell\n",
        "#\"#Get the dataloader and set batch size\" is the same. Perhaps later we can make this cell a function of that one. \n",
        "#Functions to train and evaluate head\n",
        "fastai_encoder.eval()\n",
        "encoder_nograd = turnoffgrad_model(fastai_encoder) \n",
        "def train_head(encoder_nograd,tune_seed=10,bs_tune=20): #The seed choses a different (20) samples for training the head. 2 of each class\n",
        "    \"\"\"Train head on a tune_set, chosen through given tune_seed for reproducibility if needed\n",
        "    \"\"\"\n",
        "                                    # of the tune_seed)\n",
        "    \n",
        "    dls_tune=tune_set(items0,seed=tune_seed,bs_tune=bs_tune) #different random tune set each time (but as a function of tune_seed)\n",
        " \n",
        "    N=len(dls_tune.valid)*bs_tune \n",
        "    assert N == len(dls_tune.valid_ds) #Check that the tune set (valid) is divided by the batch size\n",
        "    assert len(dls_tune.valid_ds) == bs_tune\n",
        "\n",
        "    zdim=1024 #see above\n",
        "    head = LinearClassifier(zdim=zdim)\n",
        "    head.to(device)\n",
        "    optimizer = torch.optim.Adam(head.parameters())\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for epoch in range(200):\n",
        "        #for x,y in dls_tune.valid: #Slows massively on colab but not on kaggle. Weird. \n",
        "        x,y=dls_tune.valid.one_batch() #Same every time since dataset only has length=batch size = 20.\n",
        "                                        #Will need to fix this for CIFAR10 etc\n",
        "\n",
        "        loss = criterion(head(encoder_nograd(x)),y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return head\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_head(head):\n",
        "    \"\"\"Evaluate the (typically trained) head on on the test set\n",
        "    \"\"\"\n",
        "    N=len(dls_test.train)*bs_test\n",
        "    assert N == len(dls_test.train_ds)\n",
        "\n",
        "    num_correct=0\n",
        "    for x,y in dls_test.train:\n",
        "\n",
        "        ypred = head(encoder_nograd(x))\n",
        "        correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n",
        "        num_correct += correct.sum()\n",
        "    \n",
        "    return num_correct/N\n",
        "\n",
        "def eval_encoder(encoder_nograd,tune_seed=10):\n",
        "    \"\"\"\"Evaluate the encoder, which means to train and evaluate the head - basically wrap functions train_head\n",
        "        and eval_head\n",
        "    \"\"\"\n",
        "    head=train_head(encoder_nograd,tune_seed=tune_seed)\n",
        "    pct_correct = eval_head(head)\n",
        "    return pct_correct\n",
        "    "
      ],
      "metadata": {
        "id": "IXTxgA9-Mhih",
        "execution": {
          "iopub.status.busy": "2022-10-14T07:44:58.704957Z",
          "iopub.execute_input": "2022-10-14T07:44:58.705315Z",
          "iopub.status.idle": "2022-10-14T07:44:58.732462Z",
          "shell.execute_reply.started": "2022-10-14T07:44:58.705282Z",
          "shell.execute_reply": "2022-10-14T07:44:58.731178Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "assert tune_seed==100\n",
        "assert seed == 420\n",
        "performance_dict={}\n",
        "for num in range(5):\n",
        "    \n",
        "    pct_correct = eval_encoder(encoder_nograd,tune_seed=tune_seed+num)\n",
        "    performance_dict[f'seed_{num}'] = pct_correct \n",
        "    print(num)\n",
        "\n",
        "print(torch.mean(tensor(list(performance_dict.values()))))\n",
        "performance_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKgPajGBMpSn",
        "outputId": "8f16cf11-8675-4663-c7ee-eae9c14b1783",
        "execution": {
          "iopub.status.busy": "2022-10-14T07:45:02.529364Z",
          "iopub.execute_input": "2022-10-14T07:45:02.529750Z",
          "iopub.status.idle": "2022-10-14T07:50:12.421137Z",
          "shell.execute_reply.started": "2022-10-14T07:45:02.529719Z",
          "shell.execute_reply": "2022-10-14T07:50:12.420132Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "tensor(0.8757)\n",
            "CPU times: user 46.7 s, sys: 3.19 s, total: 49.9 s\n",
            "Wall time: 1min 25s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'seed_0': TensorCategory(0.8689),\n",
              " 'seed_1': TensorCategory(0.8483),\n",
              " 'seed_2': TensorCategory(0.9061),\n",
              " 'seed_3': TensorCategory(0.8925),\n",
              " 'seed_4': TensorCategory(0.8629)}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is with 100 learn epochs \n",
        "\n",
        "#BT style, i.e. no random sinusoid\n",
        "new_420_100={'seed_0': TensorCategory(0.7952),\n",
        " 'seed_1': TensorCategory(0.7952),\n",
        " 'seed_2': TensorCategory(0.8647),\n",
        " 'seed_3': TensorCategory(0.8407),\n",
        " 'seed_4': TensorCategory(0.8118)}\n",
        "\n",
        "print(torch.mean(tensor(list(new_420_100.values()))))#tensor(0.8215)\n",
        "\n",
        "#See earlier commit, but I think reg_reg meant RBT to redun-reduc term only?\n",
        "#reg_reg_reg applies to other term. This is all just exploratory and experimental \n",
        "#at this point otherwise. \n",
        "\n",
        "#Optimize renduc - reduc like RBT\n",
        "new_420_100_reg_reg = {'seed_0': TensorCategory(0.8285),\n",
        " 'seed_1': TensorCategory(0.7945),\n",
        " 'seed_2': TensorCategory(0.8671),\n",
        " 'seed_3': TensorCategory(0.8478),\n",
        " 'seed_4': TensorCategory(0.8328)} #tensor(0.8341)\n",
        "print(torch.mean(tensor(list(new_420_100_reg_reg.values())))) #tensor(0.8341)\n",
        "\n",
        "new_42_10_reg_reg = {'seed_0': TensorCategory(0.8705),\n",
        " 'seed_1': TensorCategory(0.8063),\n",
        " 'seed_2': TensorCategory(0.9107),\n",
        " 'seed_3': TensorCategory(0.8843),\n",
        " 'seed_4': TensorCategory(0.8835)}\n",
        "\n",
        "print(torch.mean(tensor(list(new_42_10_reg_reg.values())))) #tensor(0.8711)\n",
        "\n",
        "\n",
        "#These two are best so far (averaged together). Cool. \n",
        "\n",
        "#Applying my method (rand + sup) to `all` terms where it applies. i.e. `redun-reduc`\n",
        "#and `make reps different` term. Note: only applied to one of the `make reps different`\n",
        "#term as that is good enough for our purposes. \n",
        "new_42_10_reg_reg_reg = {'seed_0': TensorCategory(0.8754),\n",
        " 'seed_1': TensorCategory(0.8068),\n",
        " 'seed_2': TensorCategory(0.9162),\n",
        " 'seed_3': TensorCategory(0.8890),\n",
        " 'seed_4': TensorCategory(0.8818)}\n",
        "\n",
        "print(torch.mean(tensor(list(new_42_10_reg_reg_reg.values())))) #tensor(0.8738)\n",
        "\n",
        "\n",
        "new_420_100_reg_reg_reg = {'seed_0': TensorCategory(0.8689),\n",
        " 'seed_1': TensorCategory(0.8483),\n",
        " 'seed_2': TensorCategory(0.9061),\n",
        " 'seed_3': TensorCategory(0.8925),\n",
        " 'seed_4': TensorCategory(0.8629)}\n",
        "\n",
        "print(torch.mean(tensor(list(new_420_100_reg_reg_reg.values())))) #tensor(0.8757)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G1gszrPuMuzW",
        "execution": {
          "iopub.status.busy": "2022-10-14T07:56:17.082171Z",
          "iopub.execute_input": "2022-10-14T07:56:17.082552Z",
          "iopub.status.idle": "2022-10-14T07:56:17.097927Z",
          "shell.execute_reply.started": "2022-10-14T07:56:17.082520Z",
          "shell.execute_reply": "2022-10-14T07:56:17.096554Z"
        },
        "trusted": true,
        "outputId": "e1ed0046-2966-4966-f975-cd6401c9c8d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d897f482df00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#BT style, i.e. no random sinusoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m new_420_100={'seed_0': TensorCategory(0.7952),\n\u001b[0m\u001b[1;32m      5\u001b[0m  \u001b[0;34m'seed_1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorCategory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7952\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m  \u001b[0;34m'seed_2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorCategory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8647\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TensorCategory' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#200 learn epochs\n",
        "BT_42_10_run1={'seed_0': TensorCategory(0.7667),\n",
        " 'seed_1': TensorCategory(0.6843),\n",
        " 'seed_2': TensorCategory(0.8468),\n",
        " 'seed_3': TensorCategory(0.7687),\n",
        " 'seed_4': TensorCategory(0.7288)}\n",
        "print(torch.mean(tensor(list(BT_42_10_run1.values()))))#tensor(0.7591)\n",
        "\n",
        "MBT_42_10_run1 = {'seed_0': TensorCategory(0.8238),\n",
        " 'seed_1': TensorCategory(0.7834),\n",
        " 'seed_2': TensorCategory(0.8999),\n",
        " 'seed_3': TensorCategory(0.8601),\n",
        " 'seed_4': TensorCategory(0.8221)}\n",
        "\n",
        "print(torch.mean(tensor(list(MBT_42_10_run1.values()))))#tensor(0.8379)\n",
        "\n",
        "\n",
        "BT_420_100_run1 = {'seed_0': TensorCategory(0.7532),\n",
        " 'seed_1': TensorCategory(0.7501),\n",
        " 'seed_2': TensorCategory(0.7808),\n",
        " 'seed_3': TensorCategory(0.7804),\n",
        " 'seed_4': TensorCategory(0.7461)}\n",
        "\n",
        "print(torch.mean(tensor(list(BT_420_100_run1.values()))))#tensor(0.7621)\n",
        "\n",
        "MBT_420_100_run1={'seed_0': TensorCategory(0.8016),\n",
        " 'seed_1': TensorCategory(0.7849),\n",
        " 'seed_2': TensorCategory(0.8416),\n",
        " 'seed_3': TensorCategory(0.8364),\n",
        " 'seed_4': TensorCategory(0.7986)}\n",
        "\n",
        "print(torch.mean(tensor(list(MBT_420_100_run1.values())))) #tensor(0.8126)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KMNc94mz5CJ",
        "outputId": "e53331d3-eb09-4310-aa01-daa1b9847886",
        "execution": {
          "iopub.status.busy": "2022-10-14T07:57:05.294559Z",
          "iopub.execute_input": "2022-10-14T07:57:05.294947Z",
          "iopub.status.idle": "2022-10-14T07:57:05.311069Z",
          "shell.execute_reply.started": "2022-10-14T07:57:05.294914Z",
          "shell.execute_reply": "2022-10-14T07:57:05.309825Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7591)\n",
            "tensor(0.8379)\n",
            "tensor(0.7621)\n",
            "tensor(0.8126)\n"
          ]
        }
      ]
    }
  ]
}