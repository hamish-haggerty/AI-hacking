{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e41dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initially copied from BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "514cae59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a893d809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamishhaggerty/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abb754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import inspect\n",
    "\n",
    "#These are imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df738458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Base_Stein.SVGD_classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40bd1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like most other SSL algorithms BT's model consists of an encoder and projector (MLP) layer.\n",
    "#Definition is straightforward:\n",
    "#https://colab.research.google.com/github/KeremTurgutlu/self_supervised/blob/master/nbs/14%20-%20barlow_twins.ipynb#scrollTo=1M6QcUChcvpz\n",
    "\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):self.encoder,self.projector = encoder,projector\n",
    "        \n",
    "    def forward(self,x): return self.projector(self.encoder(x))\n",
    "    \n",
    "    \n",
    "#Nothing much to this: Just a simple API for the BT model, with inputs encoder and projector. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f629c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOWEVER instead of directly using the above, by passing both an encoder and a projector, create_barlow_twins_model\n",
    "#function can be used by minimally passing a predefined encoder and the expected input channels.\n",
    "\n",
    "#In the paper it's mentioned that MLP layer consists of 3 layers... following function will create a 3 layer\n",
    "#MLP projector with batchnorm and ReLU by default. Alternatively, you can change bn and nlayers. \n",
    "\n",
    "\n",
    "#Questions: Why torch.no_grad() when doing this?\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "#Similar to above. Simple API to make the BT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f420c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can use self_supervised.layers module to create an encoder. \n",
    "\n",
    "encoder = create_encoder(\"tf_efficientnet_b0_ns\",n_in=3,pretrained=False,pool_type=PoolingType.CatAvgMax)\n",
    "model = create_barlow_twins_model(encoder,hidden_size=2048,projection_size=128,nlayers=2)\n",
    "out = model(torch.randn((2,3,224,224))); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a158cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function self_supervised.augmentations.get_multi_aug_pipelines(n, size, rotate=True, jitter=True, bw=True, blur=True, resize_scale=(0.2, 1.0), resize_ratio=(0.75, 1.3333333333333333), rotate_deg=30, jitter_s=0.6, blur_s=(4, 32), same_on_batch=False, flip_p=0.5, rotate_p=0.3, jitter_p=0.3, bw_p=0.3, blur_p=0.3, stats=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), cuda=False, xtra_tfms=[])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_multi_aug_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37acc15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BarlowTwins Callback\n",
    "#The following parameters can be passed:\n",
    "# - aug_pipelines\n",
    "# Imb lambda is the weight for redundancy reduction term in the loss function\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(n=2,size=size,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126b5cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(size, rotate=True, jitter=True, bw=True, blur=True, resize_scale=(0.2, 1.0), resize_ratio=(0.75, 1.3333333333333333), rotate_deg=30, jitter_s=0.6, blur_s=(4, 32), same_on_batch=False, flip_p=0.5, rotate_p=0.3, jitter_p=0.3, bw_p=0.3, blur_p=0.3, stats=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), cuda=False, xtra_tfms=[])\n"
     ]
    }
   ],
   "source": [
    "aug_pipelines = get_barlow_twins_aug_pipelines(size=28,rotate=False,jitter=False,bw=False,blur=False,stats=None,cuda=False)\n",
    "aug_pipelines\n",
    "\n",
    "print(inspect.signature(get_barlow_twins_aug_pipelines)) #If we comment out @delegates above, then only size is printed\n",
    "                                                         #here; i.e. just prints **kwargs instead of all the actual \n",
    "                                                         #keyword arguments!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "61abfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines, lmb=5e-3, print_augs=False):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        \n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "                    \n",
    "            \n",
    "    def before_batch(self):\n",
    "        xi,xj = self.aug1(self.x), self.aug2(self.x)\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "        \n",
    "    \n",
    "    #Check BT.pynb for original lf. Here we make our edits to try out SBT\n",
    "    def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n",
    "        bs,nf = pred.size(0)//2,pred.size(1)\n",
    "            \n",
    "        z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "        \n",
    "        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "        \n",
    "        OffDiagLoss=0\n",
    "        for i in range(nf):\n",
    "            for j in range(nf):\n",
    "                if j==i:\n",
    "                    continue\n",
    "\n",
    "                Particles = torch.stack((z1norm[:,i],z2norm[:,j])).T #set of initial particles for SVGD\n",
    "                svgd = trainable_SVGD(N=bs,zdim=2,eta=0.01) #N particles and 2 dimensional\n",
    "                \n",
    "                svgd.Particles = Particles.detach()\n",
    "                \n",
    "                #put inner loop here if doing more than one SVGD step...\n",
    "                g = svgd.get_gradient() # \"Like forward\"\n",
    "                svgd.AdamStep(gradient=g) #\"Like step\"\n",
    "                \n",
    "                #QUESTION: Does this do what I think it does...\n",
    "                OffDiagLoss += (Particles-svgd.Particles).pow(2).sum()\n",
    "\n",
    "        C = (z1norm.T @ z2norm) / bs \n",
    "        cdiff = (C - self.I)**2\n",
    "        #loss = (cdiff*self.I + cdiff*(1-self.I)*self.lmb).sum() \n",
    "        loss = (cdiff*self.I).sum() + self.lmb*OffDiagLoss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1):\n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:] \n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]] \n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "500d4e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n",
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.089093</td>\n",
       "      <td>0.085310</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.079891</td>\n",
       "      <td>0.075348</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.063264</td>\n",
       "      <td>0.071951</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.067533</td>\n",
       "      <td>0.177168</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.072721</td>\n",
       "      <td>0.107661</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.072457</td>\n",
       "      <td>0.080421</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.072219</td>\n",
       "      <td>0.094365</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0.111430</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.067954</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.064716</td>\n",
       "      <td>0.105506</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
    "learn.fit(10) #delete this cell later\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ae54f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64\n",
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)\n",
    "tds = Datasets(items, [PILImageBW.create, [parent_label, Categorize()]], splits=GrandparentSplitter()(items))\n",
    "dls = tds.dataloaders(bs=bs, after_item=[ToTensor(), IntToFloatTensor()], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a17ce95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function self_supervised.layers.create_encoder(arch: str, pretrained=True, n_in=3, pool_type='catavgmax')>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76cd6de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n",
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x864 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's build a reasonable composite augmentation: initially copy pasted from aug_pipe_exploration\n",
    "\n",
    "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
    "model = create_barlow_twins_model(fastai_encoder, hidden_size=1024, projection_size=1024)\n",
    "#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n",
    "#values for these which is tantamount to doing nothing\n",
    "\n",
    "#So if we choose resize_scale=(1,1) then the images look the same.\n",
    "#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\n",
    "aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=False)\n",
    "\n",
    "learn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
    "b = dls.one_batch()\n",
    "learn._split(b)\n",
    "learn('before_batch')\n",
    "axes = learn.barlow_twins.show(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8250ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.recorder.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893cfa3",
   "metadata": {},
   "source": [
    "So, in the above we train Barlow Twins on `MNIST_TINY`. \n",
    "\n",
    "Next step: Figure out what exactly we are training on. Then we want to \"fine tune\" on validation set and examine \n",
    "performance. \n",
    "\n",
    "Ok, for now let's just train as usual. We WILL improve this later. Iterate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50e24aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaba7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, train a classifier on the embedding!\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,zdim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(zdim,2) #As only 2 classes in TINY_MNIST\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = cast(self.fc1(x),Tensor) #so we have to use cross entropy loss. cast is because using old version fastai \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53c5de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=128\n",
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)\n",
    "tds = Datasets(items, [PILImageBW.create, [parent_label, Categorize()]], splits=GrandparentSplitter()(items))\n",
    "dls = tds.dataloaders(bs=bs,num_workers=0, after_item=[ToTensor(), IntToFloatTensor()], device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2b4b2428",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [164]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m fastai_encoder \u001b[38;5;241m=\u001b[39m create_encoder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxresnet18\u001b[39m\u001b[38;5;124m'\u001b[39m, n_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m create_barlow_twins_model(fastai_encoder, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, projection_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#Use aug pipeline from above\u001b[39;00m\n\u001b[1;32m      5\u001b[0m aug_pipelines \u001b[38;5;241m=\u001b[39m get_barlow_twins_aug_pipelines(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m, rotate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,flip_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,resize_scale\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.7\u001b[39m,\u001b[38;5;241m1\u001b[39m), jitter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, bw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,blur\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,blur_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,blur_s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/ipykernel/kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1074\u001b[0m     )\n\u001b[0;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/ipykernel/kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
    "model = create_barlow_twins_model(fastai_encoder, hidden_size=100, projection_size=10)\n",
    "#Use aug pipeline from above\n",
    "aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=False)\n",
    "learn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])#,ShortEpochCallback(0.001)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d374c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.valid.bs = len(list(iter(dls.valid_ds))) #Set the validation dataloader batch size to be the length of the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "97bc22ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.810843</td>\n",
       "      <td>1.508676</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.079975</td>\n",
       "      <td>0.270545</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.437366</td>\n",
       "      <td>0.373931</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.070069</td>\n",
       "      <td>0.245965</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.846498</td>\n",
       "      <td>0.270651</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.691370</td>\n",
       "      <td>0.350234</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.573768</td>\n",
       "      <td>0.155162</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.492096</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.425368</td>\n",
       "      <td>0.124471</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.372595</td>\n",
       "      <td>0.155469</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "learn.fit(10)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "eb3bb43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorCategory(0.1293, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.0836, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.1042, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.0839, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.0964, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.1063, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.1432, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.0773, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.0850, grad_fn=<AliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Train Classifier on encoder(tiny_mnist)\n",
    "\n",
    "zdim=1024 #see above\n",
    "head = LinearClassifier(zdim=zdim)\n",
    "optimizer = torch.optim.Adam(head.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "EPOCHS=100\n",
    "for epoch in range(EPOCHS):\n",
    "    #break \n",
    "    b = dls.train.one_batch() #Seems need dls[0] or dls.train for training ... dls[1] is validation see here https://docs.fast.ai/data.core.html#DataLoaders.__getitem__\n",
    "    x,y = b[0],b[1]\n",
    "\n",
    "    loss = criterion(head(fastai_encoder(x)),y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch>90:\n",
    "        print(loss)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "dde7d022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9756795167922974\n"
     ]
    }
   ],
   "source": [
    "#Test result of above cell on the validation set - assumes that batch size of valid-dataloader is = number of valid samples                                        \n",
    "b = dls.valid.one_batch()\n",
    "x,y = b[0],b[1]\n",
    "ypred = head(fastai_encoder(x))\n",
    "correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n",
    "print(correct.mean().item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "79237ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorCategory(0.0962, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.1417, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.0836, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.1354, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.0906, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.0815, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.1050, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.1309, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.1284, grad_fn=<AliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Just train a linear classifier (no encoder)\n",
    "#Basically cell above but remove encoder and some re-shaping\n",
    "\n",
    "zdim=28*28 #see above\n",
    "head = LinearClassifier(zdim=zdim)\n",
    "optimizer = torch.optim.Adam(head.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS=100\n",
    "for epoch in range(EPOCHS):\n",
    "    #break\n",
    "    b = dls.train.one_batch() #see here https://docs.fast.ai/data.core.html#DataLoaders.__getitem__\n",
    "    x,y = b[0],b[1]\n",
    "\n",
    "    x=x.view(bs,zdim)\n",
    "    x=cast(x, Tensor) #Have to do this when using old version of fastai for some reason...\n",
    "\n",
    "    out = head(x)\n",
    "    loss = criterion(out,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch>90:\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f7bd5db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9828326106071472\n"
     ]
    }
   ],
   "source": [
    "#Test result of above cell, (i.e. just a linear classifier), on the validation set - assumes that batch size of valid-dataloader is = number of valid samples                                        \n",
    "b = dls.valid.one_batch()\n",
    "x,y = b[0],b[1]\n",
    "x = x.view(-1,zdim)\n",
    "ypred = head(x)\n",
    "\n",
    "correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n",
    "print(correct.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402215e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
