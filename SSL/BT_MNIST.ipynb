{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e41dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building / continuing from BT.pynb: extend to MNIST and clean the file up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "514cae59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a893d809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamishhaggerty/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abb754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import inspect\n",
    "\n",
    "#These are imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40bd1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like most other SSL algorithms BT's model consists of an encoder and projector (MLP) layer.\n",
    "#Definition is straightforward:\n",
    "#https://colab.research.google.com/github/KeremTurgutlu/self_supervised/blob/master/nbs/14%20-%20barlow_twins.ipynb#scrollTo=1M6QcUChcvpz\n",
    "\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):self.encoder,self.projector = encoder,projector\n",
    "        \n",
    "    def forward(self,x): return self.projector(self.encoder(x))\n",
    "    \n",
    "    \n",
    "#Nothing much to this: Just a simple API for the BT model, with inputs encoder and projector. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f629c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOWEVER instead of directly using the above, by passing both an encoder and a projector, create_barlow_twins_model\n",
    "#function can be used by minimally passing a predefined encoder and the expected input channels.\n",
    "\n",
    "#In the paper it's mentioned that MLP layer consists of 3 layers... following function will create a 3 layer\n",
    "#MLP projector with batchnorm and ReLU by default. Alternatively, you can change bn and nlayers. \n",
    "\n",
    "\n",
    "#Questions: Why torch.no_grad() when doing this?\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "#Similar to above. Simple API to make the BT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37acc15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BarlowTwins Callback\n",
    "#The following parameters can be passed:\n",
    "# - aug_pipelines\n",
    "# Imb lambda is the weight for redundancy reduction term in the loss function\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(n=2,size=size,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61abfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines, lmb=5e-3, print_augs=False):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        \n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "                    \n",
    "            \n",
    "    def before_batch(self):\n",
    "        xi,xj = self.aug1(self.x), self.aug2(self.x)\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "        \n",
    "    \n",
    "    #loss function for BT. This is where the action is at: and potentially where I can make my edits...\n",
    "    def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n",
    "        bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "        z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "        \n",
    "        C = (z1norm.T @ z2norm) / bs \n",
    "        cdiff = (C - self.I)**2\n",
    "        loss = (cdiff*self.I + cdiff*(1-self.I)*self.lmb).sum() \n",
    "        return loss\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1):\n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:] \n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]] \n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ae54f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dataloader and set batch size\n",
    "bs=512\n",
    "path = untar_data(URLs.MNIST)\n",
    "items = get_image_files(path/'training') #i.e. NOT testing!!!\n",
    "split = RandomSplitter(valid_pct=0.95) #randomly split training set into training and validation\n",
    "#tds = Datasets(items,splits=split(items)) #Do we want this?\n",
    "tds = Datasets(items, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items)) #Or do we want this?\n",
    "dls = tds.dataloaders(bs=bs,num_workers=0, after_item=[ToTensor(), IntToFloatTensor()], device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76cd6de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n",
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#A \"reasonable\" composite augmentation: initially copy pasted BT. We run this cell a few times to check it makes sense\n",
    "#Also define encoder and model\n",
    "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
    "model = create_barlow_twins_model(fastai_encoder, hidden_size=100,projection_size=100)# projection_size=1024)\n",
    "#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n",
    "#values for these which is tantamount to doing nothing\n",
    "#So if we choose resize_scale=(1,1) then the images look the same.\n",
    "#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\n",
    "aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=False)\n",
    "learn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
    "dls.valid.bs = len(dls.valid_ds) #Set the validation dataloader batch size to be the length of the validation dataset\n",
    "\n",
    "b = dls.one_batch()\n",
    "learn._split(b)\n",
    "learn('before_batch')\n",
    "axes = learn.barlow_twins.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a207b4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eaba7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple linear classifier\n",
    "class LinearClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,zdim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(zdim,10) #As 10 classes for mnist\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = cast(self.fc1(x),Tensor) #so we have to use cross entropy loss. cast is because using old version fastai \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97bc22ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:222\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:164\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:213\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:164\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:208\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_train()\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:204\u001b[0m, in \u001b[0;36mLearner._do_epoch_validate\u001b[0;34m(self, ds_idx, dl)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: dl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls[ds_idx]\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m dl\n\u001b[0;32m--> 204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelValidException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:164\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:170\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mone_batch(\u001b[38;5;241m*\u001b[39mo)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/data/load.py:125\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_iter()\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idxs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_idxs() \u001b[38;5;66;03m# called in context of main process (not workers/subprocesses)\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m _loaders[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfake_l\u001b[38;5;241m.\u001b[39mnum_workers\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfake_l):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# pin_memory causes tuples to be converted to lists, so convert them back to tuples\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpin_memory \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(b) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m: b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(b)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: b \u001b[38;5;241m=\u001b[39m to_device(b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:39\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/data/load.py:136\u001b[0m, in \u001b[0;36mDataLoader.create_batches\u001b[0;34m(self, samps)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m    135\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m o:o \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_item, samps))\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunkify(res))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/basics.py:219\u001b[0m, in \u001b[0;36mchunked\u001b[0;34m(it, chunk_sz, drop_last, n_chunks)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(it, Iterator): it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(it)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_sz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(res)\u001b[38;5;241m==\u001b[39mchunk_sz \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m drop_last): \u001b[38;5;28;01myield\u001b[39;00m res\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res)\u001b[38;5;241m<\u001b[39mchunk_sz: \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/data/load.py:151\u001b[0m, in \u001b[0;36mDataLoader.do_item\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_item(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m SkipItemException: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/data/load.py:158\u001b[0m, in \u001b[0;36mDataLoader.create_item\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexed: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index an iterable dataset numerically - must use `None`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/data/core.py:338\u001b[0m, in \u001b[0;36mDatasets.__getitem__\u001b[0;34m(self, it)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, it):\n\u001b[0;32m--> 338\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([tl[it] \u001b[38;5;28;01mfor\u001b[39;00m tl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtls])\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res \u001b[38;5;28;01mif\u001b[39;00m is_indexer(it) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mres))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/data/core.py:338\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, it):\n\u001b[0;32m--> 338\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([\u001b[43mtl\u001b[49m\u001b[43m[\u001b[49m\u001b[43mit\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtls])\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res \u001b[38;5;28;01mif\u001b[39;00m is_indexer(it) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mres))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/data/core.py:304\u001b[0m, in \u001b[0;36mTfmdLists.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    302\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(idx)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_after_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m is_indexer(idx) \u001b[38;5;28;01melse\u001b[39;00m res\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_item)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/data/core.py:266\u001b[0m, in \u001b[0;36mTfmdLists._after_item\u001b[0;34m(self, o)\u001b[0m\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_after_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, o): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtfms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/transform.py:200\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, o)\u001b[0m\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, o): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompose_tfms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/transform.py:150\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tfms:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_enc: f \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdecode\n\u001b[0;32m--> 150\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/transform.py:73\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencodes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/transform.py:83\u001b[0m, in \u001b[0;36mTransform._call\u001b[0;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, x, split_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split_idx\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/transform.py:89\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     88\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, x, ret)\n\u001b[1;32m     90\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/dispatch.py:117\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 117\u001b[0m     ts \u001b[38;5;241m=\u001b[39m \u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    118\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;28mtuple\u001b[39m(ts)]\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f: \u001b[38;5;28;01mreturn\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/foundation.py:155\u001b[0m, in \u001b[0;36mL.map\u001b[0;34m(self, f, gen, *args, **kwargs)\u001b[0m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, \u001b[38;5;241m*\u001b[39margs, gen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[43mmap_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/basics.py:785\u001b[0m, in \u001b[0;36mmap_ex\u001b[0;34m(iterable, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_ex\u001b[39m(iterable, f, \u001b[38;5;241m*\u001b[39margs, gen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLike `map`, but use `bind`, and supports `str` and indexing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 785\u001b[0m     g \u001b[38;5;241m=\u001b[39m (\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m callable(f)\n\u001b[1;32m    786\u001b[0m          \u001b[38;5;28;01melse\u001b[39;00m f\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f,\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    787\u001b[0m          \u001b[38;5;28;01melse\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m)\n\u001b[1;32m    788\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(g, iterable)\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gen: \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/basics.py:767\u001b[0m, in \u001b[0;36mbind.__init__\u001b[0;34m(self, func, *pargs, **pkwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39mpargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpkwargs):\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpargs,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpkwargs \u001b[38;5;241m=\u001b[39m func,pargs,pkwargs\n\u001b[0;32m--> 767\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Arg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/basics.py:767\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39mpargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpkwargs):\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpargs,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpkwargs \u001b[38;5;241m=\u001b[39m func,pargs,pkwargs\n\u001b[0;32m--> 767\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((x\u001b[38;5;241m.\u001b[39mi \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m pargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _Arg)), default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit(1)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eb3bb43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorCategory(2.3619, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(2.1774, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(2.0685, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.9830, grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(head(fastai_encoder(x)),y)\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/_tensor.py:355\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/overrides.py:1394\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1388\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1389\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in PyTorch 1.11, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1390\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1394\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/torch_core.py:341\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): convert,types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m),(torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 341\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert: res \u001b[38;5;241m=\u001b[39m convert(res)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, TensorBase): res\u001b[38;5;241m.\u001b[39mset_meta(\u001b[38;5;28mself\u001b[39m, as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/_tensor.py:1142\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1142\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train Classifier on encoder(mnist)\n",
    "\n",
    "zdim=1024 #see above\n",
    "head = LinearClassifier(zdim=zdim)\n",
    "optimizer = torch.optim.Adam(head.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "EPOCHS=100\n",
    "for epoch in range(EPOCHS):\n",
    "    #break \n",
    "    b = dls.train.one_batch() #Seems need dls[0] or dls.train for training ... dls[1] is validation see here https://docs.fast.ai/data.core.html#DataLoaders.__getitem__\n",
    "    x,y = b[0],b[1]\n",
    "\n",
    "    loss = criterion(head(fastai_encoder(x)),y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    \n",
    "    if epoch>90:\n",
    "        print(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "11306c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9756795167922974\n"
     ]
    }
   ],
   "source": [
    "#Test result of above cell on the validation set - assumes that batch size of valid-dataloader is = number of valid samples                                        \n",
    "b = dls.valid.one_batch()\n",
    "x,y = b[0],b[1]\n",
    "ypred = head(fastai_encoder(x))\n",
    "correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n",
    "print(correct.mean().item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "79237ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorCategory(2.3457, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(2.2964, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(2.2385, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(2.1930, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(2.1532, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(2.1011, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(2.0655, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(2.0111, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.9650, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.9102, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.9128, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.8624, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.8390, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.8179, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.7613, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.6904, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.6816, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.6208, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.6097, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.5825, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.5681, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.4994, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.4819, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.4759, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.4609, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.4065, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.3914, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.3732, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.3682, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.3211, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.2880, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.2725, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.2691, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.2429, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.2040, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.2123, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.1966, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.1964, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.1838, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.1019, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.1220, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.1070, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.0570, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.0563, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.0498, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.0176, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.0565, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.9938, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.9871, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.9658, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(1.0199, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.9657, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.9495, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.9350, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.9471, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.9121, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.9091, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.8989, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.9070, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.8406, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.9296, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.8566, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.8773, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.8183, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.8246, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.8324, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.8396, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.8185, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.8144, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7910, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7665, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7816, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.8191, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7698, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7793, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7381, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7999, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7713, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7893, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7806, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7233, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7646, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7669, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7241, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6922, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7260, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6512, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7088, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7288, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6886, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7025, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6711, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6711, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6970, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6970, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6694, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6694, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6654, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6654, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6822, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6822, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6910, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6910, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6533, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6533, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7252, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.7252, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6481, grad_fn=<AliasBackward0>)\n",
      "TensorCategory(0.6481, grad_fn=<AliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Just train a linear classifier (no encoder)\n",
    "#Basically cell above but remove encoder and some re-shaping\n",
    "\n",
    "zdim=28*28 #see above\n",
    "head = LinearClassifier(zdim=zdim)\n",
    "optimizer = torch.optim.Adam(head.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS=100\n",
    "for epoch in range(EPOCHS):\n",
    "    #break\n",
    "    b = dls.train.one_batch() #see here https://docs.fast.ai/data.core.html#DataLoaders.__getitem__\n",
    "    x,y = b[0],b[1]\n",
    "\n",
    "    x=x.view(bs,zdim)\n",
    "    x=cast(x, Tensor) #Have to do this when using old version of fastai for some reason...\n",
    "\n",
    "    out = head(x)\n",
    "    loss = criterion(out,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    \n",
    "    if epoch>90:\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f7bd5db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8671875\n"
     ]
    }
   ],
   "source": [
    "#Test result of above cell, (i.e. just a linear classifier), on the validation set - assumes that batch size of valid-dataloader is = number of valid samples                                        \n",
    "b = dls.valid.one_batch()\n",
    "x,y = b[0],b[1]\n",
    "x = x.view(-1,zdim)\n",
    "ypred = head(x)\n",
    "\n",
    "correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n",
    "print(correct.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f82a31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
