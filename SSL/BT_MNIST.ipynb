{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0\n!pip install fastai==2.6.3 --no-deps\n!pip install self_supervised","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:52:53.541457Z","iopub.execute_input":"2022-08-28T05:52:53.546184Z","iopub.status.idle":"2022-08-28T05:53:14.426774Z","shell.execute_reply.started":"2022-08-28T05:52:53.546140Z","shell.execute_reply":"2022-08-28T05:53:14.425619Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch==1.11.0 in /opt/conda/lib/python3.7/site-packages (1.11.0)\nRequirement already satisfied: torchvision==0.12.0 in /opt/conda/lib/python3.7/site-packages (0.12.0)\nRequirement already satisfied: torchaudio==0.11.0 in /opt/conda/lib/python3.7/site-packages (0.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.11.0) (4.1.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0) (2.27.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0) (9.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0) (1.21.6)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0) (2.0.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0) (2022.6.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0) (1.26.9)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: fastai==2.6.3 in /opt/conda/lib/python3.7/site-packages (2.6.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: self_supervised in /opt/conda/lib/python3.7/site-packages (1.0.4)\nRequirement already satisfied: fastai>=2.2.7 in /opt/conda/lib/python3.7/site-packages (from self_supervised) (2.6.3)\nRequirement already satisfied: kornia>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from self_supervised) (0.5.8)\nRequirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from self_supervised) (22.1.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from self_supervised) (21.3)\nRequirement already satisfied: timm>=0.4.5 in /opt/conda/lib/python3.7/site-packages (from self_supervised) (0.6.7)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (2.3.7)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (2.27.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.7.3)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (0.12.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (3.5.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.3.5)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (6.0)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (0.0.6)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.0.2)\nRequirement already satisfied: pillow>6.0.0 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (9.1.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.0.2)\nRequirement already satisfied: torch<1.12,>=1.7.0 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.11.0)\nRequirement already satisfied: fastcore<1.5,>=1.3.27 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.4.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->self_supervised) (3.0.9)\nRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.5)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.0)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.21.6)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.0.6)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.7.8)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (4.64.0)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (59.8.0)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.0.6)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.1.3)\nRequirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (7.4.5)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (2022.6.15)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (1.26.9)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch<1.12,>=1.7.0->fastai>=2.2.7->self_supervised) (4.1.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (4.33.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (1.4.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fastai>=2.2.7->self_supervised) (2022.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai>=2.2.7->self_supervised) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai>=2.2.7->self_supervised) (1.1.0)\nRequirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai>=2.2.7->self_supervised) (4.12.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->fastai>=2.2.7->self_supervised) (1.16.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai>=2.2.7->self_supervised) (3.8.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import fastai\nimport self_supervised\nimport torch\nfastai.__version__ #Check that version is 2.6.3","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:53:19.094603Z","iopub.execute_input":"2022-08-28T05:53:19.095006Z","iopub.status.idle":"2022-08-28T05:53:20.948944Z","shell.execute_reply.started":"2022-08-28T05:53:19.094971Z","shell.execute_reply":"2022-08-28T05:53:20.948038Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'2.6.3'"},"metadata":{}}]},{"cell_type":"code","source":"#This is not needed unless running SBT\n#!pip uninstall --yes git+https://github.com/hamish-haggerty/SVGD_packages.git#egg='Base_Stein'\n!pip install git+https://github.com/hamish-haggerty/SVGD_packages.git#egg='Base_Stein'","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:53:25.907534Z","iopub.execute_input":"2022-08-28T05:53:25.908347Z","iopub.status.idle":"2022-08-28T05:53:43.820139Z","shell.execute_reply.started":"2022-08-28T05:53:25.908302Z","shell.execute_reply":"2022-08-28T05:53:43.818791Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting Base_Stein\n  Cloning https://github.com/hamish-haggerty/SVGD_packages.git to /tmp/pip-install-m40ncx_5/base-stein_a71dd6adb70a49c7bcea2205737b06a4\n  Running command git clone --filter=blob:none --quiet https://github.com/hamish-haggerty/SVGD_packages.git /tmp/pip-install-m40ncx_5/base-stein_a71dd6adb70a49c7bcea2205737b06a4\n  Resolved https://github.com/hamish-haggerty/SVGD_packages.git to commit bbaeeb9c07b01a45a3a87c5843b183a6cc884ab4\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from Base_Stein) (1.11.0)\nRequirement already satisfied: pytest>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from Base_Stein) (7.1.2)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=7.1.2->Base_Stein) (2.0.1)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=7.1.2->Base_Stein) (21.4.0)\nRequirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from pytest>=7.1.2->Base_Stein) (1.11.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest>=7.1.2->Base_Stein) (21.3)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest>=7.1.2->Base_Stein) (1.1.1)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=7.1.2->Base_Stein) (1.0.0)\nRequirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=7.1.2->Base_Stein) (4.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.11.0->Base_Stein) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest>=7.1.2->Base_Stein) (3.8.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pytest>=7.1.2->Base_Stein) (3.0.9)\nBuilding wheels for collected packages: Base_Stein\n  Building wheel for Base_Stein (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for Base_Stein: filename=Base_Stein-0.0.0-py3-none-any.whl size=4089 sha256=a4d5fb720a5011d64ab166db9dcc6b634f4ac060cd0515cc0b43a626b17f509e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-w2hm_wdp/wheels/f3/4b/c4/586c145d9208aecc7b612cf639a19d1e998ebdfd4297955fce\nSuccessfully built Base_Stein\nInstalling collected packages: Base_Stein\nSuccessfully installed Base_Stein-0.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from fastai.vision.all import *\nfrom self_supervised.augmentations import *\nfrom self_supervised.layers import *\nimport inspect\nimport warnings\nimport random\nwarnings.filterwarnings(\"ignore\")\nfrom Base_Stein.SVGD_classes import *","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:53:46.370140Z","iopub.execute_input":"2022-08-28T05:53:46.371682Z","iopub.status.idle":"2022-08-28T05:53:46.381874Z","shell.execute_reply.started":"2022-08-28T05:53:46.371641Z","shell.execute_reply":"2022-08-28T05:53:46.380932Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Like most other SSL algorithms BT's model consists of an encoder and projector (MLP) layer.\n#Definition is straightforward:\n#https://colab.research.google.com/github/KeremTurgutlu/self_supervised/blob/master/nbs/14%20-%20barlow_twins.ipynb#scrollTo=1M6QcUChcvpz\nclass BarlowTwinsModel(Module):\n    \"\"\"An encoder followed by a projector\n    \"\"\"\n    def __init__(self,encoder,projector):self.encoder,self.projector = encoder,projector\n        \n    def forward(self,x): return self.projector(self.encoder(x))","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:53:46.388521Z","iopub.execute_input":"2022-08-28T05:53:46.391089Z","iopub.status.idle":"2022-08-28T05:53:46.399412Z","shell.execute_reply.started":"2022-08-28T05:53:46.391031Z","shell.execute_reply":"2022-08-28T05:53:46.398378Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#HOWEVER instead of directly using the above, by passing both an encoder and a projector, create_barlow_twins_model\n#function can be used by minimally passing a predefined encoder and the expected input channels.\n\n#In the paper it's mentioned that MLP layer consists of 3 layers... following function will create a 3 layer\n#MLP projector with batchnorm and ReLU by default. Alternatively, you can change bn and nlayers. \n\n#Questions: Why torch.no_grad() when doing this?\ndef create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n    \"Create Barlow Twins model\"\n    n_in  = in_channels(encoder)\n    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n    apply_init(projector)\n    return BarlowTwinsModel(encoder, projector)\n\n#Similar to above. Simple API to make the BT model:","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:53:46.405091Z","iopub.execute_input":"2022-08-28T05:53:46.407994Z","iopub.status.idle":"2022-08-28T05:53:46.417153Z","shell.execute_reply.started":"2022-08-28T05:53:46.407954Z","shell.execute_reply":"2022-08-28T05:53:46.416090Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#BarlowTwins Callback\n#The following parameters can be passed:\n# - aug_pipelines\n# Imb lambda is the weight for redundancy reduction term in the loss function\n\n@delegates(get_multi_aug_pipelines)\ndef get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(n=2,size=size,**kwargs)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:53:46.422092Z","iopub.execute_input":"2022-08-28T05:53:46.425319Z","iopub.status.idle":"2022-08-28T05:53:46.433823Z","shell.execute_reply.started":"2022-08-28T05:53:46.425280Z","shell.execute_reply":"2022-08-28T05:53:46.432075Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#A random degree 2 polynomial, of the form a*x^2 + b*x, where a and b are in {-1,1}, {-1,0,1} respectively\ndef random_poly(A):\n    coeff1 = random.choice([-1,0,1])\n    coeff2 = random.choice([-1,1]) #degree 2 term\n    B = coeff1*A + coeff2*A.pow(2) \n    return B\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:53:46.439226Z","iopub.execute_input":"2022-08-28T05:53:46.441492Z","iopub.status.idle":"2022-08-28T05:53:46.448606Z","shell.execute_reply.started":"2022-08-28T05:53:46.441454Z","shell.execute_reply":"2022-08-28T05:53:46.447604Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Uniform random number between a and b\ndef Unif(a,b):\n    return (b-a)*torch.rand(1).item()+a","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:53:46.454130Z","iopub.execute_input":"2022-08-28T05:53:46.456741Z","iopub.status.idle":"2022-08-28T05:53:46.463288Z","shell.execute_reply.started":"2022-08-28T05:53:46.456704Z","shell.execute_reply":"2022-08-28T05:53:46.462201Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#export\nclass BarlowTwins(Callback):\n    order,run_valid = 9,True\n    def __init__(self, aug_pipelines, lmb=5e-3, print_augs=False):\n        assert_aug_pipelines(aug_pipelines)\n        self.aug1, self.aug2 = aug_pipelines\n        if print_augs: print(self.aug1), print(self.aug2)\n        store_attr('lmb')\n        \n    def before_fit(self): \n        self.learn.loss_func = self.lf\n        nf = self.learn.model.projector[-1].out_features\n        self.I = torch.eye(nf).to(self.dls.device)\n            \n    def before_batch(self):\n        xi,xj = self.aug1(self.x), self.aug2(self.x)\n        self.learn.xb = (torch.cat([xi, xj]),)\n        \n        #Uncomment to run standard BT\n    \n#     def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n#         bs,nf = pred.size(0)//2,pred.size(1)\n\n#         z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n\n#         z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n#         z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n        \n#         C = (z1norm.T @ z2norm) / bs \n#         cdiff = (C - self.I)**2\n#         loss = (cdiff*self.I + cdiff*(1-self.I)*self.lmb).sum() \n#         return loss\n\n    def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n        bs,nf = pred.size(0)//2,pred.size(1)\n\n        #All standard, from BT\n        z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n        C = (z1norm.T @ z2norm) / bs \n        cdiff = (C - self.I)**2\n        \n        #polyprob=0.1\n        polyprob=0.25\n        temrand = random.random()\n        if temrand < polyprob: #With some probability we want off diag terms to be (quadratic) say.\n\n            #This block is \"best so far\"\n            z1norm_2 = random_poly(z1norm)       \n            z2norm_2 = z2norm\n\n            C_2 = (z1norm_2.T @ z2norm_2) / bs\n            \n            cdiff_2 = (C_2)**2 #don't need to subtract I as only looking at off diag terms\n            \n        else:\n            cdiff_2 = cdiff\n            \n        l2 = cdiff_2*(1-self.I)*self.lmb #Is either the standard term - or not.\n\n        loss = (cdiff*self.I + l2).sum() \n        return loss\n\n    \n    @torch.no_grad()\n    def show(self, n=1):\n        bs = self.learn.x.size(0)//2\n        x1,x2  = self.learn.x[:bs], self.learn.x[bs:] \n        idxs = np.random.choice(range(bs),n,False)\n        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n        images = []\n        for i in range(n): images += [x1[i],x2[i]] \n        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:53:50.471634Z","iopub.execute_input":"2022-08-28T05:53:50.472101Z","iopub.status.idle":"2022-08-28T05:53:50.509088Z","shell.execute_reply.started":"2022-08-28T05:53:50.472059Z","shell.execute_reply":"2022-08-28T05:53:50.507906Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Debugging cell - delete later (similar to cell below)\nfastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\nmodel = create_barlow_twins_model(fastai_encoder, hidden_size=125,projection_size=125)# projection_size=1024)\n#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n#values for these which is tantamount to doing nothing\n#So if we choose resize_scale=(1,1) then the images look the same.\n#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\naug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=True)\n#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\nlearn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\nlearn.fit(1) #300","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:57:05.102904Z","iopub.execute_input":"2022-08-28T05:57:05.103502Z","iopub.status.idle":"2022-08-28T05:57:12.223815Z","shell.execute_reply.started":"2022-08-28T05:57:05.103455Z","shell.execute_reply":"2022-08-28T05:57:12.222059Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\nPipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>39.456692</td>\n      <td>37.395454</td>\n      <td>00:06</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"#Get the dataloader and set batch size\nbs=512\npath = untar_data(URLs.MNIST)\nitems = get_image_files(path/'training') #i.e. NOT testing!!!\nitems=items.shuffle()\n\nitems1 = items[0:2000]\n\nsplit = RandomSplitter(valid_pct=0.5) #randomly split training set into training and validation\n#tds = Datasets(items,splits=split(items)) #Do we want this?\ntds = Datasets(items1, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items1)) #Or do we want this?\ndls = tds.dataloaders(bs=bs, after_item=[ToTensor(), IntToFloatTensor()], device='cuda')\n\n#Evaluate linear classifier on this guy\nitems2 = items[2000:]\nsplit = RandomSplitter(valid_pct=0.99) #randomly split training set into training and validation\ntds_new = Datasets(items2, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items2)) #Or do we want this?\ndls_new = tds_new.dataloaders(bs=bs, after_item=[ToTensor(), IntToFloatTensor()], device='cuda')\n","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:54:13.957798Z","iopub.execute_input":"2022-08-28T05:54:13.958343Z","iopub.status.idle":"2022-08-28T05:54:54.420351Z","shell.execute_reply.started":"2022-08-28T05:54:13.958302Z","shell.execute_reply":"2022-08-28T05:54:54.419182Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.03% [15687680/15683414 00:00<00:00]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"#A \"reasonable\" composite augmentation: initially copy pasted BT. We run this cell a few times to check it makes sense\n#Also define encoder and model\nfastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\nmodel = create_barlow_twins_model(fastai_encoder, hidden_size=10,projection_size=10)# projection_size=1024)\n#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n#values for these which is tantamount to doing nothing\n#So if we choose resize_scale=(1,1) then the images look the same.\n#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\naug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=True)\n#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\nlearn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n\n#dls.valid.bs = len(dls.valid_ds) #Set the validation dataloader batch size to be the length of the validation dataset\n\nb = dls.one_batch()\nlearn._split(b)\nlearn('before_batch')\naxes = learn.barlow_twins.show(n=2)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:55:04.385065Z","iopub.execute_input":"2022-08-28T05:55:04.385829Z","iopub.status.idle":"2022-08-28T05:55:08.305250Z","shell.execute_reply.started":"2022-08-28T05:55:04.385785Z","shell.execute_reply":"2022-08-28T05:55:08.298072Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\nPipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x432 with 4 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#Simple linear classifier\nclass LinearClassifier(nn.Module):\n    \n    def __init__(self,zdim):\n        super().__init__()\n        self.fc1 = nn.Linear(zdim,10) #As 10 classes for mnist\n        \n    def forward(self,x):\n        x = cast(self.fc1(x),Tensor) #so we have to use cross entropy loss. cast is because using old version fastai \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-08-28T05:55:13.038011Z","iopub.execute_input":"2022-08-28T05:55:13.038519Z","iopub.status.idle":"2022-08-28T05:55:13.067445Z","shell.execute_reply.started":"2022-08-28T05:55:13.038469Z","shell.execute_reply":"2022-08-28T05:55:13.063583Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Train Classifier on encoder(mnist) for (at the moment) one epoch\n\nfastai_encoder.eval()\n\nzdim=1024 #see above\nhead = LinearClassifier(zdim=zdim)\ndevice='cuda'\nhead.to(device)\noptimizer = torch.optim.Adam(head.parameters())\ncriterion = nn.CrossEntropyLoss()\n#EPOCHS=100\n\nfor epoch in range(10):\n    for x,y in dls.train:\n        #break \n\n        #b = dls.train.one_batch() #Seems need dls[0] or dls.train for training ... dls[1] is validation see here https://docs.fast.ai/data.core.html#DataLoaders.__getitem__\n        #x,y = b[0],b[1]\n\n        loss = criterion(head(fastai_encoder(x)),y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        #print(loss)\nprint('done')\n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-23T04:24:04.909901Z","iopub.execute_input":"2022-08-23T04:24:04.910473Z","iopub.status.idle":"2022-08-23T04:24:20.951092Z","shell.execute_reply.started":"2022-08-23T04:24:04.910425Z","shell.execute_reply":"2022-08-23T04:24:20.949822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test result of above cell on the validation set - assumes that batch size of valid-dataloader is = number of valid samples                                        \n\n# print('The validation batch size is: {} '.format(dls.valid.bs))\n# input()\n\n\n#b = dls.valid.one_batch()\n\nfastai_encoder.eval()\n\nnum_correct=0\nfor x,y in dls_new.valid:\n    ypred = head(fastai_encoder(x))\n    correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n    num_correct += correct.sum()\n\nprint(num_correct/len(dls_new.valid_ds))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-23T04:24:38.329876Z","iopub.execute_input":"2022-08-23T04:24:38.330457Z","iopub.status.idle":"2022-08-23T04:25:54.763106Z","shell.execute_reply.started":"2022-08-23T04:24:38.330409Z","shell.execute_reply":"2022-08-23T04:25:54.761847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Some PRELIMINARY results...\n#300 epochs, train/val = 1000/1000, batch_size=512 hidden_size=proj_size=125, train linear classifier 10 epochs. Also, evaluate on ~58k remaining\n#Need to beat ~ 0.6 which is just training linear classifier\nSupervised = 0.6\nBT = 0.7327\nquadratic_polyprob25 = 0.7865\nrandom_poly_polyprob25 = 0.7985 #Still best","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preliminary results for MNIST:\n\nWe perform some ablations on the Barlow twins loss function: Instead of the $\\operatorname{Corr}(z_{1i},z_{2j})=0$ constraints, we \nhave a constraint $\\operatorname{Corr}(z_{1i},p(z_{2j}))=0$, where $p$ is a random polynomial (sampled for each batch). Motivation: The $\\operatorname{Corr}(z_{1i},z_{2j})$ constraint in BT is a redundancy reduction term. Really want these terms to be statistically independent, not just uncorrelated. It is a theorem that if $\\operatorname{Corr}(h(X),h(Y))=0$ for all $h$ in a suitable class of functions (e.g. continuous functions) THEN $X$ and $Y$ are independent. \n\nBaseline: Train BT on 1000 (unlabelled) MNIST samples (around 1.67% of the available training data), to learn a representation (125 dimensional). Then take the frozen representation, and on the same samples train a linear classifier head (with the labels). Evaluate on ~58k MNIST samples. Result: 73.27% accuracy\n\nModification: We take p to be a low dimensional polynomial. Then training modified BT, (MBT) on the same 1k MNIST samples as above, and evaluating on the remaining ~58k, we get 79.85% accuracy, which is larger than 73.27% for Barlow twins. As a point of comparison, if we train a linear classifier on the raw 28x28 pixels (instead of the frozen representation), accuracy is 60%, so as expected training a linear classifier on a learned representation is superior to training on the raw pixels.\n\nConcerns: Usually these is a mistake, especially when results are positive... Need to test everything carefully. Have been experimenting on MNIST for a while, so need to test on a different dataset, maybe CIFAR or miniImagenet. \n\n**Plan for next week or so**\n\n* Test above results more carefully by running several times (on different 1k samples each time), and try performing ablations similar to the BT paper. I think it is likely I have made several mistakes, as is typical..\n* Importantly: test the above loss function ablations on another dataset to MNIST. \n* Spend ~ 50% of time continuing to read literature. Especially want to read VICReg paper, which builds on BT paper\n* Need to improve Latex skills, and in particular learn how to create good graphics / visuals\n\n\n","metadata":{}},{"cell_type":"code","source":"# #Just train a linear classifier (no encoder)\n# #Basically cell above but remove encoder and some re-shaping\n# zdim=28*28 #see above\n# head = LinearClassifier(zdim=zdim)\n# head.to(device)\n# optimizer = torch.optim.Adam(head.parameters())\n# criterion = nn.CrossEntropyLoss()\n\n\n# for x,y in dls.train:\n#     #break\n#     #b = dls.train.one_batch() #see here https://docs.fast.ai/data.core.html#DataLoaders.__getitem__\n#     #x,y = b[0],b[1]\n\n#     x=x.view(bs,zdim)\n#     x=cast(x, Tensor) #Have to do this when using old version of fastai for some reason...\n    \n#     out = head(x)\n#     loss = criterion(out,y)\n#     optimizer.zero_grad()\n#     loss.backward()\n#     optimizer.step()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T04:44:23.777730Z","iopub.execute_input":"2022-08-23T04:44:23.778296Z","iopub.status.idle":"2022-08-23T04:44:23.883036Z","shell.execute_reply.started":"2022-08-23T04:44:23.778147Z","shell.execute_reply":"2022-08-23T04:44:23.881493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Test result of above cell, (i.e. just a linear classifier), on the validation set - assumes that batch size of valid-dataloader is = number of valid samples                                        \n# num_correct=0\n# for x,y in dls_new.valid:\n\n#     x=x.view(x.shape[0],zdim)\n#     x=cast(x, Tensor) #Have to do this when using old version of fastai for some reason...\n    \n#     ypred = head(x)\n#     correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n#     num_correct += correct.sum()\n    \n# print(num_correct/len(dls_new.valid_ds))","metadata":{"execution":{"iopub.status.busy":"2022-08-23T03:20:27.522639Z","iopub.execute_input":"2022-08-23T03:20:27.523131Z","iopub.status.idle":"2022-08-23T03:21:41.420888Z","shell.execute_reply.started":"2022-08-23T03:20:27.523080Z","shell.execute_reply":"2022-08-23T03:21:41.419308Z"},"trusted":true},"execution_count":null,"outputs":[]}]}