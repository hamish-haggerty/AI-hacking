{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0\n!pip install fastai==2.6.3 --no-deps\n!pip install self_supervised","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:01:30.762385Z","iopub.execute_input":"2022-09-11T07:01:30.763083Z","iopub.status.idle":"2022-09-11T07:02:01.518169Z","shell.execute_reply.started":"2022-09-11T07:01:30.762967Z","shell.execute_reply":"2022-09-11T07:02:01.516900Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch==1.11.0 in /opt/conda/lib/python3.7/site-packages (1.11.0)\nRequirement already satisfied: torchvision==0.12.0 in /opt/conda/lib/python3.7/site-packages (0.12.0)\nRequirement already satisfied: torchaudio==0.11.0 in /opt/conda/lib/python3.7/site-packages (0.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.11.0) (4.1.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0) (9.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0) (1.21.6)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0) (2.27.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0) (2022.6.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0) (2.0.12)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0) (1.26.9)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting fastai==2.6.3\n  Downloading fastai-2.6.3-py3-none-any.whl (197 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.9/197.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fastai\n  Attempting uninstall: fastai\n    Found existing installation: fastai 2.7.4\n    Uninstalling fastai-2.7.4:\n      Successfully uninstalled fastai-2.7.4\nSuccessfully installed fastai-2.6.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting self_supervised\n  Downloading self_supervised-1.0.4-py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m441.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: fastai>=2.2.7 in /opt/conda/lib/python3.7/site-packages (from self_supervised) (2.6.3)\nRequirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from self_supervised) (22.1.1)\nCollecting timm>=0.4.5\n  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from self_supervised) (21.3)\nRequirement already satisfied: kornia>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from self_supervised) (0.5.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (2.27.1)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (0.0.6)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.0.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.0.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.3.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (3.5.2)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (0.12.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.7.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (6.0)\nRequirement already satisfied: pillow>6.0.0 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (9.1.1)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (2.3.7)\nRequirement already satisfied: fastcore<1.5,>=1.3.27 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.4.5)\nRequirement already satisfied: torch<1.12,>=1.7.0 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.11.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->self_supervised) (3.0.9)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.7)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (4.64.0)\nRequirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (7.4.5)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.0.6)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.7.8)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (59.8.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.0.6)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.1.3)\nRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.5)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.21.6)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (2022.6.15)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch<1.12,>=1.7.0->fastai>=2.2.7->self_supervised) (4.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (1.4.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (4.33.3)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fastai>=2.2.7->self_supervised) (2022.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai>=2.2.7->self_supervised) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai>=2.2.7->self_supervised) (1.1.0)\nRequirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai>=2.2.7->self_supervised) (4.12.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->fastai>=2.2.7->self_supervised) (1.16.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai>=2.2.7->self_supervised) (3.8.0)\nInstalling collected packages: timm, self_supervised\nSuccessfully installed self_supervised-1.0.4 timm-0.6.7\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import fastai\nimport self_supervised\nimport torch\nfastai.__version__ #Check that version is 2.6.3","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:02:01.523711Z","iopub.execute_input":"2022-09-11T07:02:01.524440Z","iopub.status.idle":"2022-09-11T07:02:03.659141Z","shell.execute_reply.started":"2022-09-11T07:02:01.524398Z","shell.execute_reply":"2022-09-11T07:02:03.657948Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'2.6.3'"},"metadata":{}}]},{"cell_type":"code","source":"#This is not needed unless running SBT\n#!pip uninstall --yes git+https://github.com/hamish-haggerty/SVGD_packages.git#egg='Base_Stein'\n!pip install git+https://github.com/hamish-haggerty/SVGD_packages.git#egg='Base_Stein'","metadata":{"execution":{"iopub.status.busy":"2022-08-28T08:53:29.355511Z","iopub.execute_input":"2022-08-28T08:53:29.356046Z","iopub.status.idle":"2022-08-28T08:53:47.938520Z","shell.execute_reply.started":"2022-08-28T08:53:29.356001Z","shell.execute_reply":"2022-08-28T08:53:47.937180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.all import *\nfrom self_supervised.augmentations import *\nfrom self_supervised.layers import *\nimport inspect\nimport warnings\nimport random\nimport math\nwarnings.filterwarnings(\"ignore\")\n#from Base_Stein.SVGD_classes import *","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:02:03.664161Z","iopub.execute_input":"2022-09-11T07:02:03.667063Z","iopub.status.idle":"2022-09-11T07:02:06.084228Z","shell.execute_reply.started":"2022-09-11T07:02:03.667018Z","shell.execute_reply":"2022-09-11T07:02:06.082906Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Like most other SSL algorithms BT's model consists of an encoder and projector (MLP) layer.\n#Definition is straightforward:\n#https://colab.research.google.com/github/KeremTurgutlu/self_supervised/blob/master/nbs/14%20-%20barlow_twins.ipynb#scrollTo=1M6QcUChcvpz\nclass BarlowTwinsModel(Module):\n    \"\"\"An encoder followed by a projector\n    \"\"\"\n    def __init__(self,encoder,projector):self.encoder,self.projector = encoder,projector\n        \n    def forward(self,x): return self.projector(self.encoder(x))","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:02:06.090810Z","iopub.execute_input":"2022-09-11T07:02:06.093915Z","iopub.status.idle":"2022-09-11T07:02:06.103483Z","shell.execute_reply.started":"2022-09-11T07:02:06.093870Z","shell.execute_reply":"2022-09-11T07:02:06.101475Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#HOWEVER instead of directly using the above, by passing both an encoder and a projector, create_barlow_twins_model\n#function can be used by minimally passing a predefined encoder and the expected input channels.\n\n#In the paper it's mentioned that MLP layer consists of 3 layers... following function will create a 3 layer\n#MLP projector with batchnorm and ReLU by default. Alternatively, you can change bn and nlayers. \n\n#Questions: Why torch.no_grad() when doing this?\ndef create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n    \"Create Barlow Twins model\"\n    n_in  = in_channels(encoder)\n    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n    apply_init(projector)\n    return BarlowTwinsModel(encoder, projector)\n\n#Similar to above. Simple API to make the BT model:","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:02:06.108208Z","iopub.execute_input":"2022-09-11T07:02:06.110816Z","iopub.status.idle":"2022-09-11T07:02:06.120526Z","shell.execute_reply.started":"2022-09-11T07:02:06.110778Z","shell.execute_reply":"2022-09-11T07:02:06.119537Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#BarlowTwins Callback\n#The following parameters can be passed:\n# - aug_pipelines\n# Imb lambda is the weight for redundancy reduction term in the loss function\n\n@delegates(get_multi_aug_pipelines)\ndef get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(n=2,size=size,**kwargs)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:02:06.125686Z","iopub.execute_input":"2022-09-11T07:02:06.128794Z","iopub.status.idle":"2022-09-11T07:02:06.135945Z","shell.execute_reply.started":"2022-09-11T07:02:06.128751Z","shell.execute_reply":"2022-09-11T07:02:06.134812Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#A random degree 2 polynomial, of the form a*x^2 + b*x, where a and b are in {-1,1}, {-1,0,1} respectively\ndef random_poly(A):\n    coeff1 = random.choice([-1,0,1])\n    coeff2 = random.choice([-1,1]) #degree 2 term\n    B = coeff1*A + coeff2*A.pow(2) \n    return B\n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-09T11:18:53.343247Z","iopub.execute_input":"2022-09-09T11:18:53.343656Z","iopub.status.idle":"2022-09-09T11:18:53.350825Z","shell.execute_reply.started":"2022-09-09T11:18:53.343625Z","shell.execute_reply":"2022-09-09T11:18:53.349358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Ok, we want to sample several random polynomials according to some procedure and plot on range [-5,5], or something.\n# #This is also just good practice with plotting etc...\n\ndef random_quintic(A):\n\n    \n    B=torch.normal(mean=0, std=0.125, size=(1, 1)).item() #First Horner term (and is coefficient of x^4)\n    \n    Btem=torch.normal(mean=0, std=0.25, size=(1, 1)).item()#Sample coefficient of x^3\n    B = Btem + B*A #Second Horner term\n    \n    Btem = torch.normal(mean=0,std=0.5, size=(1, 1)).item() #Sample coefficient of x^2\n    B = Btem + B*A #Third Horner term\n    \n    Btem = random.choice([-1,1])*torch.normal(mean=1,std=2, size=(1, 1)).item() #Sample coefficient of x\n    B = Btem + B*A #Fourth Horner term\n    \n    Btem = torch.normal(mean=0,std=1, size=(1, 1)).item() #Sample coefficient of x^0\n    B = Btem + B*A #Fifth Horner term\n    \n    \n    return B\n\n\n\n#Ok, we want to sample several random polynomials according to some procedure and plot on range [-5,5], or something.\n#This is also just good practice with plotting etc...\n\n#Approx linear quintic\n# def random_quintic(A):\n\n    \n#     B=torch.normal(mean=0, std=0.01, size=(1, 1)).item() #First Horner term (and is coefficient of x^4)\n    \n#     Btem=torch.normal(mean=0, std=0.01, size=(1, 1)).item()#Sample coefficient of x^3\n#     B = Btem + B*A #Second Horner term\n    \n#     Btem = torch.normal(mean=0,std=0.025, size=(1, 1)).item() #Sample coefficient of x^2\n#     B = Btem + B*A #Third Horner term\n    \n#     Btem = random.choice([-1,1])*torch.normal(mean=1,std=0.05, size=(1, 1)).item() #Sample coefficient of x\n#     B = Btem + B*A #Fourth Horner term\n    \n#     Btem = torch.normal(mean=0,std=1, size=(1, 1)).item() #Sample coefficient of x^0\n#     B = Btem + B*A #Fifth Horner term\n    \n    \n#     return B","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:30:30.298217Z","iopub.execute_input":"2022-09-11T07:30:30.298681Z","iopub.status.idle":"2022-09-11T07:30:30.315155Z","shell.execute_reply.started":"2022-09-11T07:30:30.298639Z","shell.execute_reply":"2022-09-11T07:30:30.314045Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def random_sinusoid(x,std=2.0):\n    \n    t=torch.normal(mean=0,std=std,size=(1,1)).item()\n    s=torch.normal(mean=0,std=std,size=(1,1)).item()\n    \n    u=torch.normal(mean=0,std=std,size=(1,1)).item()\n    v=torch.normal(mean=0,std=std,size=(1,1)).item()\n    \n    return torch.sin(t*x+s) + torch.cos(u*x + v)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:30:33.558644Z","iopub.execute_input":"2022-09-11T07:30:33.559085Z","iopub.status.idle":"2022-09-11T07:30:33.571091Z","shell.execute_reply.started":"2022-09-11T07:30:33.559045Z","shell.execute_reply":"2022-09-11T07:30:33.570044Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def poly_sinusoid(x):\n    \n    return random_quintic(x) + random_sinusoid(x,std=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:30:36.263591Z","iopub.execute_input":"2022-09-11T07:30:36.264036Z","iopub.status.idle":"2022-09-11T07:30:36.269694Z","shell.execute_reply.started":"2022-09-11T07:30:36.263999Z","shell.execute_reply":"2022-09-11T07:30:36.268605Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def random_quad(A):\n    coeff1 = Unif(-2,2)\n    coeff2 = Unif(-2,2) #degree 2 term\n    B = (coeff1*A + 0.5*coeff2*A.pow(2))\n    return B","metadata":{"execution":{"iopub.status.busy":"2022-09-09T05:27:42.342529Z","iopub.execute_input":"2022-09-09T05:27:42.343301Z","iopub.status.idle":"2022-09-09T05:27:42.349635Z","shell.execute_reply.started":"2022-09-09T05:27:42.343254Z","shell.execute_reply":"2022-09-09T05:27:42.348833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_quad_new(A):\n    coeff2 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n    coeff1 = torch.normal(mean=1, std=0.2, size=(1, 1)).item() #degree 2 term\n    \n#     coeff2 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n#     coeff1 = torch.normal(mean=1, std=0.7, size=(1, 1)).item() #degree 2 term\n\n#     coeff2 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n#     coeff1 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n    \n    B = (coeff1*A + coeff2*A.pow(2))\n    return B","metadata":{"execution":{"iopub.status.busy":"2022-09-09T05:27:44.764549Z","iopub.execute_input":"2022-09-09T05:27:44.765370Z","iopub.status.idle":"2022-09-09T05:27:44.773507Z","shell.execute_reply.started":"2022-09-09T05:27:44.765316Z","shell.execute_reply":"2022-09-09T05:27:44.771946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_quad_new2(A):\n    power=Unif(1,2.5)\n    coeff2 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n    coeff1 = torch.normal(mean=1, std=1, size=(1, 1)).item() #degree 2 term\n    \n#     coeff2 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n#     coeff1 = torch.normal(mean=1, std=0.7, size=(1, 1)).item() #degree 2 term\n\n#     coeff2 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n#     coeff1 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n\n    \n    B = (coeff1*A + coeff2*torch.abs(A).pow(power))\n    return B","metadata":{"execution":{"iopub.status.busy":"2022-09-09T05:27:47.211996Z","iopub.execute_input":"2022-09-09T05:27:47.213199Z","iopub.status.idle":"2022-09-09T05:27:47.219674Z","shell.execute_reply.started":"2022-09-09T05:27:47.213157Z","shell.execute_reply":"2022-09-09T05:27:47.218751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#squared exponential kernel for the GP\ndef norm2(X):\n    \"\"\"\"Vectorized implementation of norm squared. X is collection of N x,y points, and\n        returns Y, where Y[i,j] = norm(X[i],X[j])**2. X has shape N*zdim, Y has shape NxN.\n    \"\"\"\n\n    #Use formula ||(x-y)||**2 = ||x||**2 + ||y||**2 - 2x.T*y. in 1d this is just the\n    #familiar formula (x-y)**2 expanded.\n\n    X_norm = torch.sum(X ** 2, axis = -1) #gives x[i]**2 for each i\n\n    #This First part is \"matrix mult\" viewed as addition\n    tem1 = X_norm[:,None] + X_norm[None,:] #gives x[i]**2 + x[j]**2 for each i,j\n\n    tem2 = - 2 * torch.mm(X, X.T) #last part of above formula\n\n    return tem1 + tem2\n\n\ndef rbf(NORM2,sig=1.0):\n    \"\"\"\"Assumes have already computed norm2(X). So can call as: rbf(norm2(X),sig)\n    \"\"\"\n\n    assert(sig>0)\n    assert NORM2.shape[0] == NORM2.shape[1]\n\n    return torch.exp(-1/(2*sig)*NORM2)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T05:27:49.478241Z","iopub.execute_input":"2022-09-09T05:27:49.478647Z","iopub.status.idle":"2022-09-09T05:27:49.487174Z","shell.execute_reply.started":"2022-09-09T05:27:49.478612Z","shell.execute_reply":"2022-09-09T05:27:49.485953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def GP(X,sig=1.0):\n    \"\"\"\"x is a set of datapoints\"\"\"\n    \n    \n    bs,N=X.shape\n    I=1e-5*torch.eye(N).to('cuda')\n    Mu = torch.zeros(N).to('cuda')\n    MVN = torch.distributions.multivariate_normal.MultivariateNormal\n    \n    \n    for i in range(bs):\n        x=X[i,:]\n        NORM2=norm2(x.view(-1,1))\n        Cov = rbf(NORM2,sig=sig) + I\n        mvn=MVN(Mu,Cov)\n    \n        X[i,:] = mvn.sample()\n        \n    \n    return X","metadata":{"execution":{"iopub.status.busy":"2022-09-09T05:27:58.132734Z","iopub.execute_input":"2022-09-09T05:27:58.133146Z","iopub.status.idle":"2022-09-09T05:27:58.141861Z","shell.execute_reply.started":"2022-09-09T05:27:58.133110Z","shell.execute_reply":"2022-09-09T05:27:58.140517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Uniform random number between a and b\ndef Unif(a,b):\n    return (b-a)*torch.rand(1).item()+a","metadata":{"execution":{"iopub.status.busy":"2022-09-09T05:28:00.797554Z","iopub.execute_input":"2022-09-09T05:28:00.798272Z","iopub.status.idle":"2022-09-09T05:28:00.804258Z","shell.execute_reply.started":"2022-09-09T05:28:00.798220Z","shell.execute_reply":"2022-09-09T05:28:00.803420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#export\nclass BarlowTwins(Callback):\n    order,run_valid = 9,True\n    def __init__(self, aug_pipelines, lmb=5e-3, print_augs=False):\n        assert_aug_pipelines(aug_pipelines)\n        self.aug1, self.aug2 = aug_pipelines\n        if print_augs: print(self.aug1), print(self.aug2)\n        store_attr('lmb')\n        \n    def before_fit(self): \n        self.learn.loss_func = self.lf\n        nf = self.learn.model.projector[-1].out_features\n        self.I = torch.eye(nf).to(self.dls.device)\n            \n    def before_batch(self):\n        xi,xj = self.aug1(self.x), self.aug2(self.x)\n        self.learn.xb = (torch.cat([xi, xj]),)\n        \n        #Uncomment to run standard BT\n    \n#     def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n#         bs,nf = pred.size(0)//2,pred.size(1)\n\n#         z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n\n#         z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n#         z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n        \n#         C = (z1norm.T @ z2norm) / bs \n#         cdiff = (C - self.I)**2\n#         loss = (cdiff*self.I + cdiff*(1-self.I)*self.lmb).sum() \n#         return loss\n\n\n    def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n        bs,nf = pred.size(0)//2,pred.size(1)\n\n        #All standard, from BT\n        z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n        C = (z1norm.T @ z2norm) / bs \n        cdiff = (C - self.I)**2\n    \n        polyprob=1\n        #polyprob=0.5\n        temrand = random.random()\n        if temrand < polyprob: #With some probability we want off diag terms to be (quadratic) say.\n\n            #This block is \"best so far\"\n#             z1norm_2 = 0.5*z1norm.pow(2)\n#             z2norm_2 = z2norm\n\n#             s=Unif(0,0.2)\n#             z1norm_2 = (1/s)*torch.sin(s*z1norm)\n#             z2norm_2 = z2norm\n            \n            z1norm_2 = poly_sinusoid(z1norm)\n\n            z2norm_2 = z2norm\n\n\n#             s=Unif(-2,2)\n# #             t=Unif(-1,1)\n#             z1norm_2 = (1/(abs(s)))*(torch.sin(s*z1norm))\n#             z2norm_2 = z2norm\n\n            C_2 = (z1norm_2.T @ z2norm_2) / bs\n            \n            cdiff_2 = (C_2)**2 #don't need to subtract I as only looking at off diag terms\n            \n        else:\n            cdiff_2 = cdiff\n            \n            \n            \n            \n       #New CCA hacking block....\n        C1 = (z1norm_2.T @ z1norm_2) / bs \n        C2 = (z2norm_2.T @ z2norm_2) / bs\n        \n        eps=1e-4\n        \n        L1, Q1 = torch.linalg.eigh(C1 + eps*self.I)\n        L2, Q2 = torch.linalg.eigh(C2 + eps*self.I)\n        \n        C = (z1norm_2.T @ z2norm_2) / bs\n        \n        L1=torch.abs(L1)\n        L2=torch.abs(L2)\n        \n        \n        C_1 = Q1 @ torch.diag(L1.pow(-0.5)) @ Q1.T #This is \n        C_2 = Q2 @ torch.diag(L2.pow(-0.5)) @ Q2.T\n        S = C_1 @ C @ C_2\n        [A,D,B]=torch.linalg.svd(S)\n        print(D)\n        input('hi')     \n            \n            \n            \n            \n        l2 = cdiff_2*(1-self.I)*self.lmb #Is either the standard term - or not.\n\n        loss = (cdiff*self.I + l2).sum() \n        return loss\n\n    \n    @torch.no_grad()\n    def show(self, n=1):\n        bs = self.learn.x.size(0)//2\n        x1,x2  = self.learn.x[:bs], self.learn.x[bs:] \n        idxs = np.random.choice(range(bs),n,False)\n        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n        images = []\n        for i in range(n): images += [x1[i],x2[i]] \n        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:31:54.186543Z","iopub.execute_input":"2022-09-11T07:31:54.187012Z","iopub.status.idle":"2022-09-11T07:31:54.217590Z","shell.execute_reply.started":"2022-09-11T07:31:54.186962Z","shell.execute_reply":"2022-09-11T07:31:54.216535Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"#new cell\nclass BarlowTwins(Callback):\n    order,run_valid = 9,True\n    def __init__(self, aug_pipelines, lmb=5e-3, print_augs=False):\n        assert_aug_pipelines(aug_pipelines)\n        self.aug1, self.aug2 = aug_pipelines\n        if print_augs: print(self.aug1), print(self.aug2)\n        store_attr('lmb')\n        \n    def before_fit(self): \n        self.learn.loss_func = self.lf\n        nf = self.learn.model.projector[-1].out_features\n        self.I = torch.eye(nf).to(self.dls.device)\n            \n    def before_batch(self):\n        xi,xj = self.aug1(self.x), self.aug2(self.x)\n        self.learn.xb = (torch.cat([xi, xj]),)\n\n    def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n        bs,nf = pred.size(0)//2,pred.size(1)\n\n        #All standard, from BT\n        z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n        C1 = (z1norm.T @ z1norm) / bs \n        C2 = (z2norm.T @ z2norm) / bs\n        \n        eps=1e-4\n        \n        L1, Q1 = torch.linalg.eigh(C1 + eps*self.I)\n        L2, Q2 = torch.linalg.eigh(C2 + eps*self.I)\n        \n        C = (z1norm.T @ z2norm) / bs\n        \n        cdiff = (C - self.I)**2\n        \n        C1_off = (1-self.I)*(C1**2)\n        C2_off = (1-self.I)*(C2**2)\n        \n        #Drive off diag terms of crosscorrelation matrices towards zero\n        Csquare = (1-self.I)*(C**2) #Redundancy reduction term. Same as BT\n        \n        #Drive autocorrelation matrices towards each other\n        AutoCorrel = (C1-C2)**2 #\"Invariance\" term (also has some redun - reduc built in)\n        \n        #Difference between largest and smallest eigenvalue\n\n#         E1 = (L1[nf-1]-L1[0]).pow(2)\n#         E2 = (L2[nf-1]-L2[0]).pow(2)\n        \n        tem1=[2*i for i in range(250)]\n        tem2=[2*i+1 for i in range(250)]\n        \n        \n        Diff = (L1[tem1] - L1[tem2]).pow(2) +  (L2[tem1] - L2[tem2]).pow(2)\n        \n        \n        #CCA: Formula from here:https://civil.colorado.edu/~balajir/Adv-Data-material/CVEN-6833/papers-2read/Cherry_2003.pdf\n        C_1 = Q1 @ torch.diag(L1.pow(-0.5)) @ Q1.T #This is \n        C_2 = Q2 @ torch.diag(L2.pow(-0.5)) @ Q2.T\n        S = C_1 @ C @ C_2\n        \n        [A,D,B]=torch.linalg.svd(S)\n        \n        loss_CCA = (D[0]-1).pow(2) + D[1]\n      \n        \n        \n#         Err1=0\n#         Err2=0\n#         PC=5\n        \n#         for i in range(1,PC):\n#             Err1 += L1[nf-i]*Q1[:,nf-i].view(-1,1) @ Q1[:,nf-i].view(1,-1)\n#             Err2 += L2[nf-i]*Q2[:,nf-i].view(-1,1) @ Q2[:,nf-i].view(1,-1)\n            \n#         Err=(Err1-Err2).pow(2)\n        \n#         #i.e. we want 500th-99th eigenvalues to be small\n#         Err_sparse = L1[0:nf-PC].pow(2) + L1[0:nf-PC].pow(2)\n\n        #Drive autocorrelation matrices away from zero\n        #s=Unif(0.05,0.25)\n        #s=0.5\n        gamma=1\n        #s=Unif(0,1)\n        \n        #C1_NoCollapse = (1-self.I)*((abs(C1)-s)**2) \n        #C2_NoCollapse = (1-self.I)*((abs(C2)-s)**2)\n        \n        relu = torch.nn.ReLU()\n        eps=1e-6\n\n        \n        #Replace squared error with hinge loss\n#         C1_NoCollapse = (1-self.I)*(relu(s-torch.abs(C1)))\n#         C2_NoCollapse = (1-self.I)*(relu(s-torch.abs(C2)))\n\n        #Prevent collapse to zero - this is mean to be like term from VicReg but haven't \n        #tested it carefully...\n        V1 = (self.I*(relu(gamma-C1)) + eps).pow(0.5)\n        V2 = (self.I*(relu(gamma-C2)) + eps).pow(0.5)\n        \n        \n        #cdiff same as BT. AutoCorrel is new, instead of redun reduc term...\n        \n        \n        #So this is BT plus the autocorrel term, plus NoCollapse terms and with appropriate rescaling\n        #loss = (self.I*cdiff).sum() + self.lmb*(0.5AutoCorrel.sum())#+0.5*Csquare.sum())# + self.lmb*0.05*(C1_NoCollapse.sum() + C2_NoCollapse.sum())   #+ 0.5*Csquare.sum() + 0.1*(C1_NoCollapse.sum() + C2_NoCollapse.sum()))#*(1/nf)\n        #loss = self.lmb*(AutoCorrel.sum())+self.lmb*0.05*(C1_NoCollapse.sum() + C2_NoCollapse.sum())#+0.5*Csquare.sum())# + self.lmb*0.05*(C1_NoCollapse.sum() + C2_NoCollapse.sum())   #+ 0.5*Csquare.sum() + 0.1*(C1_NoCollapse.sum() + C2_NoCollapse.sum()))#*(1/nf)\n        \n        #loss = self.lmb*(AutoCorrel.sum())+0.5*(V1.sum() + V2.sum())\n        \n        #loss = (1/(nf*(nf-1)))*(AutoCorrel.sum()) + 0.5*(V1.mean() + V2.mean())\n        \n        #0.8102\n        \n        eig1=L1[nf-1]\n        eig2=L2[nf-1]\n        \n        \n        loss = loss_CCA+(1/100)*(V1.sum() + V2.sum())\n        \n\n        #loss = self.lmb*(AutoCorrel.sum()) + eig1 + eig2+ 1/nf*Diff.sum() + (1/10)*(V1.sum() + V2.sum())\n        \n        #loss = (1/nf)*((L1-L2).pow(2).sum() + (L1.sum()+L2.sum()) + (V1.sum() + V2.sum()))\n        \n        #loss = (1/nf)*(self.lmb*Err.sum()  + 0.5*(Err_sparse.sum()+Err_sparse.sum()) + 0.5*(V1.sum() + V2.sum()))\n\n        #cdiff = (C - self.I)**2\n        #loss = (cdiff*self.I + 0.5*self.lmb*cdiff2 + 0.5*cdiff*(1-self.I)*self.lmb).sum()# + cdiff*(1-self.I)*self.lmb).sum() \n        return loss\n\n\n    \n    @torch.no_grad()\n    def show(self, n=1):\n        bs = self.learn.x.size(0)//2\n        x1,x2  = self.learn.x[:bs], self.learn.x[bs:] \n        idxs = np.random.choice(range(bs),n,False)\n        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n        images = []\n        for i in range(n): images += [x1[i],x2[i]] \n        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:36:12.676485Z","iopub.execute_input":"2022-09-11T07:36:12.677131Z","iopub.status.idle":"2022-09-11T07:36:13.249268Z","shell.execute_reply.started":"2022-09-11T07:36:12.677069Z","shell.execute_reply":"2022-09-11T07:36:13.247589Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"#Debugging cell - delete later (similar to cell below)\nps=500\nhs=500\nfastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\nmodel = create_barlow_twins_model(fastai_encoder, hidden_size=hs,projection_size=ps)# projection_size=1024)\n#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n#values for these which is tantamount to doing nothing\n#So if we choose resize_scale=(1,1) then the images look the same.\n#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\naug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=True)\n#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\nlearn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\nlearn.fit(1000)#300   \n","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:36:17.152325Z","iopub.execute_input":"2022-09-11T07:36:17.152932Z","iopub.status.idle":"2022-09-11T07:36:27.588769Z","shell.execute_reply.started":"2022-09-11T07:36:17.152890Z","shell.execute_reply":"2022-09-11T07:36:27.584672Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\nPipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='5' class='' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      0.50% [5/1000 00:09<31:36]\n    </div>\n    \n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>6.000460</td>\n      <td>6.000420</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>6.000463</td>\n      <td>6.001883</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6.000467</td>\n      <td>6.000453</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>6.000463</td>\n      <td>6.000458</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>6.000467</td>\n      <td>6.000429</td>\n      <td>00:01</td>\n    </tr>\n  </tbody>\n</table><p>\n\n    <div>\n      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      0.00% [0/1 00:00<00:00]\n    </div>\n    "},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3868047768.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBarlowTwins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_pipelines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_augs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/data/load.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# called in context of main process (not workers/subprocesses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0;31m# pin_memory causes tuples to be converted to lists, so convert them back to tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"#Get the dataloader and set batch size\nts=512 #training set size\nbs=256\ndevice='cuda'\npath = untar_data(URLs.MNIST)\nitems = get_image_files(path/'training') #i.e. NOT testing!!!\nitems=items.shuffle()\n\nitems1 = items[0:ts]\nsplit = RandomSplitter(valid_pct=0.5) #randomly split training set into training and validation\n#tds = Datasets(items,splits=split(items)) #Do we want this?\ntds = Datasets(items1, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items1)) #Or do we want this?\ndls = tds.dataloaders(bs=bs, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n\n#Evaluate linear classifier on this guy\nitems2 = items[ts:]\nsplit = RandomSplitter(valid_pct=0.99) #randomly split training set into training and validation\ntds_new = Datasets(items2, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items2)) #Or do we want this?\ndls_new = tds_new.dataloaders(bs=bs, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:07:02.488561Z","iopub.execute_input":"2022-09-11T07:07:02.488997Z","iopub.status.idle":"2022-09-11T07:07:42.780274Z","shell.execute_reply.started":"2022-09-11T07:07:02.488959Z","shell.execute_reply":"2022-09-11T07:07:42.777865Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.03% [15687680/15683414 00:00<00:00]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"tem = [str(i) for i in items1]\n\nt = [j.split('training/')[1] for j in tem]\nt = [j.split('/')[0] for j in t]\n\nd={'0':0,'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0,'8':0,'9':0}\n\n\nfor i in t:\n    d[i]=d[i]+1\n    \nprint(d)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T14:30:41.913229Z","iopub.execute_input":"2022-09-05T14:30:41.913746Z","iopub.status.idle":"2022-09-05T14:30:41.933042Z","shell.execute_reply.started":"2022-09-05T14:30:41.913703Z","shell.execute_reply":"2022-09-05T14:30:41.930887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#A \"reasonable\" composite augmentation: initially copy pasted BT. We run this cell a few times to check it makes sense\n#Also define encoder and model\nfastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\nmodel = create_barlow_twins_model(fastai_encoder, hidden_size=10,projection_size=10)# projection_size=1024)\n#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n#values for these which is tantamount to doing nothing\n#So if we choose resize_scale=(1,1) then the images look the same.\n#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\naug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=False)\n#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\nlearn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n\n#dls.valid.bs = len(dls.valid_ds) #Set the validation dataloader batch size to be the length of the validation dataset\n\nb = dls.one_batch()\nlearn._split(b)\nlearn('before_batch')\naxes = learn.barlow_twins.show(n=2)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:07:42.786080Z","iopub.execute_input":"2022-09-11T07:07:42.786889Z","iopub.status.idle":"2022-09-11T07:07:52.988246Z","shell.execute_reply.started":"2022-09-11T07:07:42.786850Z","shell.execute_reply":"2022-09-11T07:07:52.987222Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\nPipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x432 with 4 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAVkAAAFUCAYAAACObE8FAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ9ElEQVR4nO3dW3NUx7XA8cUdCQmBkEASwkbmYiDGCbGTPMSVPOYL5xOkkkoqTmyH2IAhRlwkgSQkJCQhi4t9Hk7q1Cn3v2FPwRIzW//f4/Lu0czQs7xrr17du3788ceQJOXY/a7fgCS1mUlWkhKZZCUpkUlWkhKZZCUpkUlWkhLtfc1/d33XG/jhhx+K2LNnz4rY8vIyjv/Xv/5VxP74xz8WsT/96U84/unTp0Xs0qVLReyzzz7D8X/4wx+K2Llz54pYf38/jn/58mUR27t37y68ePs5t98ALf18/vx5EVtZWcHx33zzTRGj+f7kyRMc39fXV8Robl65cgXHnzhxoogdOHCgiO3a1dF0xYu9k5WkRCZZSUpkkpWkRK97JqsGaq3J9EyWnlutra3h+IWFhSK2urpaxOg5bwQ/YxocHCxiAwMDOH7//v1FrJNnVB0+z1IXqs3tFy9eFLGtra0iRvM1IuLhw4dFbHFxsYhtbm7ieJpb9NuiusB2805WkhKZZCUpkUlWkhKZZCUpkUlWkhK5uuAtoFUEEVxtffToURG7desWjv/3v/9dxKanp4vY+vo6jj9+/HgRO3LkSBEbHh7G8fv27cP4T7nxezs07eKK4G5CWjFw48YNHP/VV18VMZrbe/bswfE0N2klQW11Af1m6fO/jRUy3slKUiKTrCQlMslKUiKTrCQlsvDVoaatshG8zdvt27eL2N/+9jcc/+WXXxaxu3fvFrHaw/mxsbEiNj4+XsQmJiZwPG0nt3t3+f9l22d7T9N5XCuqzszMFDHaqvDzzz/H8V988UWj16Q5HBFx9OjRIkbt5bWi9HbyTlaSEplkJSmRSVaSEplkJSmRha9XaNoBUzuHiIpUVOSigkFExJ07d4oYdbp88MEHOP7nP/95Efvkk0+K2OTkJI4/fPhwEat14BALYt2Bup6azmOawxER//znP4sYFbOoazEiYn5+vojR3KKuxVqcirq1rsXtnJveyUpSIpOsJCUyyUpSIpOsJCUyyUpSIlcXvAKdyEmnZ87NzeF4aov9+uuvi9jNmzdxPK1uOHfuXBH71a9+heN/+9vfFrELFy4UsdHRURxPp91SBdhVBN2h1kJK7aaPHz8uYvfu3StitZZvWklw/fr1Rn8ngufc1NRUEfvZz36G4z/99NMi9v777xcx2j85YnvnsXeykpTIJCtJiUyykpTIJCtJiSx8/RcVDahgsLi4WMSuXbuGr9m08LWxsYHjT58+XcSoVfazzz7D8RcvXixiIyMjRezgwYM43iJX92o6XyO4+ET7Gv/1r38tYv/4xz/wNWkeU6vuyZMncTzN448//riIXb58GcdTK/jQ0FARq7XV7t1bpj4LX5LUg0yykpTIJCtJiUyykpRoxxW+al0x9NB+dXW1iNEer7S3ZgTvE0uFs2PHjuF46nb5zW9+U8Q+/PBDHN+0yFXbI9YiV3doWuSq7Ws8PT1dxP785z8XMeruunr1Kr4m/f0zZ84UMdq/OIK7EWm+1/aT7e/vL2L79+8vYrU57H6yktQSJllJSmSSlaREJllJSmSSlaRErV5dQPux0smdEc33if373/9exL766it8zfv37xcxaue7dOkSjqfKLFVga/vBNl1J4CqC7tDJypf19fUiVjtZ9i9/+UsRoxZaagOn30UEt3zTvsa///3vcXzTeVxr+d7Ottg35Z2sJCUyyUpSIpOsJCUyyUpSolYXvqiQsLW1hddSuyvtmUlthjdu3MDXpNZDKhjQvq8RvL8mtRnSgYcRFrl6Ta0o+/Tp0yI2OztbxD7//HMc33SfWPo7ExMT+JpU5Prd735XxD766CMcT/O4k5bvXuKdrCQlMslKUiKTrCQlMslKUqIdV/iqdbA8ePCgiFHhi2J0UF0E7+d64cKFIkaHykXwIXS0jyZ1v0RY5Opm1I344sULvHZlZaWI3bx5s4jV9jWmTi7aK5mKUVTgiuDDO5se3BnBxdo2FLmId7KSlMgkK0mJTLKSlMgkK0mJTLKSlKg1qwua7h1bO9GTqrXULkt7xNaqwrQ64Ny5c0Xs/PnzOP7IkSNFjE7k3L3b/1f2Gpqb1NYawXOOVhJQ+2xExMzMTBEbHBwsYrTHa+202StXrhSxEydOFLHafrBtXUlA/HVKUiKTrCQlMslKUiKTrCQlanXhi/ZzffToEY6/detWEbt+/XoRW1tbK2LDw8P4mlTkouICFQwiuGhgkasd6HDEpaUlvPabb74pYjQ3p6encTz9NqamporYL37xiyJWa6ulfWap5btW4NpJLd/+YiUpkUlWkhKZZCUpkUlWkhK1pvBFe8dSBw11v0TwwXTLy8uN/nbtsDkqLpw6daqIUcEggosDVMSo2UnFhV5DRdmFhQW89s6dO0WMilzff/89jqfC6uXLl4vYpUuXGo2N4M5DQr/LCC7gtnW+eicrSYlMspKUyCQrSYlMspKUqDWFLyoIUeFrfn4ex1O3DW1HR9sPnj17Fl9zcnKyiA0MDBSxWnFga2uriFFxoNZVQwcs7qSCQ7egf9+NjY0iVivKPnz4sIjRlp21YhTNz/fff7+IUeciFegi6t1pP0UHJkZE9PX1Nbq2DYeEeicrSYlMspKUyCQrSYlMspKUyCQrSYlas7qg6aGJtdbFlZWVIkaVTVpdMDIygq9J7bK0H22tVZaq0lSBPXz4MI6nlQxUgd5Jh9q9C3TQJs03OjAxImJxcbGI0X60tXlIB3XSyhea77XVOLRyh2LHjx/H8ePj40WM3n+t5Xzfvn0Y70beyUpSIpOsJCUyyUpSIpOsJCXqucJXrUhExQUqfK2urjYePzQ0VMSoHXFsbAxfk4pMVMT47rvvcHzTQxtp39oILm7QZ6odzthLrYvdoDY3qTWV9iquHfJJ+8QeOnSoiNG/dwQf6Elzltq46YDRCN7jdnNzs4jV5uYnn3xSxKjIRYeJ9hrvZCUpkUlWkhKZZCUpkUlWkhL1XOGrtvcqFRfW19eLGD3cj+BOKjpEjgpfo6Oj+JrUhXb79u1GsYiIx48fN3pPNVTkoi6wXuqe6UVUVKW5SYWjCJ7bVJSs7SdL3WFzc3NFjPaIvXbtGr7mt99+i/Gfos8ewUU6+m21gXeykpTIJCtJiUyykpTIJCtJiUyykpSo51YXdNK6SPtb1qqdVJmlGK1CqJ3oOTs7W8SoKnv16lUcTy3AH330URGbmJjA8RcvXixitDqj9p3aVvt20CoTqvjTdbVraXVCbT9aao2la2m+fvHFF/ia1AJMey3THIzg30xtHvY672QlKZFJVpISmWQlKZFJVpIS9Vzhq4YKOlTkqrXl0rW0nysVDKgwEcH7gH755ZdFrNZWS4W3U6dOFbFaMa+thYReQwdVDg4OFjHaKziCDyOkfYmpGBbB84veE71mrRhHreS0b+3p06dxPBVrqajchuKrd7KSlMgkK0mJTLKSlMgkK0mJWlP4osMA6RA2ergewQUxKgQsLCwUsenpaXxNKohRpwwVISIixsfHixgVEqgYFsGH7dHfakNxoZvt3Vv+zI4dO1bEzp49i+Obdi7Oz8/jeLqWYjRfqIsrIuK9994rYtTd9etf/7rxeCoG0nfXa7yTlaREJllJSmSSlaREJllJSmSSlaREPVe6q1XCadXAyMhIEaOKfUTzlQQU29jYwNekSj6dDHvy5Ekc/+mnnxaxK1euFLEzZ87g+MOHDzd6T3o7anOT/s1pbl64cAHHU3s0raaprQSg1Qk0vr+/v4jR+4yImJqaKmI0N2srX+h1qY2c3mev6f1PIEldzCQrSYlMspKUyCQrSYlaU/iih+a0D2etuEDFq6btjJubm/ia1NY7NjZWxGqHzf3yl79sFKsV8/r6+oqYbbXbjwpfVJSsFYloblORq9be/eTJkyJG7apHjx4tYtT+GhExOTlZxGhuU6tsBH+mNrTQEu9kJSmRSVaSEplkJSmRSVaSEvXck+ZOumpoz0467C2CD4yjIhEVLFZWVvA1h4aGihh1d9UKXx9//HERo+IIvacI/k4scm0/6lqiDsXaQYpNO7E+/PBDHE8HetI8oP1ka4UrupY+U62YRX+/rXPTO1lJSmSSlaREJllJSmSSlaREJllJSrSL9qr8f175H7sJnTb77NmzIra2tobjl5aWitjc3FwRm5mZKWK1/WQHBgaKGLUjTkxM4HiqIFNVl1YRRHBVuwsquO/8DfxX183t2m+R5jathqHrXhX/KZovtf2HKd6GvV/fEM7tHf+tSFImk6wkJTLJSlIik6wkJWpN4Ys+Bz3wp/1gIyKeP39exGif2K2trSJGRYgILg7QHrO072sEF7SoTbHHCg4WvtRWFr4kabuZZCUpkUlWkhKZZCUpUWsKX0110lVDsdd8X6/VSRdWl3Zsvalu+QCtm9t65yx8SdJ2M8lKUiKTrCQlMslKUiKTrCQl2nGrC961TlYntGAlAemWD+Xc1tvm6gJJ2m4mWUlKZJKVpEQmWUlK9LrClyTpDXgnK0mJTLKSlMgkK0mJTLKSlMgkK0mJTLKSlMgkK0mJTLKSlMgkK0mJTLKSlMgkK0mJTLKSlMgkK0mJTLKSlMgkK0mJTLKSlMgkK0mJTLKSlMgkK0mJTLKSlMgkK0mJTLKSlMgkK0mJTLKSlMgkK0mJTLKSlMgkK0mJTLKSlMgkK0mJ9r7mv/+4Le9ih/vxR/6af/jhhyL28uXLIra1tYXjNzY2Gl9L9u3bV8QOHTpUxPr6+nD8/v37Kbyr8RvI5dzW24Zz2ztZSUpkkpWkRCZZSUq0q/Y88L98bvUTr/m+3upr7tpVPuKhGD27jeDnt7Vrm76v3bvL/y/v3cuP9una8Jls12paA4jgudF0vkRE7Nmzp/G1PcRnspK03UyykpTIJCtJiUyykpTIJCtJiVqzuoAqo52sBGhate/kNZuO7+Q1qQJL7712LVV1a+Obvq/a+NrlnVycqGfmdtM5U1sJQPFnz54VMeoG/P7775u8xYjgDsFaN+CBAwcaxTqcW++aqwskabuZZCUpkUlWkhKZZCUp0eu2Onyn6OF+rS30+fPnjWIvXrzA8RSngkEnhSt6TYp1stUhFQKo4BDB2xL29/c3Ht/S1seuVZsHTef25uYmjl9dXS1ijx8/LmIrKytF7MmTJ/iaVNAaHh4uYqOjozj+2LFjRYzas2st273EX4wkJTLJSlIik6wkJTLJSlKirn6qTIUAeuAfEbG+vl7E6KE9FQFq11IhgYpRtfdE3TJNi2ERXHijYtTQ0BCOHxsbK2LHjx8vYlSwiODiBhXJLIb9r1rhqmkBt5O5TYWrxcVFHH/v3r0idv/+/SK2sLBQxGodXwMDA0Xs9OnTRezSpUs4nubRwYMHi5iFL0nSK5lkJSmRSVaSEplkJSmRSVaSEnV16Y6qsrQPZgS3BM7NzRWx6elpHE8V2I2NjSJGFf9aOyPtz0mfqba6gKrNtLpgZGQEx58/f76IXb58uYjVKrhUAW5DtbdTTVcH1P4dac7S3Kq1sD58+LCI3blzp4jNzs7i+JmZmSJGvw26jlY2REQcOXKkiC0tLeG1hFbEHD16tIjRHrO9xjtZSUpkkpWkRCZZSUpkkpWkRF1TxWh6MFyt8EUP6Ofn54sYFQwiuCD29OnTRu+Jim618VS4Wl5exvH0urSf7NTUFI4nVFygvT1r17ZZba9iKmhRUXNtbQ3HU7srFbOo1TWCi1QPHjwoYtRqW/v79Dug90RzOIJbrmluU2t3BLe31wqHvc47WUlKZJKVpEQmWUlKZJKVpERdU/giVIioFScIFYlqe37SQ/um3U21rhTqmKKCSW3PTipYdHIQ46lTp4rYo0ePGr2nCN4nti17x3bSeUcdfdTdVOu4+vbbb4vY3bt3ixj920Q03xe59tvYv39/EaOOK+pCqxWaac7Qd1LrYqO/VdtPt9e14xcjSV3KJCtJiUyykpTIJCtJiUyykpSoq1cXUCWbKqUREYcPHy5i4+PjRay29+vg4GCja6naWqvAEqq20iqE2uvS+Np30nR1Bq2siODVGRTrRZ2sLqB2WTrZ9fbt2zj+1q1bRYzaYmurPEh/f38RoxNkI3jv18nJySJGLbA3b97E16y18P5UJ6sTaHUBtbFH1OdsN/JOVpISmWQlKZFJVpISmWQlKVFXF77o4fbBgwfx2uHh4SJGBSVqJ4zgfTOpENLJw3kqMtG+tbWH+NRuS3t+1j4TFTzoe6IiyqveV1vV2pOb7idb23uV5gd9t4cOHcLxVJSlQu/o6CiOpwIwFVCpcFcrqlKrMP02a62+9J100kbfS3PTO1lJSmSSlaREJllJSmSSlaREXVP4ok4ierhd28+0aZGsdjhg031a6UF8rWBChSsqJFD3UAQfBEkFAyqMRHDha2RkpIjVOoV6qbjwNtTmFu0r3MncosITFStrBUjqxDpx4kQRqx2ISf++1MVGv8HaHre01zHNzU6KiU2LYb3GO1lJSmSSlaREJllJSmSSlaREJllJStQ1qwuaqu1nSi20tX1aSa01tolaBbTpfri190nXUjtlrapNKwno2r6+Phzf9LTetqjNrU5WEhBaHUBzo7ZKhFYi0IqBWss5rRJZWVkpYvQ+a62+NDeprfhN22rbwDtZSUpkkpWkRCZZSUpkkpWkRDursvEKb9JCWiuaUVvt6upqEVtfX8fxVAigQkRtH1E6LK/pvrttR0WuWqGPCoNUVKSiZE0neyXTvw+911pbMM1PGk/fSW1uNz1QtNZWS3+r9v57XTs/lSR1CZOsJCUyyUpSIpOsJCWy8NUhepBPD/wjIh4/flzE7t+/X8SWlpZwPB3WR8URKsJERJw8ebKIUXFmp+0bG9F8/+II/s47KRY2LfLUCj+1TrSfqhWZCB0IurGxUcRqRVm6lopktc/0psW8XtL7n0CSuphJVpISmWQlKZFJVpISWfh6BSokUMHgyZMnOP7BgwdF7O7du0WsdlgdbR1HHVt0qF4EH6xHh/XtxMIXqRWY6Pvppe+MOgepWEvzrVbUbdpFVuuio4IWvc/a9of022xaINxu3slKUiKTrCQlMslKUiKTrCQlMslKUiJXF7wCVTZpj9jFxUUc/5///KeIPXz4sIjVVifQSgBqoaV9YyMijhw5UsToALw2tC6qjuYxrQ6glQS16j7FO1ldQG21tGKjW1cMdMJflyQlMslKUiKTrCQlMslKUiILX69ALbR0ECK1z0ZEzM7ONhpfe7hPhSvaI3ZsbAzHDwwMFLFeagdVZ2r7yVKRivYqpr1jqdW2Nn5wcLCIHThwAMfT3KRi2JvusdsNvJOVpEQmWUlKZJKVpEQmWUlKtOMKX50cNkcP9xcWForYrVu3cPzMzEwRo8MVDx06hOOpu+u9994rYrRvbITdXTtNbW6/ePGiiNFBiCsrK41iEVxM6+vrK2J0cGcEdzNS4auXClw1/uIkKZFJVpISmWQlKZFJVpISmWQlKVGrVxdQtZX20YzgvTTpFNnp6elGsQjeZ5ZWLIyPj+N42ieWYtR+G9Heaq06m9u0BzLtYUwxGhvB7bI0D2tzk1bU0N6zbZiv3slKUiKTrCQlMslKUiKTrCQlanXhq+lhcRERS0tLRezu3btF7MaNG0Vsfn4eX3Nzc7OIDQ8PFzFqlY2IOHfuXBEbHR0tYrU9O907tr2orZXaZyN4HlJ7OP0Gaod8Uns2FbMsfHknK0mpTLKSlMgkK0mJTLKSlKg1hS/qgKFCwNraGo6nvV+vXr1axKi7i/aIjeD9NekgxA8++ADHU3fX0NBQEaPOroh2FA3Ems73CC5eUbGWYrXfCxVwae/YWuHr4MGDRaytex2381NJUpcwyUpSIpOsJCUyyUpSIpOsJCXqudUFnZzI+fTp0yL24MEDHP/1118XsWvXrhWxe/fuve4t/p+JiYkidubMmSJ24cIFHH/8+PEiRi20ba3Kqo7aamt7vy4vLxcx+h3Mzs4WMfoNRfAeyBmrC9qwQsZfpyQlMslKUiKTrCQlMslKUqKeK3zRA/8IfuhPe2ZSMSuCC1/fffddEaMWxdp+sKdOnSpiVOSiVtuIiIGBgSLm4Yg7DxV76XdA+8ZG8IGeTfeOrRWaaW5SkYuui+C9Y9tawG3np5KkLmGSlaREJllJSmSSlaREXV34etM9M+/fv1/Erl+/juNv3rxZxObm5orYsWPHitjY2Bi+Jh2EePr06SJ29OhRHL9///4iZpFr52la+Hr+/DmOp6Iwjaei6uDgIL4mHehJe8z29/fj+LYWucjO+aSS9A6YZCUpkUlWkhKZZCUpkUlWkhK1ZnXByspKEbtz504Rq+0HS3tpUiWfWmBpxUBExPnz54sY7RFLe2tGROzZs6fRe1K70b85xahVNYJPOKb9YK9cuVLEaqsAaG5PTU0VsUOHDuH4nTS3vZOVpEQmWUlKZJKVpEQmWUlK1DWFLypyvXz5sojVDnZ7+PBhEaMiV+0gRWo9pDZBOhyR2mdr11KbIrUzRrS3EKA3R4WjWgsrtX1fvHix0Xhq7Y6IOHv2bBGj+d7JfrJtne/eyUpSIpOsJCUyyUpSIpOsJCXqmsIXocLX2toaXkt7v87Pzxex5eVlHE8P4ukgRIrVDkKkTpud9MBfbwfND+rEqnUO0t6v9JqTk5NFrFb4oqIw7YtcG+9+spKkt8IkK0mJTLKSlMgkK0mJTLKSlKirVxdQq+3W1hZeS6sOKLa5uYnjqTLbtK2WTrCNiDhw4EARcyWB3gaqztcq+bTKheZhX19f47/fdG7TbziCT8ttum9ur/FOVpISmWQlKZFJVpISmWQlKdGu2oNpSdKb805WkhKZZCUpkUlWkhKZZCUpkUlWkhKZZCUp0f8AMQ4gwHT0vCMAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#Simple linear classifier\nclass LinearClassifier(nn.Module):\n    \n    def __init__(self,zdim):\n        super().__init__()\n        self.fc1 = nn.Linear(zdim,10) #As 10 classes for mnist\n        \n    def forward(self,x):\n        x = cast(self.fc1(x),Tensor) #so we have to use cross entropy loss. cast is because using old version fastai \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-09-11T07:07:52.998439Z","iopub.execute_input":"2022-09-11T07:07:53.008979Z","iopub.status.idle":"2022-09-11T07:07:53.033612Z","shell.execute_reply.started":"2022-09-11T07:07:53.008937Z","shell.execute_reply":"2022-09-11T07:07:53.032452Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Train Classifier on encoder(mnist) for (at the moment) one epoch\n\nfastai_encoder.eval()\n\nzdim=1024 #see above\nhead = LinearClassifier(zdim=zdim)\ndevice='cuda'\nhead.to(device)\noptimizer = torch.optim.Adam(head.parameters())\ncriterion = nn.CrossEntropyLoss()\n#EPOCHS=100\n\nfor epoch in range(100):\n    for x,y in dls.train:\n        #break \n        #b = dls.train.one_batch() #Seems need dls[0] or dls.train for training ... dls[1] is validation see here https://docs.fast.ai/data.core.html#DataLoaders.__getitem__\n        #x,y = b[0],b[1]\n\n        loss = criterion(head(fastai_encoder(x)),y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        #print(loss)\nprint('done')\n        ","metadata":{"execution":{"iopub.status.busy":"2022-09-10T09:31:01.805981Z","iopub.execute_input":"2022-09-10T09:31:01.806407Z","iopub.status.idle":"2022-09-10T09:31:55.337124Z","shell.execute_reply.started":"2022-09-10T09:31:01.806365Z","shell.execute_reply":"2022-09-10T09:31:55.335118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test result of above cell on the validation set - assumes that batch size of valid-dataloader is = number of valid samples                                        \n\n# print('The validation batch size is: {} '.format(dls.valid.bs))\n# input()\n\n#b = dls.valid.one_batch()\n\nfastai_encoder.eval()\n\nnum_correct=0\nfor x,y in dls_new.valid:\n    ypred = head(fastai_encoder(x))\n    correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n    num_correct += correct.sum()\nprint(num_correct/len(dls_new.valid_ds))\n\n#0.9168 - 400 epochs, poly_sinusoid (need to uncomment random_quintic top part)\n#quite good results on only 400 epochs. ","metadata":{"execution":{"iopub.status.busy":"2022-09-10T09:31:55.339743Z","iopub.execute_input":"2022-09-10T09:31:55.340144Z","iopub.status.idle":"2022-09-10T09:32:50.490006Z","shell.execute_reply.started":"2022-09-10T09:31:55.340105Z","shell.execute_reply":"2022-09-10T09:32:50.488756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Results for poly_sinusoid - see above for the present implementation of quintic/sinusoid/poly_sin \n\nBase HPs as before: ts=512,bs=256, ps=hs=500,pp=1, learn_epochs=1000, tune_epochs=100.\n\n**Run_1: 0.9294, Run_2: 0.9181, Run_3: 0.9233, Run_4: 0.9253, Run_5:0.9192,Run_6: 0.9243  \nMean: 0.9233**\n\nComments: This is with poly_sinusoid implemented as above (for this commit). This is best so far (but basically equal results to \"random_quad_new2\" -> see the cell below)\n\n","metadata":{}},{"cell_type":"markdown","source":"Further results for Quad_Normal - experimenting to find best polynomial\nBase HPs are: ts=512,bs=256, ps=hs=500,pp=1, learn_epochs=1000, tune_epochs=100\nSpecific HPs: power = Unif(1,3), coeff2 = N(0,1), coeff1=N(1,0.2)  \nRun_1: 0.9193, Run_2: 0.9105.   After two runs average is basically same as below average. So, let's try varying specific HPs  \n\nNamely, let's make power Unif(1/3,2.5) instead of Unif(1,3). Keep everything else same. \nSpecific HPs: power = Unif(1/3,2.5), coeff2 = N(0,1), coeff1=N(1,0.2)  \nRun_2: 0.9057 (bit worse than above)  \n\nLet's make power=max(0.1,N(2,0.25))\n\nRun_2: 0.8854 (definitely worse than above)\n\n**NEW random sample**\n\nSpecific HPs: power = Unif(1,2.5), coeff2 = N(0,1), coeff1=N(1,1)  \n**Run_1: 0.9210, Run_2: 0.9161, Run_3: 0.9184, Run_4: 0.9233, Run_5: 0.9263\nAverage: 0.92102**\n\nComments: See random_quad_new2 above (this was the function used)","metadata":{}},{"cell_type":"markdown","source":"Further results for MNIST: Quad_normal seems slightly better\n\n\nFirst the hps are:\n\nHPs are: ts=512,bs=256, ps=hs=500,pp=1, learn_epochs=1000, tune_epochs=100, std=0.7. Note: std for Quad_normal=std=0.7 or 0.2. Not actually sure here. \n\nImp note: since we split with 0.5 to training and validation, the training set size is actually 256 (this is a \"bug\" with what we have been doing...)\n\nSo we are using a training set of 512, batch size of 256, (to try and make it \"harder\" so we can actually discriminate better between the models / see if there is actually a difference). Also increased latent size to 500, since from the paper, BT requires large latent dimension to work well.  1000 learn epochs and 100 tune epochs.\n\n**BT, run_1: 0.8864, run_2: 0.8950, run_3: 0.9053, run_4: 0.9049, run_5: 0.9033\nQuad_normal, run_1: 0.9103,run_2: 0.9075  run_3: 0.9205, run_4: 0.9081, run_5: 0.9313**  \n\nComments: \n\nAfter 5 runs, BT mean performance was 0.89898 with SD=0.008181 and Quad_normal was 0.91554 with SD=0.010252. Quad_normal is 1.018% better and outperformed BT on each run\n\nValidation loss on Quad_normal run_2 jumped from ~25 on prior epochs to 78.8 on last - still did a touch better than BT anyway.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"Background we are performing ablations on the Barlow twins loss function: Instead of the $\\operatorname{Corr}(z_{i}^A,z_{j}^B)=0$ constraints, we \nhave a constraint $\\operatorname{Corr}(z_{i}^A,p(z_{j}^B))=0$, where $p$ is a random polynomial (sampled for each batch). Motivation: The $\\operatorname{Corr}(z_{i}^A,z_{j}^B)=0$, constraint in BT is a redundancy reduction term. Really want these terms to be statistically independent, not just uncorrelated. It is a theorem that if $\\operatorname{Corr}(h(X),h(Y))=0$ for all $h$ in a suitable class of functions (e.g. continuous functions) THEN $X$ and $Y$ are independent.\n\nSetup: there are two steps, a self supervised phase (with no labels) and a supervised phase (to test the quality of the representation learned): Step 1 - the SSL phase:  We train BT (and the modified BT) on 256 unlabelled MNIST samples for 1000 epochs, with a latent dimension size of 500. Step 2: Then we take the frozen representation learned, and fine tune a linear classifier on top of it (using the same 256 samples - this time with the labels).  i.e. we train a linear classifier on a frozen 500 dimensional input, which is the latent representation learned through the self supervised learning procedure. From the point of view of the second step, we are just training a linear model with a 500 dimensional input, and ten output categories. After the linear model is trained, we evaluate it on remaining ~ 59k MNIST samples for accuracy. We repeat this whole procedure 5 times (with different random 256 training samples each time).\n\nLast week kept experimenting with ways of sampling $p$. Have found that low degree works ok, higher degree degrades performance. We sample $p$ according to: $ax + bx^2$, where $a \\sim \\mathcal{N(1,0.2)}$ and $b \\sim \\mathcal{N(0,1)}$. So a typical sample might look like: $p(x)=1.18x + 1.7x^2$\n\nWith this setup, results from the 5 runs (different 256 samples for each run_i, and trained BT and Modified on these samples)\n\nBT, run_1: 0.8864, run_2: 0.8950, run_3: 0.9053, run_4: 0.9049, run_5: 0.9033\n\nModified BT, run_1: 0.9103,run_2: 0.9075  run_3: 0.9205, run_4: 0.9081, run_5: 0.9313\n\nComments: Mean performance of BT is 89.90% and Modified is 91.55%. Modified beat BT on each run, with the biggest gap being 90.33% vs 93.13%.\n\nWhen tried sampling a larger degree polynomial, even degree 3 causes performance to degrade. When tried sampling $p$ from some other class of continuous functions, e.g. sinusoids, performance degraded. \n\n** Really want a more principled way of sampling $p$ ** \n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"Further results for MNIST:\n\nBackground we are performing ablations on the Barlow twins loss function: Instead of the $\\operatorname{Corr}(z_{i}^A,z_{j}^B)=0$ constraints, we \nhave a constraint $\\operatorname{Corr}(z_{i}^A,p(z_{j}^B))=0$, where $p$ is a random polynomial (sampled for each batch). Motivation: The $\\operatorname{Corr}(z_{i}^A,z_{j}^B)=0$, constraint in BT is a redundancy reduction term. Really want these terms to be statistically independent, not just uncorrelated. It is a theorem that if $\\operatorname{Corr}(h(X),h(Y))=0$ for all $h$ in a suitable class of functions (e.g. continuous functions) THEN $X$ and $Y$ are independent.\n\n\nBaseline: Train BT on 1024 (unlabelled) MNIST samples (around 1.67% of the available training data), to learn a representation (100 dimensional). Then take the frozen representation, and on the same samples train a linear classifier head (with the labels). Evaluate on ~58k MNIST samples. Result: 92.91% accuracy\n\nModified method: After experimentation, best result so far was sampling $p$ as $p(x)=\\frac{1}{2} x^2$ with probability $0.25$ or $p(x)=x$ with probability $0.75$. With same procedure as above, result: 93.44% accuracy. A tiny bit better than 92.91%, but possibly not statistically significant difference.   \n\nUnfortunately, gap between results from last week closed as trained for more epochs (1000). Tried different ways of sampling $p$ between batches, e.g. as a moderate degree polynomial with uniformly random weights $Unif[-1,1]$ but couldn't get this to work - it degraded performance. Conclusion: Even though modified method is motivated, it may not improve on BT for whatever reason... However, since a fairly hacky way of sampling $p$ does work at least as well (actually slightly better) in experiments so far, going to continue experimenting with ways of sampling $p$. Plan with this line of investigation: Keep experimenting, but don't spend 100% of time on it. Need to try using larger latent dimension, as BT tends to require large dimensionality to work (conversely to other SSL methods).\n\nAlso exploring alternative ablations of BT loss function. In BT the loss function depends on $C^{AB}$ the cross correlation matrix. Loosely speaking,$L_{BT}$  tries to make this correlation matrix equal to the identity.  It is natural to consider instead the autocorrelation matrices $C^{AA}$ and $C^{BB}$ and a loss function that makes the autocorrelation matrices equal. The idea behind this is that representations $Z^{A}$ and $Z^{B}$ of two distorted views of the same image, should have approximately equal correlations between variables. In order to do this, the representation has to learn to ignore the specific distortions applied to the image. Preliminary results slightly underperform BT. \n\nPlan for next week:\nKeep experimenting, but read more of the literature and explore other SSL papers\n\n\n","metadata":{}},{"cell_type":"markdown","source":"Ok let's be a little bit more systematic:\n\nLet's just compare BT to quadratic applied to one variable. i.e. $\\frac{1}{2} x^2$ and $y$. \nHyperparameters: ts=1024,bs=128, ps=hs=100,pp=0.25, learn_epochs=300, tune_epochs=100\n\nResults (different random ts each time, i.e. for each run)\n\nRun_1: BT=0.8784, QUAD_1var = 0.8633 (last validation loss was a bit high though)  \nRun_2: BT=0.8788, QUAD_1var = 0.8891 (opposite to above line - last validation loss dropped a lot compared to prior few)\nRun_3: BT=0.8695, QUAD_1var = 0.8589\n\nComments: Ok, this looks like typical variation. Sometimes BT a little better, sometimes quad a little better. On the other hand, validation loss fluctuates A LOT for quad - when it ended on a low value, it did better. So maybe we need to train for more epochs, i.e. \"to convergence\". \n\nSo, keep everything above the same, except train for 1k learn_epochs. Then get:  \nRun_1: BT=0.9291, QUAD_1var = 0.9344, QUAD_2var = 0.9324, New_LF=0.9128, New_LF_normorderflipped = 0.9198 (note that loss started increasing unnaturally at the end - may need to re-run this one)\nSo quad smidge better, but not clear this is statistically meaningful.\n\nComments: (After BT): the training loss goes down consistently, more and more slowly as training progresses. Validation loss trends down too, but with VERY large variance. Perhaps this suggests I need to train on a larger number of training samples for BT and instead evaluate by tuning on a small dataset. Training loss ended at 0.3, validation at 1.37 (ending validation loss was ok, but e.g. on the last few epochs had: 2.25,0.75,0.62,1.37; i.e a lot of variance). (After quad): Same comments as before. Validation loss on last few epochs: 0.78, 0.87, 0.9,0.89. (After QUAD_2var - i.e. everything same except we apply quadratic to both variables): Loss doesn't go down as much as for other two methods. Even more variance in CV loss. Last few terms: 3.66,3.51,0.84,0.99.)\n\nWhat I have learned: Need to train for longer (i.e. \"to convergence\"). \n","metadata":{}},{"cell_type":"markdown","source":"New model: (All hps same as above, diff random sample)\nRun_1","metadata":{}},{"cell_type":"markdown","source":"Preliminary results for MNIST:\n\nWe perform some ablations on the Barlow twins loss function: Instead of the $\\operatorname{Corr}(z_{1i},z_{2j})=0$ constraints, we \nhave a constraint $\\operatorname{Corr}(z_{1i},p(z_{2j}))=0$, where $p$ is a random polynomial (sampled for each batch). Motivation: The $\\operatorname{Corr}(z_{1i},z_{2j})$ constraint in BT is a redundancy reduction term. Really want these terms to be statistically independent, not just uncorrelated. It is a theorem that if $\\operatorname{Corr}(h(X),h(Y))=0$ for all $h$ in a suitable class of functions (e.g. continuous functions) THEN $X$ and $Y$ are independent. \n\nBaseline: Train BT on 1000 (unlabelled) MNIST samples (around 1.67% of the available training data), to learn a representation (125 dimensional). Then take the frozen representation, and on the same samples train a linear classifier head (with the labels). Evaluate on ~58k MNIST samples. Result: 73.27% accuracy\n\nModification: We take p to be a low dimensional polynomial. Then training modified BT, (MBT) on the same 1k MNIST samples as above, and evaluating on the remaining ~58k, we get 79.85% accuracy, which is larger than 73.27% for Barlow twins. As a point of comparison, if we train a linear classifier on the raw 28x28 pixels (instead of the frozen representation), accuracy is 60%, so as expected training a linear classifier on a learned representation is superior to training on the raw pixels.\n\nConcerns: Usually these is a mistake, especially when results are positive... Need to test everything carefully. Have been experimenting on MNIST for a while, so need to test on a different dataset, maybe CIFAR or miniImagenet. \n\n**Plan for next week or so**\n\n* Test above results more carefully by running several times (on different 1k samples each time), and try performing ablations similar to the BT paper. I think it is likely I have made several mistakes, as is typical..\n* Importantly: test the above loss function ablations on another dataset to MNIST. \n* Spend ~ 50% of time continuing to read literature. Especially want to read VICReg paper, which builds on BT paper\n* Need to improve Latex skills, and in particular learn how to create good graphics / visuals\n\n\n","metadata":{}},{"cell_type":"code","source":"#Current hacking:\nBaseline_BT=0.7983\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Just train a linear classifier (no encoder)\n# #Basically cell above but remove encoder and some re-shaping\nzdim=500 #see above\nhead = LinearClassifier(zdim=zdim)\nhead.to(device)\noptimizer = torch.optim.Adam(head.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n\nfor x,y in dls.train:\n    #break\n    #b = dls.train.one_batch() #see here https://docs.fast.ai/data.core.html#DataLoaders.__getitem__\n    #x,y = b[0],b[1]\n\n    x=x.view(bs,zdim)\n    x=cast(x, Tensor) #Have to do this when using old version of fastai for some reason...\n    \n    out = head(x)\n    loss = criterion(out,y)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n","metadata":{"execution":{"iopub.status.busy":"2022-09-05T01:57:43.524021Z","iopub.execute_input":"2022-09-05T01:57:43.524591Z","iopub.status.idle":"2022-09-05T01:57:44.708695Z","shell.execute_reply.started":"2022-09-05T01:57:43.524542Z","shell.execute_reply":"2022-09-05T01:57:44.705871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Test result of above cell, (i.e. just a linear classifier), on the validation set - assumes that batch size of valid-dataloader is = number of valid samples                                        \n# num_correct=0\n# for x,y in dls_new.valid:\n\n#     x=x.view(x.shape[0],zdim)\n#     x=cast(x, Tensor) #Have to do this when using old version of fastai for some reason...\n    \n#     ypred = head(x)\n#     correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n#     num_correct += correct.sum()\n    \n# print(num_correct/len(dls_new.valid_ds))","metadata":{"execution":{"iopub.status.busy":"2022-08-23T03:20:27.522639Z","iopub.execute_input":"2022-08-23T03:20:27.523131Z","iopub.status.idle":"2022-08-23T03:21:41.420888Z","shell.execute_reply.started":"2022-08-23T03:20:27.523080Z","shell.execute_reply":"2022-08-23T03:21:41.419308Z"},"trusted":true},"execution_count":null,"outputs":[]}]}