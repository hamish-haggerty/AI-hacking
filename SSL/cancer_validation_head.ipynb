{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamish-haggerty/AI-hacking/blob/master/SSL/cancer_validation_head.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqZPF94637Fk"
      },
      "source": [
        "# cancer_validation_ensemble\n",
        "\n",
        "> Purpose of this notebook is to do experiments on the head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gFWev-_Q37Fm"
      },
      "outputs": [],
      "source": [
        "#| default_exp cancer_validation_ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cat536_37Fn"
      },
      "source": [
        "Setup: Surely there is a way to get rid of having to put this cell everywhere. hmmm.\n",
        "\n",
        "Or we can just copy paste / delete this in and out when needed. Either way, getting close to a decent workable workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fO8vhi6b37Fn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4537f78f-6fcb-4e95-a6df-d52df7032baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#| hide\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "def colab_is_true():\n",
        "\n",
        "    try: \n",
        "        from google.colab import drive\n",
        "\n",
        "        return True \n",
        "    except ModuleNotFoundError:\n",
        "        return False\n",
        "\n",
        "def setup_colab():\n",
        "\n",
        "    drive.mount('/content/drive',force_remount=True)\n",
        "    #os.system('unzip -q \"/content/drive/My Drive/archive (1).zip\"')\n",
        "    os.system('git clone https://github.com/hamish-haggerty/cancer-proj.git')\n",
        "\n",
        "    os.chdir('cancer-proj')\n",
        "    \n",
        "    os.system('pip install .')\n",
        "    os.system('pip install -qU nbdev')\n",
        "    os.system('nbdev_install_quarto')\n",
        "\n",
        "    os.system('unzip -q \"/content/drive/My Drive/archive (1).zip\"') #does this work?\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    on_colab = colab_is_true()\n",
        "    if on_colab:\n",
        "        setup_colab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VNjMrD_W37Fo"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "from nbdev.showdoc import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1RZVlbHF37Fo"
      },
      "outputs": [],
      "source": [
        "#| export\n",
        "from fastai.vision.all import *\n",
        "from base_rbt.all import *\n",
        "from cancer_proj.cancer_dataloading import *\n",
        "from cancer_proj.cancer_metrics import *\n",
        "from cancer_proj.cancer_maintrain import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict_model(xval,yval,model,aug_pipelines_test,numavg=3):\n",
        "    \"Note that this assumes xval is entire validation set. If it doesn't fit in memory, can't use this guy\"\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    N=xval.shape[0]\n",
        "\n",
        "    scores=0\n",
        "    for _ in range(numavg):\n",
        "\n",
        "        scores += model(aug_pipelines_test[0](xval)) #test time augmentation. This also gets around issue of randomness in the dataloader in each session...\n",
        "\n",
        "    scores *= 1/numavg\n",
        "\n",
        "    ypred = cast(torch.argmax(scores, dim=1),TensorCategory)\n",
        "\n",
        "    correct = (ypred == yval)#.type(torch.FloatTensor)\n",
        "\n",
        "    #correct = (torch.argmax(ypred,dim=1) == yval).type(torch.FloatTensor)\n",
        "    num_correct = correct.sum()\n",
        "    accuracy = num_correct/N\n",
        "    \n",
        "    return scores,ypred,accuracy.item()"
      ],
      "metadata": {
        "id": "zRYDiC-ze-rH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN4Js6uo37Fq"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pp3x3wbL37Fq"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "#Since we have cloned repository and cd'd into it (and the data itself is not stored in the\n",
        "#repo) we need cd out of it, get the data, then cd back into the repo `cancer-proj`.\n",
        "#This is a bit annoying, can maybe remove this later\n",
        "if on_colab:\n",
        "    #os.chdir('..') #assumes we are currently in cancer-proj directory\n",
        "    train_dir = colab_train_dir\n",
        "    test_dir = colab_test_dir\n",
        "else:\n",
        "    train_dir = local_train_dir\n",
        "    test_dir = local_test_dir\n",
        "\n",
        "#define general hps\n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#bs=256\n",
        "#bs=698\n",
        "bs=256\n",
        "bs_tune=256\n",
        "size=128\n",
        "bs_val=174\n",
        "\n",
        "#get the data dictionary\n",
        "data_dict = get_fnames_dls_dict(train_dir=train_dir,test_dir=test_dir,\n",
        "                    device=device,bs_val=bs_val,bs=bs,bs_tune=bs_tune,size=size,n_in=3)\n",
        "\n",
        "#get the dataloaders\n",
        "dls_train,dls_tune,dls_valid = data_dict['dls_train'],data_dict['dls_tune'],data_dict['dls_valid']\n",
        "x,y = data_dict['x'],data_dict['y']\n",
        "xval,yval = data_dict['xval'],data_dict['yval']\n",
        "xtune,ytune = data_dict['xtune'],data_dict['ytune']\n",
        "vocab = data_dict['vocab']\n",
        "\n",
        "#If we want to write some tests (make sure the data is same every time etc):\n",
        "fnames,fnames_train,fnames_tune,fnames_valid,fnames_test = data_dict['fnames'],data_dict['fnames_train'],data_dict['fnames_tune'],data_dict['fnames_valid'],data_dict['fnames_test']\n",
        "\n",
        "test_eq(x.shape,xtune.shape)\n",
        "\n",
        "# if on_colab:\n",
        "#     os.chdir('cancer-proj')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PpIwqfu37Fr"
      },
      "source": [
        "## Load aug pipelines here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ntc4hMMj37Fr"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "aug_dict = create_aug_pipelines(size=size,device=device,Augs=BYOL_Augs,TUNE_Augs=TUNE_Augs,Val_Augs=Val_Augs)\n",
        "aug_pipelines = aug_dict['aug_pipelines']\n",
        "aug_pipelines_tune = aug_dict['aug_pipelines_tune']\n",
        "aug_pipelines_test = aug_dict['aug_pipelines_test'] "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optionally, display:"
      ],
      "metadata": {
        "id": "zlZuNHTW34iy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PP7Sp4P837Fr"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "#show_bt_batch(dls=dls_train,aug=aug_pipelines,n_in=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "foWFxkv_37Fr"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "#show_linear_batch(dls=dls_tune,n_in=3,aug=aug_pipelines_tune,n=2,print_augs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KAW1Mwwa37Fs"
      },
      "outputs": [],
      "source": [
        "#| export\n",
        "\n",
        "@patch\n",
        "def lf(self:BarlowTwins, pred,*yb): return lf_bt(pred,I=self.I,lmb=self.lmb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to run a few exploratory experiments. Based on the results, next is to run some systematic experiments, probably with W and B... Or final results..."
      ],
      "metadata": {
        "id": "uA_B-8T8-NpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "@patch\n",
        "@delegates(Learner.fit_one_cycle)\n",
        "def encoder_fine_tune(self:Learner, epochs, base_lr=2e-3, freeze_epochs=1, lr_mult=100,\n",
        "              pct_start=0.3, div=5.0, **kwargs):\n",
        "    \"Fine tuner to use with bt initial weights\"\n",
        "    \n",
        "    self.freeze() #freeze the resnet\n",
        "    self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs)\n",
        "    base_lr /= 2\n",
        "    #self.unfreeze() #don't unfreeze the resnet. We are fitting training the encoder head + projector\n",
        "    #self.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div, **kwargs)\n",
        "    self.fit_one_cycle(epochs, slice(base_lr, base_lr), pct_start=pct_start, div=div, **kwargs)\n",
        "\n",
        "    self.unfreeze() #We can unfreeze at the end"
      ],
      "metadata": {
        "id": "0q915iOR-gFj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write me"
      ],
      "metadata": {
        "id": "CKsB_xyHjcLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "class HeadEncoder(nn.Module):\n",
        "    \"Basic nonlinear \"\n",
        "    def __init__(self,resnet_encoder,device='cuda'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.resnet_encoder=resnet_encoder\n",
        "\n",
        "        self.head_encoder = sequential(nn.Linear(2048,2048),nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "                               nn.ReLU(inplace=True))\n",
        "        \n",
        "        self.device = torch.device(device)\n",
        "        self.to(self.device)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.resnet_encoder(x)\n",
        "        x=self.head_encoder(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def create_model(which_model,device,ps=8192,n_in=3):\n",
        "    print('inside create_model')\n",
        "\n",
        "    #pretrained=True if 'which_model' in ['bt_pretrain', 'supervised_pretrain'] else False\n",
        "\n",
        "    if which_model == 'bt_pretrain': model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
        "    \n",
        "    elif which_model == 'no_pretrain': model = resnet50()\n",
        "\n",
        "    elif which_model == 'supervised_pretrain': model = resnet50(weights='IMAGENET1K_V2')\n",
        "\n",
        "    #ignore the 'pretrained=False' argument here. Just means we use the weights above \n",
        "    #(which themselves are either pretrained or not)\n",
        "    encoder = get_resnet_encoder(model)\n",
        "    encoder = HeadEncoder(encoder,device='cpu')\n",
        "\n",
        "    model = create_barlow_twins_model(encoder, hidden_size=ps,projection_size=ps,nlayers=3)\n",
        "\n",
        "    if device == 'cuda':\n",
        "        model.cuda()\n",
        "        encoder.cuda()\n",
        "\n",
        "\n",
        "    return model,encoder\n",
        "\n",
        "bt_model,encoder = create_model(which_model='bt_pretrain',ps=8192,device=device)\n",
        "\n",
        "def my_splitter_bt(m):\n",
        "\n",
        "    return L(sequential(*m.encoder.resnet_encoder),sequential(m.encoder.head_encoder,m.projector)).map(params)\n",
        "\n",
        "test_eq(len(my_splitter_bt(bt_model)),2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g2RtinCF8uh",
        "outputId": "a3205179-3cba-4e9c-bd18-5e671e895b56"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Verify that splitter freezes expected part of model:\n",
        "\n",
        "# #test : manual. BT\n",
        "\n",
        "learn = Learner(dls_train,bt_model,splitter=my_splitter_bt,cbs=[BarlowTwins(aug_pipelines,n_in=3,lmb=1/8192,print_augs=False)])\n",
        "learn.freeze()\n",
        "print('resnet should be frozen, encoder head + projector unfrozen')\n",
        "learn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7dujr1ggO0-m",
        "outputId": "1d28c10f-4da4-453d-b1ee-6944c8c2730f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resnet should be frozen, encoder head + projector unfrozen\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BarlowTwinsModel (Input shape: 256 x 3 x 128 x 128)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     256 x 64 x 64 x 64  \n",
              "Conv2d                                    9408       False     \n",
              "BatchNorm2d                               128        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "MaxPool2d                                                      \n",
              "Conv2d                                    4096       False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 32 x 32 \n",
              "Conv2d                                    32768      False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 16 x 16 \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 8 x 8   \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    2097152    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 1 x 1  \n",
              "AdaptiveAvgPool2d                                              \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048          \n",
              "Flatten                                                        \n",
              "Linear                                    4196352    True      \n",
              "BatchNorm1d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 8192          \n",
              "Linear                                    16785408   True      \n",
              "BatchNorm1d                               16384      True      \n",
              "ReLU                                                           \n",
              "Linear                                    67117056   True      \n",
              "BatchNorm1d                               16384      True      \n",
              "ReLU                                                           \n",
              "Linear                                    67117056   True      \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 178,760,768\n",
              "Total trainable params: 155,305,856\n",
              "Total non-trainable params: 23,454,912\n",
              "\n",
              "Optimizer used: <function Adam at 0x7fa2826b0160>\n",
              "Loss function: <bound method BarlowTwins.lf of BarlowTwins>\n",
              "\n",
              "Model frozen up to parameter group #1\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - CastToTensor\n",
              "  - BarlowTwins\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We also need to edit main_train. Now the model is: resnet_encoder -> head_encoder -> projector or linear layer. Also need to edit the splitter fuction for fine tuning."
      ],
      "metadata": {
        "id": "-RdYwIMrIIhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All that changes here is the definition of our model in `fine_tune`, and we need a new splitter function.\n",
        "\n",
        "We tried just patching in new def of fine_tune, but since `create_model` defintion changed it fucked things up. \n",
        "\n",
        "Feels like this should be some kind of callback, written extensibly enough that you just just \"patch\" functions etc in..."
      ],
      "metadata": {
        "id": "0Qo0TxLpTWI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "class main_train:\n",
        "    \"\"\"Instantiate and (optionally) train the encoder. Then fine-tune the supervised model. \n",
        "    Outputs metrics on validation data\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 dls_train, #used for training BT (if pretrain=True)\n",
        "                 dls_tune , #used for tuning\n",
        "                 dls_valid, #used to compute metrics / evaluate results. \n",
        "                 xval, #currently `predict_model` below assumes this is entire validation / test data\n",
        "                 yval,\n",
        "                 aug_pipelines, #the aug pipeline for self-supervised learning\n",
        "                 aug_pipelines_tune, #the aug pipeline for supervised learning\n",
        "                 aug_pipelines_test, #test (or valid) time augmentations \n",
        "                 initial_weights, #Which initial weights to use\n",
        "                 pretrain, #Whether to fit BT\n",
        "                 num_epochs, #number of BT fit epochs\n",
        "                 numfit, #number of tune_fit epochs\n",
        "                 freeze_num_epochs, #How many epochs to freeze body for when training BT\n",
        "                 freeze_numfit, #How many epochs to freeze body for when fine tuning\n",
        "                 ps=8192, #projection size\n",
        "                 n_in=3, #color channels\n",
        "                 indim=2048, #dimension output of encoder (2048 for resnet50)\n",
        "                 outdim=9, #number of classes\n",
        "                 print_report=False, #F1 metrics etc\n",
        "                 print_plot=False, #ROC curve\n",
        "                 ):\n",
        "        store_attr()\n",
        "        self.vocab = self.dls_valid.vocab\n",
        "        self.device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "\n",
        "                \n",
        "                 \n",
        "\n",
        "                 #Soon we might want to save some models here:\n",
        "\n",
        "                 #if self.model_type == 'res_proj': test_eq(self.fit_policy,'resnet_fine_tune') #I THINK this is only viable option?\n",
        "                 #self.encoder_path = f'/content/drive/My Drive/models/baselineencoder_initial_weights={self.initial_weights}_pretrain={self.pretrain}.pth'\n",
        "                 #self.tuned_model_path = f'/content/drive/My Drive/models/baselinefinetuned_initial_weights={self.initial_weights}_pretrain={self.pretrain}.pth'\n",
        "\n",
        "    @staticmethod\n",
        "    def fit(learn,fit_type,epochs,freeze_epochs,initial_weights):\n",
        "        \"\"\"We can patch in a modification, e.g. if we want subtype of fine_tune:supervised_pretrain to be different\n",
        "        to fine_tune:bt_pretrain\"\"\"\n",
        "\n",
        "        if fit_type == 'encoder_fine_tune': #i.e. barlow twins\n",
        "\n",
        "            learn.encoder_fine_tune(epochs,freeze_epochs=freeze_epochs) \n",
        "\n",
        "        elif fit_type == 'fine_tune':\n",
        "            \n",
        "            #elif initial_weights == 'supervised_pretrain':\n",
        "            learn.linear_fine_tune(epochs,freeze_epochs=freeze_epochs) \n",
        "\n",
        "        else: raise Exception('Fit policy not of expected form')\n",
        "\n",
        "    def train_encoder(self):\n",
        "        \"create encoder and (optionally, if pretrain=True) train with BT algorithm, according to fit_policy\"\n",
        "\n",
        "        try: #get existing encoder and plonk on new projector\n",
        "            encoder = self.encoder\n",
        "            encoder.cpu()\n",
        "            bt_model = create_barlow_twins_model(encoder, hidden_size=self.ps,projection_size=self.ps,nlayers=3)\n",
        "            bt_model.cuda()\n",
        "\n",
        "        except AttributeError: #otherwise, create\n",
        "            bt_model,encoder = create_model(which_model=self.initial_weights,ps=self.ps,device=self.device)\n",
        "\n",
        "        if self.pretrain: #train encoder according to fit policy\n",
        "\n",
        "            learn = Learner(self.dls_train,bt_model,splitter=my_splitter_bt,cbs=[BarlowTwins(self.aug_pipelines,n_in=self.n_in,lmb=1/self.ps,print_augs=False)])\n",
        "            main_train.fit(learn,fit_type='encoder_fine_tune',\n",
        "                           epochs=self.num_epochs,freeze_epochs=self.freeze_num_epochs,\n",
        "                           initial_weights=self.initial_weights\n",
        "                          )\n",
        "            \n",
        "        self.encoder = bt_model.encoder\n",
        "\n",
        "    def fine_tune(self):\n",
        "        \"fine tune in supervised fashion, according to tune_fit_policy, and get metrics\"\n",
        "\n",
        "        #encoder = pickle.loads(pickle.dumps(self.encoder)) #We might want to pretrain once and fine tune several times (varying e.g. tune augs)\n",
        "\n",
        "        try: \n",
        "            encoder = self.encoder\n",
        "        \n",
        "        except AttributeError:\n",
        "            _,self.encoder = create_model(which_model=self.initial_weights,ps=self.ps,device=device)\n",
        "\n",
        "        #model = LM(self.encoder)\n",
        "        model = sequential(self.encoder,nn.Linear(2048,9))\n",
        "        \n",
        "        learn = Learner(self.dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "        #debugging\n",
        "        #learn = Learner(self.dls_tune,model,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "        main_train.fit(learn,fit_type='fine_tune',\n",
        "                       epochs=self.numfit,freeze_epochs=self.freeze_numfit,\n",
        "                       initial_weights=self.initial_weights\n",
        "                      ) #fine tuning (don't confuse this with fit policy!)\n",
        "        \n",
        "        #model.encoder=encoder\n",
        "        scores,preds, acc = predict_model(self.xval,self.yval,model=model,aug_pipelines_test=self.aug_pipelines_test,numavg=3)\n",
        "        #metrics dict will have f1 score, auc etc etc\n",
        "        metrics = classification_report_wrapper(preds, self.yval, self.vocab, print_report=self.print_report)\n",
        "        auc_dict = plot_roc(self.yval,preds,self.vocab,print_plot=self.print_plot)\n",
        "        metrics['acc'],metrics['auc_dict'],metrics['scores'],metrics['preds'],metrics['xval'],metrics['yval'] = acc,auc_dict,scores,preds,self.xval,self.yval\n",
        "  \n",
        "        #torch.save(model.state_dict(), self.tuned_model_path)\n",
        "        return metrics #\n",
        "\n",
        "    def __call__(self):\n",
        "\n",
        "        self.train_encoder() #train (or extract) the encoder\n",
        "        metrics = self.fine_tune()\n",
        "        \n",
        "        return metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "1C9RO65sIK7X"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to define the splitter function for the fine_tune part of main differently as well:"
      ],
      "metadata": {
        "id": "JEHA6-14QiXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_splitter(m):\n",
        "    print('inside new my_splitter')\n",
        "    return L(sequential(*m[0].resnet_encoder),sequential(m[0].head_encoder,m[1])).map(params)"
      ],
      "metadata": {
        "id": "FMwr-MngRaYP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # #Verify that splitter freezes expected part of model, from linear point of view:\n",
        "\n",
        "bt_model,encoder = create_model(which_model='bt_pretrain',ps=8192,device=device)\n",
        "model = sequential(encoder,nn.Linear(2048,9))\n",
        "test_eq(len(my_splitter(model)),2)\n",
        "test_eq(len(my_splitter_bt(bt_model)),2)\n",
        "\n",
        "learn = Learner(dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=aug_pipelines_tune,n_in=3)],wd=0.0)\n",
        "learn.freeze()\n",
        "print('resnet should be frozen, encoder_head + linear layer unfrozen')\n",
        "learn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gW5SiWd0PS9s",
        "outputId": "ea578615-9f80-40bd-998a-1dbdfff820a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside new my_splitter\n",
            "inside new my_splitter\n",
            "resnet should be frozen, encoder_head + linear layer unfrozen\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential (Input shape: 256 x 3 x 128 x 128)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     256 x 64 x 64 x 64  \n",
              "Conv2d                                    9408       False     \n",
              "BatchNorm2d                               128        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "MaxPool2d                                                      \n",
              "Conv2d                                    4096       False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 32 x 32 \n",
              "Conv2d                                    32768      False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 16 x 16 \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 8 x 8   \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    2097152    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 1 x 1  \n",
              "AdaptiveAvgPool2d                                              \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048          \n",
              "Flatten                                                        \n",
              "Linear                                    4196352    True      \n",
              "BatchNorm1d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 9             \n",
              "Linear                                    18441      True      \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 27,726,921\n",
              "Total trainable params: 4,272,009\n",
              "Total non-trainable params: 23,454,912\n",
              "\n",
              "Optimizer used: <function Adam at 0x7fa2826b0160>\n",
              "Loss function: <bound method LinearBt.lf of LinearBt>\n",
              "\n",
              "Model frozen up to parameter group #1\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - CastToTensor\n",
              "  - LinearBt\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment: Fine tune nonlinear head (no pretraining) with `fine_tune` instead of `linear_fine_tune`:"
      ],
      "metadata": {
        "id": "4JjTmZFjJvG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All we changed here is linear_fine_tune replaced by fine_tune"
      ],
      "metadata": {
        "id": "fX-MixSkLtnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "class tem_main_train:\n",
        "    \"\"\"Instantiate and (optionally) train the encoder. Then fine-tune the supervised model. \n",
        "    Outputs metrics on validation data\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 dls_train, #used for training BT (if pretrain=True)\n",
        "                 dls_tune , #used for tuning\n",
        "                 dls_valid, #used to compute metrics / evaluate results. \n",
        "                 xval, #currently `predict_model` below assumes this is entire validation / test data\n",
        "                 yval,\n",
        "                 aug_pipelines, #the aug pipeline for self-supervised learning\n",
        "                 aug_pipelines_tune, #the aug pipeline for supervised learning\n",
        "                 aug_pipelines_test, #test (or valid) time augmentations \n",
        "                 initial_weights, #Which initial weights to use\n",
        "                 pretrain, #Whether to fit BT\n",
        "                 num_epochs, #number of BT fit epochs\n",
        "                 numfit, #number of tune_fit epochs\n",
        "                 freeze_num_epochs, #How many epochs to freeze body for when training BT\n",
        "                 freeze_numfit, #How many epochs to freeze body for when fine tuning\n",
        "                 ps=8192, #projection size\n",
        "                 n_in=3, #color channels\n",
        "                 indim=2048, #dimension output of encoder (2048 for resnet50)\n",
        "                 outdim=9, #number of classes\n",
        "                 print_report=False, #F1 metrics etc\n",
        "                 print_plot=False, #ROC curve\n",
        "                 ):\n",
        "        store_attr()\n",
        "        self.vocab = self.dls_valid.vocab\n",
        "        self.device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "\n",
        "                \n",
        "                 \n",
        "\n",
        "                 #Soon we might want to save some models here:\n",
        "\n",
        "                 #if self.model_type == 'res_proj': test_eq(self.fit_policy,'resnet_fine_tune') #I THINK this is only viable option?\n",
        "                 #self.encoder_path = f'/content/drive/My Drive/models/baselineencoder_initial_weights={self.initial_weights}_pretrain={self.pretrain}.pth'\n",
        "                 #self.tuned_model_path = f'/content/drive/My Drive/models/baselinefinetuned_initial_weights={self.initial_weights}_pretrain={self.pretrain}.pth'\n",
        "\n",
        "    @staticmethod\n",
        "    def fit(learn,fit_type,epochs,freeze_epochs,initial_weights):\n",
        "        \"\"\"We can patch in a modification, e.g. if we want subtype of fine_tune:supervised_pretrain to be different\n",
        "        to fine_tune:bt_pretrain\"\"\"\n",
        "\n",
        "        if fit_type == 'encoder_fine_tune': #i.e. barlow twins\n",
        "\n",
        "            learn.encoder_fine_tune(epochs,freeze_epochs=freeze_epochs) \n",
        "\n",
        "        elif fit_type == 'fine_tune':\n",
        "            \n",
        "            #elif initial_weights == 'supervised_pretrain':\n",
        "            learn.fine_tune(epochs,freeze_epochs=freeze_epochs) \n",
        "\n",
        "        else: raise Exception('Fit policy not of expected form')\n",
        "\n",
        "    def train_encoder(self):\n",
        "        \"create encoder and (optionally, if pretrain=True) train with BT algorithm, according to fit_policy\"\n",
        "\n",
        "        try: #get existing encoder and plonk on new projector\n",
        "            encoder = self.encoder\n",
        "            encoder.cpu()\n",
        "            bt_model = create_barlow_twins_model(encoder, hidden_size=self.ps,projection_size=self.ps,nlayers=3)\n",
        "            bt_model.cuda()\n",
        "\n",
        "        except AttributeError: #otherwise, create\n",
        "            bt_model,encoder = create_model(which_model=self.initial_weights,ps=self.ps,device=self.device)\n",
        "\n",
        "        if self.pretrain: #train encoder according to fit policy\n",
        "\n",
        "            learn = Learner(self.dls_train,bt_model,splitter=my_splitter_bt,cbs=[BarlowTwins(self.aug_pipelines,n_in=self.n_in,lmb=1/self.ps,print_augs=False)])\n",
        "            main_train.fit(learn,fit_type='encoder_fine_tune',\n",
        "                           epochs=self.num_epochs,freeze_epochs=self.freeze_num_epochs,\n",
        "                           initial_weights=self.initial_weights\n",
        "                          )\n",
        "            \n",
        "        self.encoder = bt_model.encoder\n",
        "\n",
        "    def fine_tune(self):\n",
        "        \"fine tune in supervised fashion, according to tune_fit_policy, and get metrics\"\n",
        "\n",
        "        #encoder = pickle.loads(pickle.dumps(self.encoder)) #We might want to pretrain once and fine tune several times (varying e.g. tune augs)\n",
        "\n",
        "        try: \n",
        "            encoder = self.encoder\n",
        "        \n",
        "        except AttributeError:\n",
        "            _,self.encoder = create_model(which_model=self.initial_weights,ps=self.ps,device=device)\n",
        "\n",
        "        #model = LM(self.encoder)\n",
        "        model = sequential(self.encoder,nn.Linear(2048,9))\n",
        "        \n",
        "        learn = Learner(self.dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "        #debugging\n",
        "        #learn = Learner(self.dls_tune,model,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "        main_train.fit(learn,fit_type='fine_tune',\n",
        "                       epochs=self.numfit,freeze_epochs=self.freeze_numfit,\n",
        "                       initial_weights=self.initial_weights\n",
        "                      ) #fine tuning (don't confuse this with fit policy!)\n",
        "        \n",
        "        #model.encoder=encoder\n",
        "        scores,preds, acc = predict_model(self.xval,self.yval,model=model,aug_pipelines_test=self.aug_pipelines_test,numavg=3)\n",
        "        #metrics dict will have f1 score, auc etc etc\n",
        "        metrics = classification_report_wrapper(preds, self.yval, self.vocab, print_report=self.print_report)\n",
        "        auc_dict = plot_roc(self.yval,preds,self.vocab,print_plot=self.print_plot)\n",
        "        metrics['acc'],metrics['auc_dict'],metrics['scores'],metrics['preds'],metrics['xval'],metrics['yval'] = acc,auc_dict,scores,preds,self.xval,self.yval\n",
        "  \n",
        "        #torch.save(model.state_dict(), self.tuned_model_path)\n",
        "        return metrics #\n",
        "\n",
        "    def __call__(self):\n",
        "\n",
        "        self.train_encoder() #train (or extract) the encoder\n",
        "        metrics = self.fine_tune()\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    initial_weights = 'bt_pretrain'\n",
        "    pretrain=False\n",
        "    numfit=50\n",
        "    num_epochs='na'\n",
        "    freeze_num_epochs = 'na'\n",
        "    freeze_numfit=3\n",
        "\n",
        "    main = tem_main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "            aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "            initial_weights=initial_weights,pretrain=pretrain,\n",
        "            num_epochs=num_epochs,numfit=numfit,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "            print_report=True,\n",
        "                    )\n",
        "\n",
        "    metrics = main()\n",
        "    print(metrics['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xx-HO1ceK8GT",
        "outputId": "c402e3da-ec2f-405f-f0bb-2a53338c7077"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside new my_splitter\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.219589</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.995378</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.741916</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.827599</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.800118</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.783509</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.762727</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.724671</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.692689</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.651357</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.615676</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.585942</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.549648</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.516253</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.485829</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.461984</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.437892</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.417995</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.397737</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.380005</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.361929</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.346435</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.333813</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.324339</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.311985</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.303005</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.293182</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.281987</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.272695</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.263966</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.255928</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.246155</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.239147</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.231738</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.225237</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.219394</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.214070</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.208957</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.204279</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.199794</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.195381</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.190258</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.185481</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.180974</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.177934</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.174029</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.170409</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.166032</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.163284</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.159561</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.156575</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.153434</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.151083</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.46      0.65      0.54        20\n",
            "      basal cell carcinoma       0.57      0.65      0.60        20\n",
            "            dermatofibroma       0.75      0.79      0.77        19\n",
            "                  melanoma       0.31      0.20      0.24        20\n",
            "                     nevus       0.48      0.55      0.51        20\n",
            "pigmented benign keratosis       0.44      0.40      0.42        20\n",
            "      seborrheic keratosis       0.50      0.47      0.48        15\n",
            "   squamous cell carcinoma       0.46      0.30      0.36        20\n",
            "           vascular lesion       0.82      0.90      0.86        20\n",
            "\n",
            "                  accuracy                           0.55       174\n",
            "                 macro avg       0.53      0.55      0.53       174\n",
            "              weighted avg       0.53      0.55      0.53       174\n",
            "\n",
            "0.545976996421814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Still no good with nonlinear head."
      ],
      "metadata": {
        "id": "U62mPRWQQI82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Next, let's try adding the FastAI head to the end of a resnet.\n",
        "\n",
        "Note that for this to work we don't downsample, so create_resnet_encoder will have to be edited.\n"
      ],
      "metadata": {
        "id": "YUEbk-guQ59q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "#| export\n",
        "def get_resnet_encoder(model,n_in=3):\n",
        "    model = create_body(model, n_in=n_in, pretrained=False, cut=len(list(model.children()))-2)\n",
        "    #model.add_module('flatten', torch.nn.Flatten())\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model(which_model,device,ps=8192,n_in=3):\n",
        "    print('inside create_model')\n",
        "\n",
        "    #pretrained=True if 'which_model' in ['bt_pretrain', 'supervised_pretrain'] else False\n",
        "\n",
        "    if which_model == 'bt_pretrain': model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
        "    \n",
        "    elif which_model == 'no_pretrain': model = resnet50()\n",
        "\n",
        "    elif which_model == 'supervised_pretrain': model = resnet50(weights='IMAGENET1K_V2')\n",
        "\n",
        "    #ignore the 'pretrained=False' argument here. Just means we use the weights above \n",
        "    #(which themselves are either pretrained or not)\n",
        "    encoder = get_resnet_encoder(model)\n",
        "\n",
        "    model = create_barlow_twins_model(encoder, hidden_size=ps,projection_size=ps,nlayers=3)\n",
        "\n",
        "    if device == 'cuda':\n",
        "        model.cuda()\n",
        "        encoder.cuda()\n",
        "\n",
        "\n",
        "    return None,encoder\n",
        "\n",
        "\n",
        "class tem_main_train:\n",
        "    \"\"\"Instantiate and (optionally) train the encoder. Then fine-tune the supervised model. \n",
        "    Outputs metrics on validation data\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 dls_train, #used for training BT (if pretrain=True)\n",
        "                 dls_tune , #used for tuning\n",
        "                 dls_valid, #used to compute metrics / evaluate results. \n",
        "                 xval, #currently `predict_model` below assumes this is entire validation / test data\n",
        "                 yval,\n",
        "                 aug_pipelines, #the aug pipeline for self-supervised learning\n",
        "                 aug_pipelines_tune, #the aug pipeline for supervised learning\n",
        "                 aug_pipelines_test, #test (or valid) time augmentations \n",
        "                 initial_weights, #Which initial weights to use\n",
        "                 pretrain, #Whether to fit BT\n",
        "                 num_epochs, #number of BT fit epochs\n",
        "                 numfit, #number of tune_fit epochs\n",
        "                 freeze_num_epochs, #How many epochs to freeze body for when training BT\n",
        "                 freeze_numfit, #How many epochs to freeze body for when fine tuning\n",
        "                 ps=8192, #projection size\n",
        "                 n_in=3, #color channels\n",
        "                 indim=2048, #dimension output of encoder (2048 for resnet50)\n",
        "                 outdim=9, #number of classes\n",
        "                 print_report=False, #F1 metrics etc\n",
        "                 print_plot=False, #ROC curve\n",
        "                 ):\n",
        "        store_attr()\n",
        "        self.vocab = self.dls_valid.vocab\n",
        "        self.device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "\n",
        "                \n",
        "                 \n",
        "\n",
        "                 #Soon we might want to save some models here:\n",
        "\n",
        "                 #if self.model_type == 'res_proj': test_eq(self.fit_policy,'resnet_fine_tune') #I THINK this is only viable option?\n",
        "                 #self.encoder_path = f'/content/drive/My Drive/models/baselineencoder_initial_weights={self.initial_weights}_pretrain={self.pretrain}.pth'\n",
        "                 #self.tuned_model_path = f'/content/drive/My Drive/models/baselinefinetuned_initial_weights={self.initial_weights}_pretrain={self.pretrain}.pth'\n",
        "\n",
        "    @staticmethod\n",
        "    def fit(learn,fit_type,epochs,freeze_epochs,initial_weights):\n",
        "        \"\"\"We can patch in a modification, e.g. if we want subtype of fine_tune:supervised_pretrain to be different\n",
        "        to fine_tune:bt_pretrain\"\"\"\n",
        "\n",
        "        if fit_type == 'encoder_fine_tune': #i.e. barlow twins\n",
        "\n",
        "            learn.encoder_fine_tune(epochs,freeze_epochs=freeze_epochs) \n",
        "\n",
        "        elif fit_type == 'fine_tune':\n",
        "            \n",
        "            #elif initial_weights == 'supervised_pretrain':\n",
        "            learn.fine_tune(epochs,freeze_epochs=freeze_epochs) \n",
        "\n",
        "        else: raise Exception('Fit policy not of expected form')\n",
        "\n",
        "    def train_encoder(self):\n",
        "        \"create encoder and (optionally, if pretrain=True) train with BT algorithm, according to fit_policy\"\n",
        "\n",
        "        try: #get existing encoder and plonk on new projector\n",
        "            encoder = self.encoder\n",
        "            encoder.cpu()\n",
        "            bt_model = create_barlow_twins_model(encoder, hidden_size=self.ps,projection_size=self.ps,nlayers=3)\n",
        "            bt_model.cuda()\n",
        "\n",
        "        except AttributeError: #otherwise, create\n",
        "            bt_model,encoder = create_model(which_model=self.initial_weights,ps=self.ps,device=self.device)\n",
        "\n",
        "        if self.pretrain: #train encoder according to fit policy\n",
        "\n",
        "            learn = Learner(self.dls_train,bt_model,splitter=my_splitter_bt,cbs=[BarlowTwins(self.aug_pipelines,n_in=self.n_in,lmb=1/self.ps,print_augs=False)])\n",
        "            main_train.fit(learn,fit_type='encoder_fine_tune',\n",
        "                           epochs=self.num_epochs,freeze_epochs=self.freeze_num_epochs,\n",
        "                           initial_weights=self.initial_weights\n",
        "                          )\n",
        "            \n",
        "        self.encoder = bt_model.encoder\n",
        "\n",
        "    def fine_tune(self):\n",
        "        \"fine tune in supervised fashion, according to tune_fit_policy, and get metrics\"\n",
        "\n",
        "        #encoder = pickle.loads(pickle.dumps(self.encoder)) #We might want to pretrain once and fine tune several times (varying e.g. tune augs)\n",
        "\n",
        "        # try: \n",
        "        #     encoder = self.encoder\n",
        "        \n",
        "        # except AttributeError:\n",
        "        _,self.encoder = create_model(which_model=self.initial_weights,ps=self.ps,device=device)\n",
        "\n",
        "        #model = LM(self.encoder)\n",
        "\n",
        "        head = create_head(2048,9)\n",
        "\n",
        "        model = sequential(self.encoder,head)\n",
        "        \n",
        "        learn = Learner(self.dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "        #debugging\n",
        "        #learn = Learner(self.dls_tune,model,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "        main_train.fit(learn,fit_type='fine_tune',\n",
        "                       epochs=self.numfit,freeze_epochs=self.freeze_numfit,\n",
        "                       initial_weights=self.initial_weights\n",
        "                      ) #fine tuning (don't confuse this with fit policy!)\n",
        "        \n",
        "        #model.encoder=encoder\n",
        "        scores,preds, acc = predict_model(self.xval,self.yval,model=model,aug_pipelines_test=self.aug_pipelines_test,numavg=3)\n",
        "        #metrics dict will have f1 score, auc etc etc\n",
        "        metrics = classification_report_wrapper(preds, self.yval, self.vocab, print_report=self.print_report)\n",
        "        auc_dict = plot_roc(self.yval,preds,self.vocab,print_plot=self.print_plot)\n",
        "        metrics['acc'],metrics['auc_dict'],metrics['scores'],metrics['preds'],metrics['xval'],metrics['yval'] = acc,auc_dict,scores,preds,self.xval,self.yval\n",
        "  \n",
        "        #torch.save(model.state_dict(), self.tuned_model_path)\n",
        "        return metrics #\n",
        "\n",
        "    def __call__(self):\n",
        "\n",
        "        self.train_encoder() #train (or extract) the encoder\n",
        "        metrics = self.fine_tune()\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "def my_splitter(m):\n",
        "    print('inside new my_splitter')\n",
        "    return L(sequential(*m[0]),sequential(m[1])).map(params)\n"
      ],
      "metadata": {
        "id": "a6tstcpURQDp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "\n",
        "bt_model,encoder = create_model(which_model='bt_pretrain',ps=8192,device=device)\n",
        "head = create_head(2048,9)\n",
        "model = sequential(encoder,head)\n",
        "test_eq(len(my_splitter(model)),2)\n",
        "\n",
        "learn = Learner(dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=aug_pipelines_tune,n_in=3)],wd=0.0)\n",
        "learn.freeze()\n",
        "print('resnet should be frozen, fastai head unfrozen')\n",
        "learn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NKe-LgG_KkQC",
        "outputId": "e15b006a-b2cc-4dfd-85ee-9fa6e310abac"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside new my_splitter\n",
            "inside new my_splitter\n",
            "resnet should be frozen, encoder_head + linear layer unfrozen\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential (Input shape: 256 x 3 x 128 x 128)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     256 x 64 x 64 x 64  \n",
              "Conv2d                                    9408       False     \n",
              "BatchNorm2d                               128        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "MaxPool2d                                                      \n",
              "Conv2d                                    4096       False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 32 x 32 \n",
              "Conv2d                                    32768      False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 16 x 16 \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 8 x 8   \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    2097152    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 1 x 1  \n",
              "AdaptiveAvgPool2d                                              \n",
              "AdaptiveMaxPool2d                                              \n",
              "____________________________________________________________________________\n",
              "                     256 x 4096          \n",
              "Flatten                                                        \n",
              "BatchNorm1d                               8192       True      \n",
              "Dropout                                                        \n",
              "____________________________________________________________________________\n",
              "                     256 x 512           \n",
              "Linear                                    2097152    True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               1024       True      \n",
              "Dropout                                                        \n",
              "____________________________________________________________________________\n",
              "                     256 x 9             \n",
              "Linear                                    4608       True      \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 25,619,008\n",
              "Total trainable params: 2,164,096\n",
              "Total non-trainable params: 23,454,912\n",
              "\n",
              "Optimizer used: <function Adam at 0x7fa2826b0160>\n",
              "Loss function: <bound method LinearBt.lf of LinearBt>\n",
              "\n",
              "Model frozen up to parameter group #1\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - CastToTensor\n",
              "  - LinearBt\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we run experiment: BT initial weights and using a FastAI head"
      ],
      "metadata": {
        "id": "Kl1k83heUXL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights = 'bt_pretrain'\n",
        "pretrain=False\n",
        "numfit=50\n",
        "num_epochs='na'\n",
        "freeze_num_epochs = 'na'\n",
        "freeze_numfit=3\n",
        "\n",
        "main = tem_main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "    aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "    initial_weights=initial_weights,pretrain=pretrain,\n",
        "    num_epochs=num_epochs,numfit=numfit,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "    print_report=True,\n",
        "        )\n",
        "\n",
        "metrics = main.fine_tune()\n",
        "print(metrics['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "id5elUHKUcWB",
        "outputId": "8fc3b180-ef0b-4d95-b952-c3a61e9b7ffa"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside new my_splitter\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.443856</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.227248</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.990031</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.287078</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.251684</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.197474</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.153834</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.110263</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.069712</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.032485</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.988651</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.944109</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.909275</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.869956</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.838988</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.803806</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.771495</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.734926</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.700485</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.676485</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.645744</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.622283</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.597361</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.573413</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.549263</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.528713</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.508524</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.488431</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.469574</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.455518</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.439786</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.423967</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.411075</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.396451</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.384708</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.372198</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.362631</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.353027</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.343822</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.335550</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.328150</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.318144</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.309937</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.302191</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.293983</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.287151</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.282740</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.276911</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.270962</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.264378</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.261136</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.257494</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.252153</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.57      0.60      0.59        20\n",
            "      basal cell carcinoma       0.76      0.65      0.70        20\n",
            "            dermatofibroma       0.65      0.79      0.71        19\n",
            "                  melanoma       0.38      0.30      0.33        20\n",
            "                     nevus       0.50      0.50      0.50        20\n",
            "pigmented benign keratosis       0.53      0.50      0.51        20\n",
            "      seborrheic keratosis       0.44      0.47      0.45        15\n",
            "   squamous cell carcinoma       0.60      0.60      0.60        20\n",
            "           vascular lesion       0.82      0.90      0.86        20\n",
            "\n",
            "                  accuracy                           0.59       174\n",
            "                 macro avg       0.58      0.59      0.58       174\n",
            "              weighted avg       0.59      0.59      0.59       174\n",
            "\n",
            "0.5919539928436279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ok, nonlinear head really doesn't work, with the FT protocol, with BT weights. We haven't tried probing yet, but theory says that shouldn't work.\n",
        "\n",
        "#Seem best approach is just to add a linear head."
      ],
      "metadata": {
        "id": "3eAngU1xW9Rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final go: train head for 20 epochs, then unfreeze resnet for just 5 epochs"
      ],
      "metadata": {
        "id": "bHfUt1zuYKFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights = 'bt_pretrain'\n",
        "pretrain=False\n",
        "numfit=5\n",
        "num_epochs='na'\n",
        "freeze_num_epochs = 'na'\n",
        "freeze_numfit=20\n",
        "\n",
        "main = tem_main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "    aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "    initial_weights=initial_weights,pretrain=pretrain,\n",
        "    num_epochs=num_epochs,numfit=numfit,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "    print_report=True,\n",
        "        )\n",
        "\n",
        "metrics = main.fine_tune()\n",
        "print(metrics['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wV4RBK6LTYJh",
        "outputId": "de436098-99c2-4212-a5a1-b8033799b398"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside new my_splitter\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.444406</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.358700</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.249949</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.161808</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.057310</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.953972</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.853001</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.757501</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.677391</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.590446</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.520906</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.439672</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.379221</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.310718</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.246554</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.189535</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.135646</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.087088</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.038708</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.994535</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.366417</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.390759</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.377901</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.404624</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.399794</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.39      0.85      0.53        20\n",
            "      basal cell carcinoma       0.58      0.70      0.64        20\n",
            "            dermatofibroma       0.71      0.53      0.61        19\n",
            "                  melanoma       0.29      0.25      0.27        20\n",
            "                     nevus       0.42      0.40      0.41        20\n",
            "pigmented benign keratosis       0.27      0.15      0.19        20\n",
            "      seborrheic keratosis       0.25      0.33      0.29        15\n",
            "   squamous cell carcinoma       1.00      0.15      0.26        20\n",
            "           vascular lesion       0.68      0.75      0.71        20\n",
            "\n",
            "                  accuracy                           0.46       174\n",
            "                 macro avg       0.51      0.46      0.43       174\n",
            "              weighted avg       0.52      0.46      0.44       174\n",
            "\n",
            "0.4597701132297516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, doesn't work."
      ],
      "metadata": {
        "id": "vjpTCx5xZBYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ok, let's just try adding linear layer to BT backbone"
      ],
      "metadata": {
        "id": "y3HAbvLpg-3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All we do is uncomment one line in `create_model`, and edited the splitter:"
      ],
      "metadata": {
        "id": "vOQroyjKhfze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "\n",
        "def create_model(which_model,device,ps=8192,n_in=3):\n",
        "    print('inside create_model')\n",
        "\n",
        "    #pretrained=True if 'which_model' in ['bt_pretrain', 'supervised_pretrain'] else False\n",
        "\n",
        "    if which_model == 'bt_pretrain': model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
        "    \n",
        "    elif which_model == 'no_pretrain': model = resnet50()\n",
        "\n",
        "    elif which_model == 'supervised_pretrain': model = resnet50(weights='IMAGENET1K_V2')\n",
        "\n",
        "    #ignore the 'pretrained=False' argument here. Just means we use the weights above \n",
        "    #(which themselves are either pretrained or not)\n",
        "    encoder = get_resnet_encoder(model)\n",
        "    #encoder = HeadEncoder(encoder,device='cpu')\n",
        "\n",
        "    model = create_barlow_twins_model(encoder, hidden_size=ps,projection_size=ps,nlayers=3)\n",
        "\n",
        "    if device == 'cuda':\n",
        "        model.cuda()\n",
        "        encoder.cuda()\n",
        "\n",
        "\n",
        "    return model,encoder\n",
        "\n",
        "\n",
        "def my_splitter(m):\n",
        "    print('inside new my_splitter')\n",
        "    return L(sequential(*m[0]),sequential(m[1])).map(params)"
      ],
      "metadata": {
        "id": "AkRDnzD7hDEt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # #Verify that splitter freezes expected part of model, from linear point of view:\n",
        "\n",
        "bt_model,encoder = create_model(which_model='bt_pretrain',ps=8192,device=device)\n",
        "model = sequential(encoder,nn.Linear(2048,9))\n",
        "learn = Learner(dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=aug_pipelines_tune,n_in=3)],wd=0.0)\n",
        "learn.freeze()\n",
        "print('resnet should be frozen, then should just have unfrozen linear layer')\n",
        "learn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7Q0__sZwhvMX",
        "outputId": "e1cf2681-fb65-4003-b414-02e8b2b7a4b6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside new my_splitter\n",
            "resnet should be frozen, encoder_head + linear layer unfrozen\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential (Input shape: 256 x 3 x 128 x 128)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     256 x 64 x 64 x 64  \n",
              "Conv2d                                    9408       False     \n",
              "BatchNorm2d                               128        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "MaxPool2d                                                      \n",
              "Conv2d                                    4096       False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 32 x 32 \n",
              "Conv2d                                    32768      False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 16 x 16 \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 8 x 8   \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    2097152    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 1 x 1  \n",
              "AdaptiveAvgPool2d                                              \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048          \n",
              "Flatten                                                        \n",
              "____________________________________________________________________________\n",
              "                     256 x 9             \n",
              "Linear                                    18441      True      \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 23,526,473\n",
              "Total trainable params: 71,561\n",
              "Total non-trainable params: 23,454,912\n",
              "\n",
              "Optimizer used: <function Adam at 0x7fbc7740a0d0>\n",
              "Loss function: <bound method LinearBt.lf of LinearBt>\n",
              "\n",
              "Model frozen up to parameter group #1\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - CastToTensor\n",
              "  - LinearBt\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Experiment: Linear layer. Comparing to with nonlinear head..."
      ],
      "metadata": {
        "id": "SsFB8zmalENv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Non default inputs\n",
        "initial_weights = 'bt_pretrain'\n",
        "pretrain=False\n",
        "numfit=50\n",
        "num_epochs='na'\n",
        "freeze_num_epochs = 'na'\n",
        "freeze_numfit=6\n",
        "\n",
        "avg=0\n",
        "for _ in range(3):\n",
        "\n",
        "    main = main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "            aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "            initial_weights=initial_weights,pretrain=pretrain,\n",
        "            num_epochs=num_epochs,numfit=numfit,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "            print_report=True,\n",
        "                    )\n",
        "\n",
        "    metrics = main()\n",
        "    avg += metrics['acc']\n",
        "\n",
        "avg/3\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o7cYpTNwioAb",
        "outputId": "1d8e3e66-0529-40f3-f03d-e61c7d4b3529"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside new my_splitter\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.198341</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.196352</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.192322</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.186077</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.176804</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.163485</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.069430</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.068809</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.059758</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.053328</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.044665</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.034600</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.023101</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.011719</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.996386</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.976805</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.953595</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.927138</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.894686</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.859201</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.817305</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.770916</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.722516</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.674248</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.622990</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.571304</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.517367</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.462131</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.408615</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.356084</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.305149</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.257388</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.208990</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.163944</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.117596</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.075497</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.033147</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.992616</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.954866</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.918212</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.884951</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.852918</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.821603</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.791009</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.762083</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.735640</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.710138</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.687064</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.663541</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.641257</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.619402</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.599954</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.581083</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.563153</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.545914</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.529574</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.64      0.70      0.67        20\n",
            "      basal cell carcinoma       0.68      0.65      0.67        20\n",
            "            dermatofibroma       0.80      0.84      0.82        19\n",
            "                  melanoma       0.50      0.40      0.44        20\n",
            "                     nevus       0.59      0.65      0.62        20\n",
            "pigmented benign keratosis       0.56      0.70      0.62        20\n",
            "      seborrheic keratosis       0.50      0.40      0.44        15\n",
            "   squamous cell carcinoma       0.71      0.50      0.59        20\n",
            "           vascular lesion       0.79      0.95      0.86        20\n",
            "\n",
            "                  accuracy                           0.65       174\n",
            "                 macro avg       0.64      0.64      0.64       174\n",
            "              weighted avg       0.65      0.65      0.64       174\n",
            "\n",
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside new my_splitter\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.202211</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.199894</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.196281</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.189226</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.179641</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.165967</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.065496</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.065332</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.058458</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.051941</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.044210</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.034340</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.024710</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.011851</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.997306</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.978611</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.957904</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.932869</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.902417</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.866896</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.825991</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.786438</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.738470</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.689090</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.637896</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.583727</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.531953</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.481654</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.431111</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.379689</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.330266</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.280401</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.231820</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.184975</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.139744</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.095591</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.053545</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.013233</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.974759</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.937454</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.902206</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.869110</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.836766</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.807037</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.777451</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.750637</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.724277</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.699332</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.676720</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.654189</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.633398</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.612627</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.593680</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.575676</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.559913</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.543637</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.70      0.70      0.70        20\n",
            "      basal cell carcinoma       0.69      0.55      0.61        20\n",
            "            dermatofibroma       0.80      0.84      0.82        19\n",
            "                  melanoma       0.44      0.35      0.39        20\n",
            "                     nevus       0.55      0.55      0.55        20\n",
            "pigmented benign keratosis       0.48      0.50      0.49        20\n",
            "      seborrheic keratosis       0.47      0.53      0.50        15\n",
            "   squamous cell carcinoma       0.63      0.60      0.62        20\n",
            "           vascular lesion       0.76      0.95      0.84        20\n",
            "\n",
            "                  accuracy                           0.62       174\n",
            "                 macro avg       0.61      0.62      0.61       174\n",
            "              weighted avg       0.62      0.62      0.62       174\n",
            "\n",
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside new my_splitter\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.197782</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.196333</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.192182</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.186058</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.176118</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.162399</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.069100</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.061539</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.052295</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.048429</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.040670</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.032983</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.023321</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.009928</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.995080</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.974495</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.952185</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.925520</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.893992</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.854636</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.814561</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.768071</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.723325</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.673268</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.622761</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.572439</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.520319</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.467811</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.416576</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.366465</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.314230</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.263600</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.214913</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.166810</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.120296</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.077868</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.036856</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.996838</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.958666</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.921926</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.887448</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.853289</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.820489</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.789365</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.760423</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.732963</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.706414</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.681582</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.659004</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.637929</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.616540</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.596444</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.577089</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.559685</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.544365</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.528249</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.59      0.65      0.62        20\n",
            "      basal cell carcinoma       0.83      0.75      0.79        20\n",
            "            dermatofibroma       0.84      0.84      0.84        19\n",
            "                  melanoma       0.57      0.40      0.47        20\n",
            "                     nevus       0.58      0.70      0.64        20\n",
            "pigmented benign keratosis       0.48      0.60      0.53        20\n",
            "      seborrheic keratosis       0.60      0.60      0.60        15\n",
            "   squamous cell carcinoma       0.65      0.55      0.59        20\n",
            "           vascular lesion       0.90      0.90      0.90        20\n",
            "\n",
            "                  accuracy                           0.67       174\n",
            "                 macro avg       0.67      0.67      0.67       174\n",
            "              weighted avg       0.67      0.67      0.67       174\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6455938617388407"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory baseline ensembling with a nonlinear head, without pretraining:"
      ],
      "metadata": {
        "id": "TcWo9NGxwxt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to make sure the nonlinear head model is still around..."
      ],
      "metadata": {
        "id": "TsonTn0ht9hV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "#| export\n",
        "\n",
        "class HeadEncoder(nn.Module):\n",
        "    \"Basic nonlinear \"\n",
        "    def __init__(self,resnet_encoder,device='cuda'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.resnet_encoder=resnet_encoder\n",
        "\n",
        "        self.head_encoder = sequential(nn.Linear(2048,2048),nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "                               nn.ReLU(inplace=True))\n",
        "        \n",
        "        self.device = torch.device(device)\n",
        "        self.to(self.device)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.resnet_encoder(x)\n",
        "        x=self.head_encoder(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def create_model(which_model,device,ps=8192,n_in=3):\n",
        "    print('inside create_model')\n",
        "\n",
        "    #pretrained=True if 'which_model' in ['bt_pretrain', 'supervised_pretrain'] else False\n",
        "\n",
        "    if which_model == 'bt_pretrain': model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
        "    \n",
        "    elif which_model == 'no_pretrain': model = resnet50()\n",
        "\n",
        "    elif which_model == 'supervised_pretrain': model = resnet50(weights='IMAGENET1K_V2')\n",
        "\n",
        "    #ignore the 'pretrained=False' argument here. Just means we use the weights above \n",
        "    #(which themselves are either pretrained or not)\n",
        "    encoder = get_resnet_encoder(model)\n",
        "    encoder = HeadEncoder(encoder,device='cpu')\n",
        "\n",
        "    model = create_barlow_twins_model(encoder, hidden_size=ps,projection_size=ps,nlayers=3)\n",
        "\n",
        "    if device == 'cuda':\n",
        "        model.cuda()\n",
        "        encoder.cuda()\n",
        "\n",
        "\n",
        "    return model,encoder\n",
        "\n",
        "bt_model,encoder = create_model(which_model='bt_pretrain',ps=8192,device=device)\n",
        "\n",
        "def my_splitter_bt(m):\n",
        "\n",
        "    return L(sequential(*m.encoder.resnet_encoder),sequential(m.encoder.head_encoder,m.projector)).map(params)\n",
        "\n",
        "test_eq(len(my_splitter_bt(bt_model)),2)\n",
        "\n",
        "class main_train:\n",
        "    \"\"\"Instantiate and (optionally) train the encoder. Then fine-tune the supervised model. \n",
        "    Outputs metrics on validation data\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 dls_train, #used for training BT (if pretrain=True)\n",
        "                 dls_tune , #used for tuning\n",
        "                 dls_valid, #used to compute metrics / evaluate results. \n",
        "                 xval, #currently `predict_model` below assumes this is entire validation / test data\n",
        "                 yval,\n",
        "                 aug_pipelines, #the aug pipeline for self-supervised learning\n",
        "                 aug_pipelines_tune, #the aug pipeline for supervised learning\n",
        "                 aug_pipelines_test, #test (or valid) time augmentations \n",
        "                 initial_weights, #Which initial weights to use\n",
        "                 pretrain, #Whether to fit BT\n",
        "                 num_epochs, #number of BT fit epochs\n",
        "                 numfit, #number of tune_fit epochs\n",
        "                 freeze_num_epochs, #How many epochs to freeze body for when training BT\n",
        "                 freeze_numfit, #How many epochs to freeze body for when fine tuning\n",
        "                 ps=8192, #projection size\n",
        "                 n_in=3, #color channels\n",
        "                 indim=2048, #dimension output of encoder (2048 for resnet50)\n",
        "                 outdim=9, #number of classes\n",
        "                 print_report=False, #F1 metrics etc\n",
        "                 print_plot=False, #ROC curve\n",
        "                 ):\n",
        "        store_attr()\n",
        "        self.vocab = self.dls_valid.vocab\n",
        "        self.device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "\n",
        "                \n",
        "                 \n",
        "\n",
        "                 #Soon we might want to save some models here:\n",
        "\n",
        "                 #if self.model_type == 'res_proj': test_eq(self.fit_policy,'resnet_fine_tune') #I THINK this is only viable option?\n",
        "                 #self.encoder_path = f'/content/drive/My Drive/models/baselineencoder_initial_weights={self.initial_weights}_pretrain={self.pretrain}.pth'\n",
        "                 #self.tuned_model_path = f'/content/drive/My Drive/models/baselinefinetuned_initial_weights={self.initial_weights}_pretrain={self.pretrain}.pth'\n",
        "\n",
        "    @staticmethod\n",
        "    def fit(learn,fit_type,epochs,freeze_epochs,initial_weights):\n",
        "        \"\"\"We can patch in a modification, e.g. if we want subtype of fine_tune:supervised_pretrain to be different\n",
        "        to fine_tune:bt_pretrain\"\"\"\n",
        "\n",
        "        if fit_type == 'encoder_fine_tune': #i.e. barlow twins\n",
        "\n",
        "            learn.encoder_fine_tune(epochs,freeze_epochs=freeze_epochs) \n",
        "\n",
        "        elif fit_type == 'fine_tune':\n",
        "            \n",
        "            #elif initial_weights == 'supervised_pretrain':\n",
        "            learn.linear_fine_tune(epochs,freeze_epochs=freeze_epochs) \n",
        "\n",
        "        else: raise Exception('Fit policy not of expected form')\n",
        "\n",
        "    def train_encoder(self):\n",
        "        \"create encoder and (optionally, if pretrain=True) train with BT algorithm, according to fit_policy\"\n",
        "\n",
        "        try: #get existing encoder and plonk on new projector\n",
        "            encoder = self.encoder\n",
        "            encoder.cpu()\n",
        "            bt_model = create_barlow_twins_model(encoder, hidden_size=self.ps,projection_size=self.ps,nlayers=3)\n",
        "            bt_model.cuda()\n",
        "\n",
        "        except AttributeError: #otherwise, create\n",
        "            bt_model,encoder = create_model(which_model=self.initial_weights,ps=self.ps,device=self.device)\n",
        "\n",
        "        if self.pretrain: #train encoder according to fit policy\n",
        "\n",
        "            learn = Learner(self.dls_train,bt_model,splitter=my_splitter_bt,cbs=[BarlowTwins(self.aug_pipelines,n_in=self.n_in,lmb=1/self.ps,print_augs=False)])\n",
        "            main_train.fit(learn,fit_type='encoder_fine_tune',\n",
        "                           epochs=self.num_epochs,freeze_epochs=self.freeze_num_epochs,\n",
        "                           initial_weights=self.initial_weights\n",
        "                          )\n",
        "            \n",
        "        self.encoder = bt_model.encoder\n",
        "\n",
        "    def fine_tune(self):\n",
        "        \"fine tune in supervised fashion, according to tune_fit_policy, and get metrics\"\n",
        "\n",
        "        #encoder = pickle.loads(pickle.dumps(self.encoder)) #We might want to pretrain once and fine tune several times (varying e.g. tune augs)\n",
        "\n",
        "        try: \n",
        "            encoder = self.encoder\n",
        "        \n",
        "        except AttributeError:\n",
        "            _,self.encoder = create_model(which_model=self.initial_weights,ps=self.ps,device=device)\n",
        "\n",
        "        #model = LM(self.encoder)\n",
        "        model = sequential(self.encoder,nn.Linear(2048,9))\n",
        "        \n",
        "        learn = Learner(self.dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "        #debugging\n",
        "        #learn = Learner(self.dls_tune,model,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "        main_train.fit(learn,fit_type='fine_tune',\n",
        "                       epochs=self.numfit,freeze_epochs=self.freeze_numfit,\n",
        "                       initial_weights=self.initial_weights\n",
        "                      ) #fine tuning (don't confuse this with fit policy!)\n",
        "        \n",
        "        #model.encoder=encoder\n",
        "        scores,preds, acc = predict_model(self.xval,self.yval,model=model,aug_pipelines_test=self.aug_pipelines_test,numavg=3)\n",
        "        #metrics dict will have f1 score, auc etc etc\n",
        "        metrics = classification_report_wrapper(preds, self.yval, self.vocab, print_report=self.print_report)\n",
        "        auc_dict = plot_roc(self.yval,preds,self.vocab,print_plot=self.print_plot)\n",
        "        metrics['acc'],metrics['auc_dict'],metrics['scores'],metrics['preds'],metrics['xval'],metrics['yval'] = acc,auc_dict,scores,preds,self.xval,self.yval\n",
        "  \n",
        "        #torch.save(model.state_dict(), self.tuned_model_path)\n",
        "        return metrics #\n",
        "\n",
        "    def __call__(self):\n",
        "\n",
        "        self.train_encoder() #train (or extract) the encoder\n",
        "        metrics = self.fine_tune()\n",
        "        \n",
        "        return metrics\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tc2NWokt8-K",
        "outputId": "b670d9b1-6f09-415e-9e6a-06acefb75c80"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Verify that splitter freezes expected part of model:\n",
        "\n",
        "# #test : manual. BT\n",
        "\n",
        "learn = Learner(dls_train,bt_model,splitter=my_splitter_bt,cbs=[BarlowTwins(aug_pipelines,n_in=3,lmb=1/8192,print_augs=False)])\n",
        "learn.freeze()\n",
        "print('resnet should be frozen, encoder head + projector unfrozen')\n",
        "learn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2V9iSL4CupFj",
        "outputId": "9c865909-62df-412b-a940-f1b364d0bbf9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resnet should be frozen, encoder head + projector unfrozen\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BarlowTwinsModel (Input shape: 256 x 3 x 128 x 128)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     256 x 64 x 64 x 64  \n",
              "Conv2d                                    9408       False     \n",
              "BatchNorm2d                               128        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "MaxPool2d                                                      \n",
              "Conv2d                                    4096       False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 32 x 32 \n",
              "Conv2d                                    32768      False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 16 x 16 \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 8 x 8   \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    2097152    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 1 x 1  \n",
              "AdaptiveAvgPool2d                                              \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048          \n",
              "Flatten                                                        \n",
              "Linear                                    4196352    True      \n",
              "BatchNorm1d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 8192          \n",
              "Linear                                    16785408   True      \n",
              "BatchNorm1d                               16384      True      \n",
              "ReLU                                                           \n",
              "Linear                                    67117056   True      \n",
              "BatchNorm1d                               16384      True      \n",
              "ReLU                                                           \n",
              "Linear                                    67117056   True      \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 178,760,768\n",
              "Total trainable params: 155,305,856\n",
              "Total non-trainable params: 23,454,912\n",
              "\n",
              "Optimizer used: <function Adam at 0x7fa2826b0160>\n",
              "Loss function: <bound method BarlowTwins.lf of BarlowTwins>\n",
              "\n",
              "Model frozen up to parameter group #1\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - CastToTensor\n",
              "  - BarlowTwins\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # #Verify that splitter freezes expected part of model, from linear point of view:\n",
        "\n",
        "bt_model,encoder = create_model(which_model='bt_pretrain',ps=8192,device=device)\n",
        "model = sequential(encoder,nn.Linear(2048,9))\n",
        "learn = Learner(dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=aug_pipelines_tune,n_in=3)],wd=0.0)\n",
        "learn.freeze()\n",
        "print('resnet should be frozen, then should just have unfrozen linear layer')\n",
        "learn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OMc8zE1Kup1y",
        "outputId": "a8052ce3-7d4b-405b-82e7-a205657acf7c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside new my_splitter\n",
            "resnet should be frozen, then should just have unfrozen linear layer\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential (Input shape: 256 x 3 x 128 x 128)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     256 x 64 x 64 x 64  \n",
              "Conv2d                                    9408       False     \n",
              "BatchNorm2d                               128        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "MaxPool2d                                                      \n",
              "Conv2d                                    4096       False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 32 x 32 \n",
              "Conv2d                                    32768      False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 16 x 16 \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 8 x 8   \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    2097152    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 1 x 1  \n",
              "AdaptiveAvgPool2d                                              \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048          \n",
              "Flatten                                                        \n",
              "Linear                                    4196352    True      \n",
              "BatchNorm1d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 9             \n",
              "Linear                                    18441      True      \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 27,726,921\n",
              "Total trainable params: 4,272,009\n",
              "Total non-trainable params: 23,454,912\n",
              "\n",
              "Optimizer used: <function Adam at 0x7fa2826b0160>\n",
              "Loss function: <bound method LinearBt.lf of LinearBt>\n",
              "\n",
              "Model frozen up to parameter group #1\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - CastToTensor\n",
              "  - LinearBt\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experiment: pretrain the head for a really long time, with resnet frozen."
      ],
      "metadata": {
        "id": "B2rZbGpgvFgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Non default inputs\n",
        "initial_weights = 'bt_pretrain'\n",
        "pretrain=True\n",
        "numfit=50\n",
        "num_epochs=200\n",
        "freeze_num_epochs = 1\n",
        "freeze_numfit=6\n",
        "\n",
        "\n",
        "main = main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "        aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "        initial_weights=initial_weights,pretrain=pretrain,\n",
        "        num_epochs=num_epochs,numfit=numfit,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "        print_report=True,\n",
        "                )\n",
        "\n",
        "metrics = main()\n",
        "print(metrics['acc'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xKSSL4WOvV07",
        "outputId": "80bc08e4-5c89-416b-95fd-0bdb6bcb4e24"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside create_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5618.505859</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2225.252686</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2220.608398</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2020.624756</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1898.112427</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1812.766479</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1726.943970</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1662.019775</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1600.636841</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1549.371338</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1498.420288</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1453.601440</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1413.298218</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1375.709717</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1344.151855</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1308.969604</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1279.468750</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1247.379761</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1219.535400</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1190.677612</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1162.957031</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1138.811279</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1114.262451</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1091.691650</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1068.595093</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1045.490356</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1023.732422</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1003.405457</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>985.059509</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>968.948181</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>951.169250</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>935.535522</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>917.849365</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>903.588379</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>886.190125</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>871.231445</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>855.438904</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>840.972046</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>824.798035</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>811.757507</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>797.824707</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>784.760803</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>770.136536</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>756.785706</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>746.121582</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>733.413879</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>720.408020</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>706.812622</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>695.247803</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>684.849792</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>675.100708</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>665.224487</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>654.560791</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>644.721191</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>634.485535</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>625.267700</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>614.698486</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>604.850952</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>595.540894</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>588.320496</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>580.664429</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>571.778015</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>562.908997</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>555.578064</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>547.894165</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>539.096191</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>532.278809</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>524.385498</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>517.931641</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>510.660126</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>504.080048</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>496.859589</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>490.100128</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>483.727020</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>477.412323</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>470.285339</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>463.915100</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>457.534546</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>451.636963</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>445.503815</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>440.073944</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>434.222992</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>427.632721</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>422.399841</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>417.396088</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>412.992737</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>408.235474</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>403.750275</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>399.050690</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>394.780426</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>391.299805</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>386.701935</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>382.587250</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>377.476715</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>372.980438</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>369.737823</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>365.564423</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>361.682007</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>359.053253</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>355.582581</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>351.779938</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>347.775513</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>344.059906</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>340.558289</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>336.531189</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>334.191193</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>330.795990</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>327.979431</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>324.633972</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>322.454895</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>319.834198</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>316.641479</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>313.861969</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>311.251770</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>308.223450</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>305.610260</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>303.399628</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>301.086548</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>297.995087</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>295.670471</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>293.200226</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>290.569641</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>287.518921</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>285.104919</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>282.567139</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>279.759155</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>278.337769</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>275.934479</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>274.091492</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>272.255585</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>270.010925</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>268.165558</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>265.940277</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>263.649414</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>261.329590</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>259.465302</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>257.614258</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>256.129333</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>254.718704</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>252.911896</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>251.271332</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>249.524307</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>248.013641</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>247.095459</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>245.353455</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>244.123032</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>242.337189</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>241.039566</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>239.753983</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>238.253494</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>236.933548</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>235.454041</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>234.353973</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>232.862747</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>232.514114</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>231.578979</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>230.821915</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>230.353165</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>229.124847</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>227.675568</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>226.363342</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>225.140091</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>224.029037</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>222.698639</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>221.614761</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>220.620117</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>219.540741</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>218.437134</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>217.848373</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>217.137909</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>216.341766</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>215.482407</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>214.689087</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>214.476151</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>213.694885</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>213.001495</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>212.010315</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>211.059860</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>210.554810</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>209.788284</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>209.240829</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>209.052917</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>208.206985</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>207.598938</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>206.985321</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>206.404099</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>205.800568</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>205.147598</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>204.680145</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>204.534210</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>204.186234</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>203.357986</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>202.844528</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>202.317352</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>201.740326</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>201.145660</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>201.520203</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>201.879837</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>201.190002</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>200.703949</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>200.221161</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside new my_splitter\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.209545</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.074716</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.903065</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.718835</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.545133</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.394172</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.575437</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.549418</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.523801</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.496486</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.469012</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.446456</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.421263</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.398532</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.371554</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.352936</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.332398</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.316469</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.298481</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.284461</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.273237</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.262671</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.253104</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.244441</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.236579</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.228177</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.220256</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.216390</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.211926</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.206482</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.201531</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.196515</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.192127</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.185784</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.181490</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.177575</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.173571</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.170171</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.165984</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.163052</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.160043</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.157163</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.153340</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.150026</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.147056</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.144447</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.141952</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.139521</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.136280</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.133803</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.131742</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.129971</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.128727</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.127117</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.124934</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.123012</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.57      0.65      0.60        20\n",
            "      basal cell carcinoma       0.50      0.50      0.50        20\n",
            "            dermatofibroma       0.74      0.74      0.74        19\n",
            "                  melanoma       0.32      0.30      0.31        20\n",
            "                     nevus       0.48      0.50      0.49        20\n",
            "pigmented benign keratosis       0.46      0.55      0.50        20\n",
            "      seborrheic keratosis       0.30      0.20      0.24        15\n",
            "   squamous cell carcinoma       0.56      0.45      0.50        20\n",
            "           vascular lesion       0.82      0.90      0.86        20\n",
            "\n",
            "                  accuracy                           0.54       174\n",
            "                 macro avg       0.53      0.53      0.53       174\n",
            "              weighted avg       0.53      0.54      0.53       174\n",
            "\n",
            "0.540229856967926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wow, it didn't work at all."
      ],
      "metadata": {
        "id": "5RtgCHENIIFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "\n",
        "Depending on above results, we need to:\n",
        "\n",
        "- Explore the effect of using `fine_tune` instead of `linear_fine_tune`. i.e. using different learning rates.\n",
        "- Perhaps try using a nice FastAI head, via `create_head` magic. Perhaps we can pretrain this guy with BT instead?\n",
        "- Run head-probing experiments, where head may be linear or non linear. That is, freeze the resnet the whole way. Not sure whether to bother whether this. Probably not actually. Paper sugges LP-FT works best, after all.\n"
      ],
      "metadata": {
        "id": "i59x4iICFQTc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MI4qEtmgAB5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just look at bt weights first:"
      ],
      "metadata": {
        "id": "L9GD7DUuxFGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_main_train(initial_weights,num_epochs,freeze_numfit,freeze_num_epochs,numfit=100,pretrain=False,num=5):\n",
        "    \"run main_train num times.\"\n",
        "\n",
        "    main_dict = {}\n",
        "    for i in range(num):\n",
        "\n",
        "        main = main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "                aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "                initial_weights=initial_weights,pretrain=pretrain,\n",
        "                num_epochs=num_epochs,numfit=numfit,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "                print_report=True,\n",
        "                        )\n",
        "        \n",
        "        metrics = main()\n",
        "        main_dict[i] = metrics\n",
        "\n",
        "    return main_dict\n",
        "        "
      ],
      "metadata": {
        "id": "a4ux74eoiMkh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment: Baseline, non linear head with no pretraining. Ensemble."
      ],
      "metadata": {
        "id": "MLYZ2Iplf8L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights='bt_pretrain'\n",
        "main_dict = run_main_train(initial_weights=initial_weights,numfit=50,num_epochs='na',freeze_num_epochs='na',pretrain=False,freeze_numfit=3,num=3)\n",
        "\n",
        "from itertools import combinations\n",
        "from statistics import mean\n",
        "from statistics import stdev\n",
        "\n",
        "print('Results for ensembling within bt weights:')\n",
        "\n",
        "bt_results = list(main_dict.values())\n",
        "\n",
        "_bt_results = [k['acc'] for k in bt_results]\n",
        "print(_bt_results)\n",
        "print(mean(_bt_results))\n",
        "print(stdev(_bt_results))\n",
        "\n",
        "bt_results = list(combinations(bt_results,2)) #all pairs of results. So for num=3, will be 3\n",
        "for v in bt_results:\n",
        "\n",
        "    print(f\"\\nAcc of first guy in ensemble is: {v[0]['acc']}\")\n",
        "    print(f\"Acc of second guy in ensemble is: {v[1]['acc']}\")\n",
        "    _,acc = predict_ensemble(yval=yval,scores1=v[0]['scores'],scores2=v[1]['scores'])\n",
        "    print(f'Acc of ensemble is:{acc}\\n')"
      ],
      "metadata": {
        "id": "GKxhWwlLxCTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights='bt_pretrain'\n",
        "main_dict = run_main_train(initial_weights=initial_weights,numfit=30,num_epochs='na',freeze_num_epochs='na',pretrain=False,freeze_numfit=3,num=3)\n",
        "\n",
        "from itertools import combinations\n",
        "from statistics import mean\n",
        "from statistics import stdev\n",
        "\n",
        "print('Results for ensembling within bt weights:')\n",
        "\n",
        "bt_results = list(main_dict.values())\n",
        "\n",
        "_bt_results = [k['acc'] for k in bt_results]\n",
        "print(_bt_results)\n",
        "print(mean(_bt_results))\n",
        "print(stdev(_bt_results))\n",
        "\n",
        "bt_results = list(combinations(bt_results,2)) #all pairs of results. So for num=3, will be 3\n",
        "for v in bt_results:\n",
        "\n",
        "    print(f\"\\nAcc of first guy in ensemble is: {v[0]['acc']}\")\n",
        "    print(f\"Acc of second guy in ensemble is: {v[1]['acc']}\")\n",
        "    _,acc = predict_ensemble(yval=yval,scores1=v[0]['scores'],scores2=v[1]['scores'])\n",
        "    print(f'Acc of ensemble is:{acc}\\n')"
      ],
      "metadata": {
        "id": "kQLm7lpIDVbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert False"
      ],
      "metadata": {
        "id": "zMfncqPYNTPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's look at doing some pretraining. For now, say BT pretrain for 10 epochs. Freezing the projector doesn't make sense remember: we are aligning the random head and projector. But, check above: the backbone encoder is frozen. \n",
        "\n",
        "Thinking about this more: training the encoder_head on a frozen backbone will make them less variable."
      ],
      "metadata": {
        "id": "tBADYAKmxxZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's try an ensemble with the resnet frozen the whole way through.\n",
        "\n",
        "Notice that the resnet is kept frozen the whole way through (you can look up above to verify the freeze is working as expected):"
      ],
      "metadata": {
        "id": "BVP8NHY004hO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment: pretrain the nonlinear head with BT"
      ],
      "metadata": {
        "id": "AhZN_wuNgfAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "@patch\n",
        "@delegates(Learner.fit_one_cycle)\n",
        "def encoder_fine_tune(self:Learner, epochs, base_lr=2e-3, freeze_epochs=1, lr_mult=100,\n",
        "              pct_start=0.3, div=5.0, **kwargs):\n",
        "    \"Fine tuner to use with bt initial weights\"\n",
        "    \n",
        "    self.freeze() #freeze the resnet\n",
        "    self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs)\n",
        "    base_lr /= 2\n",
        "    #self.unfreeze() #don't unfreeze the resnet. We are fitting training the encoder head + projector\n",
        "    #self.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div, **kwargs)\n",
        "    self.fit_one_cycle(epochs, slice(base_lr, base_lr), pct_start=pct_start, div=div, **kwargs)\n",
        "\n",
        "    self.unfreeze() #We can unfreeze at the end\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    initial_weights='bt_pretrain'\n",
        "    num_epochs=100\n",
        "    freeze_num_epochs=1\n",
        "    freeze_numfit=3\n",
        "    pretrain=True\n",
        "    main_dict = run_main_train(initial_weights,num_epochs=50,freeze_numfit,freeze_num_epochs,pretrain=pretrain,num=3)\n",
        "\n",
        "\n",
        "\n",
        "    print('Results for ensembling with bt weights, where we just trained the head')\n",
        "    bt_results = list(main_dict.values())\n",
        "    print([bt_results[i]['acc'] for i in range(len(bt_results))])\n",
        "    bt_results = list(combinations(bt_results,2)) #all pairs of results. So for num=3, will be 3\n",
        "    for v in bt_results:\n",
        "\n",
        "        print(f\"\\nAcc of first guy in ensemble is: {v[0]['acc']}\")\n",
        "        print(f\"Acc of second guy in ensemble is: {v[1]['acc']}\")\n",
        "        _,acc = predict_ensemble(yval=yval,scores1=v[0]['scores'],scores2=v[1]['scores'])\n",
        "        print(f'Acc of ensemble is:{acc}\\n')\n",
        "        \n"
      ],
      "metadata": {
        "id": "qZvejZRq1POY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}