{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working on local machine (i.e. not colab or kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0\n",
    "!pip install fastai==2.6.3 --no-deps\n",
    "!pip install self_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.7.9'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai\n",
    "import self_supervised\n",
    "import torch\n",
    "print(self_supervised.__version__)\n",
    "fastai.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import inspect\n",
    "import warnings\n",
    "import random\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#from Base_Stein.SVGD_classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like most other SSL algorithms BT's model consists of an encoder and projector (MLP) layer.\n",
    "#Definition is straightforward:\n",
    "#https://colab.research.google.com/github/KeremTurgutlu/self_supervised/blob/master/nbs/14%20-%20barlow_twins.ipynb#scrollTo=1M6QcUChcvpz\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):self.encoder,self.projector = encoder,projector\n",
    "        \n",
    "    def forward(self,x): return self.projector(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOWEVER instead of directly using the above, by passing both an encoder and a projector, create_barlow_twins_model\n",
    "#function can be used by minimally passing a predefined encoder and the expected input channels.\n",
    "\n",
    "#In the paper it's mentioned that MLP layer consists of 3 layers... following function will create a 3 layer\n",
    "#MLP projector with batchnorm and ReLU by default. Alternatively, you can change bn and nlayers. \n",
    "\n",
    "#Questions: Why torch.no_grad() when doing this?\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "#Similar to above. Simple API to make the BT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BarlowTwins Callback\n",
    "#The following parameters can be passed:\n",
    "# - aug_pipelines\n",
    "# Imb lambda is the weight for redundancy reduction term in the loss function\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(n=2,size=size,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uniform random number between a and b\n",
    "def Unif(a,b):\n",
    "    return (b-a)*torch.rand(1).item()+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_polynomial(A):\n",
    "    \n",
    "    #B=torch.normal(mean=0, std=0.025, size=(1, 1)).item() #First Horner term (and is coefficient of x^4)\n",
    "    \n",
    "    #Btem = torch.normal(mean=0,std=0.05, size=(1, 1)).item() #Sample coefficient of x^3\n",
    "    #B = Btem + B*A #Third Horner term\n",
    "    \n",
    "    B = torch.normal(mean=0,std=0.5, size=(1, 1)).item() #Sample coefficient of x^2\n",
    "    \n",
    "#     Btem = torch.normal(mean=0,std=0.5, size=(1, 1)).item() #Sample coefficient of x^2\n",
    "#     B = Btem + B*A #Third Horner term\n",
    "    \n",
    "    Btem = random.choice([-1,1])*torch.normal(mean=0,std=1, size=(1, 1)).item() #Sample coefficient of x\n",
    "    #Btem=1\n",
    "    B = Btem + B*A #Fourth Horner term\n",
    "    \n",
    "    Btem = torch.normal(mean=0,std=1, size=(1, 1)).item() #Sample coefficient of x^0\n",
    "    B = Btem + B*A #Fifth Horner term\n",
    "    \n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_polynomial_bestsofar(A):\n",
    "    \n",
    "    \n",
    "    B=torch.normal(mean=0, std=0.025, size=(1, 1)).item() #First Horner term (and is coefficient of x^4)\n",
    "    \n",
    "    Btem = torch.normal(mean=0,std=0.05, size=(1, 1)).item() #Sample coefficient of x^3\n",
    "    B = Btem + B*A #Third Horner term\n",
    "    \n",
    "    Btem = torch.normal(mean=0,std=0.5, size=(1, 1)).item() #Sample coefficient of x^2\n",
    "    B = Btem + B*A #Third Horner term\n",
    "    \n",
    "    Btem = random.choice([-1,1])*torch.normal(mean=1,std=2, size=(1, 1)).item() #Sample coefficient of x\n",
    "    B = Btem + B*A #Fourth Horner term\n",
    "    \n",
    "    Btem = torch.normal(mean=0,std=1, size=(1, 1)).item() #Sample coefficient of x^0\n",
    "    B = Btem + B*A #Fifth Horner term\n",
    "    \n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_deg(A):\n",
    "    power=Unif(1,1.25)\n",
    "    coeff2 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n",
    "    coeff1 = torch.normal(mean=1, std=1, size=(1, 1)).item() #degree 2 term\n",
    "    \n",
    "#     coeff2 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n",
    "#     coeff1 = torch.normal(mean=1, std=0.7, size=(1, 1)).item() #degree 2 term\n",
    "\n",
    "#     coeff2 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n",
    "#     coeff1 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n",
    "\n",
    "    \n",
    "    B = (coeff1*A + coeff2*torch.abs(A).pow(power))\n",
    "    \n",
    "    #B = (1/power)*torch.abs(A).pow(power)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_quintic(A):\n",
    "\n",
    "    \n",
    "    B=torch.normal(mean=0, std=0.125, size=(1, 1)).item() #First Horner term (and is coefficient of x^4)\n",
    "    \n",
    "    Btem=torch.normal(mean=0, std=0.25, size=(1, 1)).item()#Sample coefficient of x^3\n",
    "    B = Btem + B*A #Second Horner term\n",
    "    \n",
    "    Btem = torch.normal(mean=0,std=0.5, size=(1, 1)).item() #Sample coefficient of x^2\n",
    "    B = Btem + B*A #Third Horner term\n",
    "    \n",
    "    Btem = random.choice([-1,1])*torch.normal(mean=1,std=2, size=(1, 1)).item() #Sample coefficient of x\n",
    "    B = Btem + B*A #Fourth Horner term\n",
    "    \n",
    "    Btem = torch.normal(mean=0,std=1, size=(1, 1)).item() #Sample coefficient of x^0\n",
    "    B = Btem + B*A #Fifth Horner term\n",
    "    \n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sinusoid(x,std=2.0):\n",
    "    \n",
    "    t=torch.normal(mean=1,std=std,size=(1,1)).item()\n",
    "    s=torch.normal(mean=1,std=std,size=(1,1)).item()\n",
    "    \n",
    "    u=torch.normal(mean=0,std=std,size=(1,1)).item()\n",
    "    v=torch.normal(mean=0,std=std,size=(1,1)).item()\n",
    "    \n",
    "    a=torch.normal(mean=0,std=2,size=(1,1)).item()\n",
    "    b=torch.normal(mean=0,std=2,size=(1,1)).item()\n",
    "    \n",
    "    return a*torch.sin(t*x+s) + b*torch.cos(u*x + v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_sinusoid(x):\n",
    "    \n",
    "    return (x) + 0.2*random_sinusoid(x,std=(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines, lmb=5e-3, print_augs=False):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "            \n",
    "    def before_batch(self):\n",
    "        xi,xj = self.aug1(self.x), self.aug2(self.x)\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "        \n",
    "        #Uncomment to run standard BT\n",
    "    \n",
    "#     def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n",
    "#         bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "#         z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "#         z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "#         z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "        \n",
    "#         C = (z1norm.T @ z2norm) / bs \n",
    "#         cdiff = (C - self.I)**2\n",
    "#         loss = (cdiff*self.I + cdiff*(1-self.I)*self.lmb).sum() \n",
    "#         return loss\n",
    "\n",
    "\n",
    "    def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n",
    "        bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "        #All standard, from BT\n",
    "        z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "        \n",
    "        \n",
    "        C = (z1norm.T @ z2norm) / bs \n",
    "        cdiff = (C - self.I)**2\n",
    "    \n",
    "        #polyprob=0.1\n",
    "        polyprob=0.5\n",
    "        temrand = random.random()\n",
    "        if temrand < polyprob: #With some probability we want off diag terms to be (quadratic) say.\n",
    "\n",
    "            p=Unif(1,2.5) \n",
    "            z1norm_2 = (1/p)*torch.abs(z1norm).pow(p)\n",
    "            z2norm_2 = z2norm\n",
    "                \n",
    "            C_2 = (z1norm_2.T @ z2norm_2) / bs\n",
    "            \n",
    "            cdiff_2 = (C_2)**2 #don't need to subtract I as only looking at off diag terms\n",
    "            \n",
    "        else:\n",
    "            cdiff_2 = cdiff\n",
    "            \n",
    "        l2 = cdiff_2*(1-self.I)*self.lmb #Is either the standard term - or not.\n",
    "\n",
    "        loss = (cdiff*self.I + l2).sum() \n",
    "        return loss\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1):\n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:] \n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]] \n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Debugging cell - delete later (similar to cell below)\n",
    "ps=500\n",
    "hs=500\n",
    "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
    "model = create_barlow_twins_model(fastai_encoder, hidden_size=hs,projection_size=ps)# projection_size=1024)\n",
    "#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n",
    "#values for these which is tantamount to doing nothing\n",
    "#So if we choose resize_scale=(1,1) then the images look the same.\n",
    "#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\n",
    "aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=True)\n",
    "#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
    "learn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
    "learn.fit(100) #300                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get the dataloader and set batch size \n",
    "# ts=512 #training set size\n",
    "# bs=256 \n",
    "# device='cpu'\n",
    "# path = untar_data(URLs.MNIST)\n",
    "# items = get_image_files(path/'training') #i.e. NOT testing!!!\n",
    "# items=items.shuffle()\n",
    "\n",
    "# items1 = items[0:ts]\n",
    "# split = RandomSplitter(valid_pct=0.5) #randomly split training set into training and validation\n",
    "# #tds = Datasets(items,splits=split(items)) #Do we want this?\n",
    "# tds = Datasets(items1, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items1)) #Or do we want this?\n",
    "# dls = tds.dataloaders(bs=bs, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n",
    "\n",
    "# #Evaluate linear classifier on this guy\n",
    "# items2 = items[ts:]\n",
    "# split = RandomSplitter(valid_pct=0.99) #randomly split training set into training and validation\n",
    "# tds_new = Datasets(items2, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items2)) #Or do we want this?\n",
    "# dls_new = tds_new.dataloaders(bs=bs, after_item=[ToTensor(), IntToFloatTensor()], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"\"\n",
    "    Seed everything.\n",
    "    \"\"\"   \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def tune_set(items0,tune_s=1000):\n",
    "  \n",
    "    items0=items0.shuffle()\n",
    "    d = {'0':0,'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0,'8':0,'9':0}\n",
    "    ITEMS=[]\n",
    "    for i in items0:\n",
    "        s=str(i).split('/training/')[1][0]\n",
    "        if d[s] is 0 or d[s] is 1:\n",
    "            ITEMS.append(i)\n",
    "            d[s]+=1\n",
    "    #items0=ITEMS\n",
    "\n",
    "    for i in items0:\n",
    "        if i not in ITEMS:\n",
    "            ITEMS.append(i)\n",
    "            \n",
    "    split = IndexSplitter(list(range(20)))\n",
    "\n",
    "    tds_tune = Datasets(ITEMS, [PILImageBW.create, [parent_label, Categorize()]], splits=split(ITEMS)) #Or do we want this?\n",
    "    dls_tune = tds_tune.dataloaders(bs=20, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n",
    "    \n",
    "    return dls_tune\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorImageBW(0.1257)\n",
      "\n",
      "TensorImageBW(0.1301)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m dls_tune\u001b[38;5;241m.\u001b[39mtrain:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#Evaluate linear classifier on this guy\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SSL/lib/python3.9/site-packages/ipykernel/kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1074\u001b[0m     )\n\u001b[0;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SSL/lib/python3.9/site-packages/ipykernel/kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "#Get the dataloader and set batch size \n",
    "ts=16384 #training set size - most everything\n",
    "bs=512\n",
    "device='cpu'\n",
    "path = untar_data(URLs.MNIST)\n",
    "\n",
    "items = get_image_files(path/'training') #i.e. NOT testing!!!\n",
    "items.sort() \n",
    "\n",
    "seed_everything(seed=42)\n",
    "# import random\n",
    "# random.seed(20)\n",
    "items=items.shuffle()\n",
    "\n",
    "items1 = items[0:ts] #train on these guys\n",
    "split = RandomSplitter(valid_pct=0.0) #randomly split training set into training and validation\n",
    "#tds = Datasets(items,splits=split(items)) #Do we want this?\n",
    "tds = Datasets(items1, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items1)) #Or do we want this?\n",
    "dls = tds.dataloaders(bs=bs, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n",
    "\n",
    "tune_s=1000 #we choose 20 guys (randomly) out of 1000 to tune on\n",
    "items0 = items[ts:ts+tune_s] #for fine tuning - just choose 2000 guys to extract 20 for fine tuning \n",
    "dls_tune=tune_set(items0,tune_s=tune_s)\n",
    "\n",
    "#NB: Uncomment and compare in colab and kaggle\n",
    "for x,y in dls_tune.train:\n",
    "    print(x.mean())\n",
    "    input()\n",
    "    break\n",
    "\n",
    "dls_tune=tune_set(items0,tune_s=1000)\n",
    "\n",
    "for x,y in dls_tune.train:\n",
    "    print(x.mean())\n",
    "    input()\n",
    "    break\n",
    "\n",
    "\n",
    "#Evaluate linear classifier on this guy\n",
    "items2 = items[ts+tune_s:]\n",
    "split = RandomSplitter(valid_pct=0.0) #randomly split training set into training and validation\n",
    "tds_test = Datasets(items2, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items2)) #Or do we want this?\n",
    "dls_test = tds_test.dataloaders(bs=390, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy paste from GitHub - trying to debug error from using create_encoder(.) below\n",
    "\n",
    "def _get_first_layer(m):\n",
    "    \"Access first layer of a model\"\n",
    "    c,p,n = m,None,None  # child, parent, name\n",
    "    \n",
    "    print(m)\n",
    "    print(dir(m))\n",
    "    \n",
    "    input()\n",
    "    m.named_parameters()\n",
    "    input('ok')\n",
    "    \n",
    "    \n",
    "    for n in next(m.named_parameters())[0].split('.')[:-1]:\n",
    "        p,c=c,getattr(c,n)\n",
    "    return c,p,n\n",
    "\n",
    "def _update_first_layer(model, n_in, pretrained):\n",
    "    \"Change first layer based on number of input channels\"\n",
    "    if n_in == 3: return\n",
    "    first_layer, parent, name = _get_first_layer(model)\n",
    "    assert isinstance(first_layer, nn.Conv2d), f'Change of input channels only supported with Conv2d, found {first_layer.__class__.__name__}'\n",
    "    assert getattr(first_layer, 'in_channels') == 3, f'Unexpected number of input channels, found {getattr(first_layer, \"in_channels\")} while expecting 3'\n",
    "    params = {attr:getattr(first_layer, attr) for attr in 'out_channels kernel_size stride padding dilation groups padding_mode'.split()}\n",
    "    params['bias'] = getattr(first_layer, 'bias') is not None\n",
    "    params['in_channels'] = n_in\n",
    "    new_layer = nn.Conv2d(**params)\n",
    "    if pretrained:\n",
    "        _load_pretrained_weights(new_layer, first_layer)\n",
    "    setattr(parent, name, new_layer)\n",
    "    \n",
    "def create_body(model, n_in=3, pretrained=True, cut=None):\n",
    "    \"Cut off the body of a typically pretrained `arch` as determined by `cut`\"\n",
    "    _update_first_layer(model, n_in, pretrained)\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n",
    "    return cut_model(model, cut)\n",
    "\n",
    "#export\n",
    "def create_fastai_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax):\n",
    "    \"Create timm encoder from a given arch backbone\"\n",
    "    encoder = create_body(arch, n_in, pretrained, cut=None)\n",
    "    pool = AdaptiveConcatPool2d() if pool_type == \"catavgmax\" else nn.AdaptiveAvgPool2d(1)\n",
    "    return nn.Sequential(*encoder, pool, Flatten())\n",
    "\n",
    "def create_timm_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax):\n",
    "    \"Creates a body from any model in the `timm` library. If pool_type is None then it uses timm default\"\n",
    "    if ('vit' in arch) or (pool_type is None):\n",
    "        model = timm.create_model(arch, pretrained=pretrained, in_chans=n_in, num_classes=0)\n",
    "    else:\n",
    "        model = timm.create_model(arch, pretrained=pretrained, in_chans=n_in, num_classes=0, global_pool=pool_type)\n",
    "    return model\n",
    "\n",
    "def create_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax):\n",
    "    \"A utility for creating encoder without specifying the package\"\n",
    "    if arch in globals(): return create_fastai_encoder(globals()[arch], pretrained, n_in, pool_type)\n",
    "    else:                 return create_timm_encoder(arch, pretrained, n_in, pool_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function xresnet18>\n",
      "['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fastai_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxresnet18\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36mcreate_encoder\u001b[0;34m(arch, pretrained, n_in, pool_type)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_encoder\u001b[39m(arch:\u001b[38;5;28mstr\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, pool_type\u001b[38;5;241m=\u001b[39mPoolingType\u001b[38;5;241m.\u001b[39mCatAvgMax):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA utility for creating encoder without specifying the package\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m(): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_fastai_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43march\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:                 \u001b[38;5;28;01mreturn\u001b[39;00m create_timm_encoder(arch, pretrained, n_in, pool_type)\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36mcreate_fastai_encoder\u001b[0;34m(arch, pretrained, n_in, pool_type)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_fastai_encoder\u001b[39m(arch:\u001b[38;5;28mstr\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, pool_type\u001b[38;5;241m=\u001b[39mPoolingType\u001b[38;5;241m.\u001b[39mCatAvgMax):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate timm encoder from a given arch backbone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 44\u001b[0m     encoder \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     pool \u001b[38;5;241m=\u001b[39m AdaptiveConcatPool2d() \u001b[38;5;28;01mif\u001b[39;00m pool_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcatavgmax\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mAdaptiveAvgPool2d(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39mencoder, pool, Flatten())\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36mcreate_body\u001b[0;34m(model, n_in, pretrained, cut)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_body\u001b[39m(model, n_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cut\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCut off the body of a typically pretrained `arch` as determined by `cut`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 35\u001b[0m     \u001b[43m_update_first_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cut \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m         ll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(model\u001b[38;5;241m.\u001b[39mchildren()))\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36m_update_first_layer\u001b[0;34m(model, n_in, pretrained)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChange first layer based on number of input channels\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_in \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m first_layer, parent, name \u001b[38;5;241m=\u001b[39m \u001b[43m_get_first_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_layer, nn\u001b[38;5;241m.\u001b[39mConv2d), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChange of input channels only supported with Conv2d, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(first_layer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_channels\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected number of input channels, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(first_layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_channels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m while expecting 3\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36m_get_first_layer\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdir\u001b[39m(m))\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m m\u001b[38;5;241m.\u001b[39mnamed_parameters()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SSL/lib/python3.9/site-packages/ipykernel/kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1074\u001b[0m     )\n\u001b[0;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SSL/lib/python3.9/site-packages/ipykernel/kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_first_layer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A \"reasonable\" composite augmentation: initially copy pasted BT. We run this cell a few times to check it makes sense\n",
    "#Also define encoder and model\n",
    "#fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
    "# model = create_barlow_twins_model(fastai_encoder, hidden_size=10,projection_size=10)# projection_size=1024)\n",
    "# #So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n",
    "# #values for these which is tantamount to doing nothing\n",
    "# #So if we choose resize_scale=(1,1) then the images look the same.\n",
    "# #IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\n",
    "# aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=False)\n",
    "# #learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
    "# learn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
    "\n",
    "# #dls.valid.bs = len(dls.valid_ds) #Set the validation dataloader batch size to be the length of the validation dataset\n",
    "\n",
    "# b = dls.one_batch()\n",
    "# learn._split(b)\n",
    "# learn('before_batch')\n",
    "# axes = learn.barlow_twins.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_encoder??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple linear classifier\n",
    "class LinearClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,zdim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(zdim,10) #As 10 classes for mnist\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = cast(self.fc1(x),Tensor) #so we have to use cross entropy loss. cast is because using old version fastai \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Train Classifier on encoder(mnist) for (at the moment) one epoch\n",
    "\n",
    "fastai_encoder.eval()\n",
    "\n",
    "zdim=1024 #see above\n",
    "head = LinearClassifier(zdim=zdim)\n",
    "device='cuda'\n",
    "head.to(device)\n",
    "optimizer = torch.optim.Adam(head.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#EPOCHS=100\n",
    "\n",
    "for epoch in range(100):\n",
    "    for x,y in dls_tune.valid:\n",
    "        #break \n",
    "        #b = dls.train.one_batch() #Seems need dls[0] or dls.train for training ... dls[1] is validation see here https://docs.fast.ai/data.core.html#DataLoaders.__getitem__\n",
    "        #x,y = b[0],b[1]\n",
    "\n",
    "        loss = criterion(head(fastai_encoder(x)),y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #print(loss)\n",
    "print('done')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Test result of above cell on the validation set - assumes that batch size of valid-dataloader is = number of valid samples                                        \n",
    "\n",
    "# print('The validation batch size is: {} '.format(dls.valid.bs))\n",
    "# input()\n",
    "\n",
    "#b = dls.valid.one_batch()\n",
    "\n",
    "fastai_encoder.eval()\n",
    "N=len(dls_test.train)*bs #close to len(dls_test.train_ds) but not quite...\n",
    "\n",
    "num_correct=0\n",
    "for x,y in dls_test.train:\n",
    "\n",
    "    ypred = head(fastai_encoder(x))\n",
    "    correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n",
    "    num_correct += correct.sum()\n",
    "print(num_correct/N)\n",
    "print('done')\n",
    "print(num_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random.seed(10)  \n",
    "**NB: Baseline with BT:\n",
    "random.seed(10), 500 epochs. \n",
    "BT: (0.7837,0.7964,0.7890)**  \n",
    "Now, hacking experiments\n",
    "100 learn epochs  \n",
    "Quad_polyprob10 = (0.7265,0.7308)  \n",
    "random_polynomial = (0.7233,0.7151)    \n",
    "low_deg = (0.7153,0.7106).  \n",
    "poly_sinusoid_polyprob20 = (0.7229,0.7250)  \n",
    "random_quad_new2_polyprob100 = (0.6357) - this is not good.     \n",
    "300 learn_epochs  \n",
    "poly_sinusoid = 0.7541 \n",
    "Can see above for other base hps\n",
    "\n",
    "Comments Quad_polyprob10 is literally just .pow(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We should at least try training linear classifier head on dls.valid (i.e. on different data to what BT was trained on - I think right?). When we do this we get:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacking since ran out of GPU\n",
    "Base HPs: ts=512,bs=256, ps=hs=500,pp=1, learn_epochs=**200**, tune_epochs=**10**.\n",
    "Run_1: BT=0.6795, MBT=0.7303"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base HPs as before: ts=512,bs=256, ps=hs=500,pp=1, learn_epochs=1000, tune_epochs=100.\n",
    "See random_polynomial above for implementation\n",
    "\n",
    "**Note: Using same random_polynomial as Version 6 notebook - so we record those \n",
    "(3) runs here and continue on given that mean was \"best so far\" (aside: although really best so far is ~ 0.92-ish, averaged over 5 or 6 runs (see some earlier notebooks). So we want to see how this random function does once we have 5 or 6 runs)**  \n",
    "**Run_1: 0.9274, Run_2: 0.9309, Run_3: 0.9202, Run_4: 0.9302, Run_5: 0.9236**   \n",
    "**Mean = 0.92646, which is basically what it was after 3 runs. Cool**\n",
    "\n",
    "Comment: So ~92.5 is best mean performance so far. 92.6 with current system, got ~92.3-5 on some others. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "mean([0.9274,0.9309,0.9202])#,0.9302,0.9236])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Just train a linear classifier (no encoder)\n",
    "# #Basically cell above but remove encoder and some re-shaping\n",
    "zdim=500 #see above\n",
    "head = LinearClassifier(zdim=zdim)\n",
    "head.to(device)\n",
    "optimizer = torch.optim.Adam(head.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for x,y in dls.train:\n",
    "    #break\n",
    "    #b = dls.train.one_batch() #see here https://docs.fast.ai/data.core.html#DataLoaders.__getitem__\n",
    "    #x,y = b[0],b[1]\n",
    "\n",
    "    x=x.view(bs,zdim)\n",
    "    x=cast(x, Tensor) #Have to do this when using old version of fastai for some reason...\n",
    "    \n",
    "    out = head(x)\n",
    "    loss = criterion(out,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Test result of above cell, (i.e. just a linear classifier), on the validation set - assumes that batch size of valid-dataloader is = number of valid samples                                        \n",
    "# num_correct=0\n",
    "# for x,y in dls_new.valid:\n",
    "\n",
    "#     x=x.view(x.shape[0],zdim)\n",
    "#     x=cast(x, Tensor) #Have to do this when using old version of fastai for some reason...\n",
    "    \n",
    "#     ypred = head(x)\n",
    "#     correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n",
    "#     num_correct += correct.sum()\n",
    "    \n",
    "# print(num_correct/len(dls_new.valid_ds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
