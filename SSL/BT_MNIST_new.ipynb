{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0\n!pip install fastai==2.6.3 --no-deps\n!pip install self_supervised","metadata":{"execution":{"iopub.status.busy":"2022-09-19T10:09:30.682145Z","iopub.execute_input":"2022-09-19T10:09:30.682992Z","iopub.status.idle":"2022-09-19T10:09:56.259961Z","shell.execute_reply.started":"2022-09-19T10:09:30.682879Z","shell.execute_reply":"2022-09-19T10:09:56.258704Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch==1.11.0 in /opt/conda/lib/python3.7/site-packages (1.11.0)\nRequirement already satisfied: torchvision==0.12.0 in /opt/conda/lib/python3.7/site-packages (0.12.0)\nRequirement already satisfied: torchaudio==0.11.0 in /opt/conda/lib/python3.7/site-packages (0.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.11.0) (4.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0) (1.21.6)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0) (9.1.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0) (2.27.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0) (1.26.9)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0) (2022.6.15)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting fastai==2.6.3\n  Downloading fastai-2.6.3-py3-none-any.whl (197 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.9/197.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fastai\n  Attempting uninstall: fastai\n    Found existing installation: fastai 2.7.4\n    Uninstalling fastai-2.7.4:\n      Successfully uninstalled fastai-2.7.4\nSuccessfully installed fastai-2.6.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting self_supervised\n  Downloading self_supervised-1.0.4-py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from self_supervised) (21.3)\nRequirement already satisfied: fastai>=2.2.7 in /opt/conda/lib/python3.7/site-packages (from self_supervised) (2.6.3)\nRequirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from self_supervised) (22.1.1)\nRequirement already satisfied: kornia>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from self_supervised) (0.5.8)\nCollecting timm>=0.4.5\n  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: fastcore<1.5,>=1.3.27 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.4.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (2.27.1)\nRequirement already satisfied: pillow>6.0.0 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (9.1.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.7.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.3.5)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (6.0)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (2.3.7)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (3.5.2)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.0.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.0.2)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (0.12.0)\nRequirement already satisfied: torch<1.12,>=1.7.0 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.11.0)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (0.0.6)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->self_supervised) (3.0.9)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.7)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.0)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.21.6)\nRequirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (7.4.5)\nRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.5)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.1.3)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.0.6)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.9.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (4.64.0)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.7.8)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (59.8.0)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.0.6)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (2022.6.15)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (2.0.12)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (1.26.9)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch<1.12,>=1.7.0->fastai>=2.2.7->self_supervised) (4.1.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (4.33.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (1.4.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (2.8.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (0.11.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fastai>=2.2.7->self_supervised) (2022.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai>=2.2.7->self_supervised) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai>=2.2.7->self_supervised) (3.1.0)\nRequirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai>=2.2.7->self_supervised) (4.12.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->fastai>=2.2.7->self_supervised) (1.16.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai>=2.2.7->self_supervised) (3.8.0)\nInstalling collected packages: timm, self_supervised\nSuccessfully installed self_supervised-1.0.4 timm-0.6.7\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"%%javascript\nfunction ClickConnect(){\nconsole.log(\"Working\");\ndocument.querySelector(\"colab-toolbar-button#connect\").click()\n}setInterval(ClickConnect,60000)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T10:09:56.265726Z","iopub.execute_input":"2022-09-19T10:09:56.268002Z","iopub.status.idle":"2022-09-19T10:09:56.283515Z","shell.execute_reply.started":"2022-09-19T10:09:56.267961Z","shell.execute_reply":"2022-09-19T10:09:56.282655Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"function ClickConnect(){\nconsole.log(\"Working\");\ndocument.querySelector(\"colab-toolbar-button#connect\").click()\n}setInterval(ClickConnect,60000)\n"},"metadata":{}}]},{"cell_type":"code","source":"import fastai\nimport self_supervised\nimport torch\nassert(fastai.__version__ == '2.6.3') #Check that version is 2.6.3","metadata":{"execution":{"iopub.status.busy":"2022-09-19T10:09:56.287267Z","iopub.execute_input":"2022-09-19T10:09:56.289770Z","iopub.status.idle":"2022-09-19T10:09:58.060276Z","shell.execute_reply.started":"2022-09-19T10:09:56.289734Z","shell.execute_reply":"2022-09-19T10:09:58.059312Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.all import *\nfrom self_supervised.augmentations import *\nfrom self_supervised.layers import *\nimport inspect\nimport warnings\nimport random\nimport math\nwarnings.filterwarnings(\"ignore\")\n#from Base_Stein.SVGD_classes import *","metadata":{"execution":{"iopub.status.busy":"2022-09-19T10:09:58.062775Z","iopub.execute_input":"2022-09-19T10:09:58.063396Z","iopub.status.idle":"2022-09-19T10:10:00.022015Z","shell.execute_reply.started":"2022-09-19T10:09:58.063358Z","shell.execute_reply":"2022-09-19T10:10:00.020853Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Like most other SSL algorithms BT's model consists of an encoder and projector (MLP) layer.\n#Definition is straightforward:\n#https://colab.research.google.com/github/KeremTurgutlu/self_supervised/blob/master/nbs/14%20-%20barlow_twins.ipynb#scrollTo=1M6QcUChcvpz\nclass BarlowTwinsModel(Module):\n    \"\"\"An encoder followed by a projector\n    \"\"\"\n    def __init__(self,encoder,projector):self.encoder,self.projector = encoder,projector\n        \n    def forward(self,x): return self.projector(self.encoder(x))","metadata":{"execution":{"iopub.status.busy":"2022-09-19T10:10:00.023769Z","iopub.execute_input":"2022-09-19T10:10:00.024956Z","iopub.status.idle":"2022-09-19T10:10:00.030911Z","shell.execute_reply.started":"2022-09-19T10:10:00.024915Z","shell.execute_reply":"2022-09-19T10:10:00.029896Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#HOWEVER instead of directly using the above, by passing both an encoder and a projector, create_barlow_twins_model\n#function can be used by minimally passing a predefined encoder and the expected input channels.\n\n#In the paper it's mentioned that MLP layer consists of 3 layers... following function will create a 3 layer\n#MLP projector with batchnorm and ReLU by default. Alternatively, you can change bn and nlayers. \n\n#Questions: Why torch.no_grad() when doing this?\ndef create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n    \"Create Barlow Twins model\"\n    n_in  = in_channels(encoder)\n    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n    apply_init(projector)\n    return BarlowTwinsModel(encoder, projector)\n\n#Similar to above. Simple API to make the BT model:","metadata":{"execution":{"iopub.status.busy":"2022-09-19T10:10:00.033384Z","iopub.execute_input":"2022-09-19T10:10:00.034084Z","iopub.status.idle":"2022-09-19T10:10:00.042621Z","shell.execute_reply.started":"2022-09-19T10:10:00.034047Z","shell.execute_reply":"2022-09-19T10:10:00.041644Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#BarlowTwins Callback\n#The following parameters can be passed:\n# - aug_pipelines\n# Imb lambda is the weight for redundancy reduction term in the loss function\n\n@delegates(get_multi_aug_pipelines)\ndef get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(n=2,size=size,**kwargs)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T10:10:00.045846Z","iopub.execute_input":"2022-09-19T10:10:00.046104Z","iopub.status.idle":"2022-09-19T10:10:00.054986Z","shell.execute_reply.started":"2022-09-19T10:10:00.046079Z","shell.execute_reply":"2022-09-19T10:10:00.053993Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Uniform random number between a and b\ndef Unif(a,b):\n    return (b-a)*torch.rand(1).item()+a","metadata":{"execution":{"iopub.status.busy":"2022-09-19T10:10:00.056334Z","iopub.execute_input":"2022-09-19T10:10:00.056788Z","iopub.status.idle":"2022-09-19T10:10:00.063326Z","shell.execute_reply.started":"2022-09-19T10:10:00.056752Z","shell.execute_reply":"2022-09-19T10:10:00.062415Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def random_polynomial(A):\n    \n    #B=torch.normal(mean=0, std=0.025, size=(1, 1)).item() #First Horner term (and is coefficient of x^4)\n    \n    #Btem = torch.normal(mean=0,std=0.05, size=(1, 1)).item() #Sample coefficient of x^3\n    #B = Btem + B*A #Third Horner term\n    \n    B = torch.normal(mean=0,std=0.5, size=(1, 1)).item() #Sample coefficient of x^2\n    \n#     Btem = torch.normal(mean=0,std=0.5, size=(1, 1)).item() #Sample coefficient of x^2\n#     B = Btem + B*A #Third Horner term\n    \n    Btem = random.choice([-1,1])*torch.normal(mean=0,std=1, size=(1, 1)).item() #Sample coefficient of x\n    #Btem=1\n    B = Btem + B*A #Fourth Horner term\n    \n    Btem = torch.normal(mean=0,std=1, size=(1, 1)).item() #Sample coefficient of x^0\n    B = Btem + B*A #Fifth Horner term\n    \n    \n    return B","metadata":{"execution":{"iopub.status.busy":"2022-09-19T06:20:31.062887Z","iopub.execute_input":"2022-09-19T06:20:31.063346Z","iopub.status.idle":"2022-09-19T06:20:31.076330Z","shell.execute_reply.started":"2022-09-19T06:20:31.063306Z","shell.execute_reply":"2022-09-19T06:20:31.075215Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"def random_polynomial_bestsofar(A):\n    \n    \n    B=torch.normal(mean=0, std=0.025, size=(1, 1)).item() #First Horner term (and is coefficient of x^4)\n    \n    Btem = torch.normal(mean=0,std=0.05, size=(1, 1)).item() #Sample coefficient of x^3\n    B = Btem + B*A #Third Horner term\n    \n    Btem = torch.normal(mean=0,std=0.5, size=(1, 1)).item() #Sample coefficient of x^2\n    B = Btem + B*A #Third Horner term\n    \n    Btem = random.choice([-1,1])*torch.normal(mean=1,std=2, size=(1, 1)).item() #Sample coefficient of x\n    B = Btem + B*A #Fourth Horner term\n    \n    Btem = torch.normal(mean=0,std=1, size=(1, 1)).item() #Sample coefficient of x^0\n    B = Btem + B*A #Fifth Horner term\n    \n    \n    return B","metadata":{"execution":{"iopub.status.busy":"2022-09-19T06:20:34.011877Z","iopub.execute_input":"2022-09-19T06:20:34.012326Z","iopub.status.idle":"2022-09-19T06:20:34.023926Z","shell.execute_reply.started":"2022-09-19T06:20:34.012284Z","shell.execute_reply":"2022-09-19T06:20:34.022841Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"def low_deg(A):\n    power=Unif(1,1.25)\n    coeff2 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n    coeff1 = torch.normal(mean=1, std=1, size=(1, 1)).item() #degree 2 term\n    \n#     coeff2 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n#     coeff1 = torch.normal(mean=1, std=0.7, size=(1, 1)).item() #degree 2 term\n\n#     coeff2 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n#     coeff1 = torch.normal(mean=0, std=1, size=(1, 1)).item() #degree 2 term\n\n    \n    B = (coeff1*A + coeff2*torch.abs(A).pow(power))\n    \n    #B = (1/power)*torch.abs(A).pow(power)\n    return B","metadata":{"execution":{"iopub.status.busy":"2022-09-19T06:20:36.918012Z","iopub.execute_input":"2022-09-19T06:20:36.918461Z","iopub.status.idle":"2022-09-19T06:20:36.931102Z","shell.execute_reply.started":"2022-09-19T06:20:36.918422Z","shell.execute_reply":"2022-09-19T06:20:36.930199Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"def random_quintic(A):\n\n    \n    B=torch.normal(mean=0, std=0.125, size=(1, 1)).item() #First Horner term (and is coefficient of x^4)\n    \n    Btem=torch.normal(mean=0, std=0.25, size=(1, 1)).item()#Sample coefficient of x^3\n    B = Btem + B*A #Second Horner term\n    \n    Btem = torch.normal(mean=0,std=0.5, size=(1, 1)).item() #Sample coefficient of x^2\n    B = Btem + B*A #Third Horner term\n    \n    Btem = random.choice([-1,1])*torch.normal(mean=1,std=2, size=(1, 1)).item() #Sample coefficient of x\n    B = Btem + B*A #Fourth Horner term\n    \n    Btem = torch.normal(mean=0,std=1, size=(1, 1)).item() #Sample coefficient of x^0\n    B = Btem + B*A #Fifth Horner term\n    \n    \n    return B","metadata":{"execution":{"iopub.status.busy":"2022-09-19T06:20:39.813382Z","iopub.execute_input":"2022-09-19T06:20:39.814036Z","iopub.status.idle":"2022-09-19T06:20:39.824153Z","shell.execute_reply.started":"2022-09-19T06:20:39.813992Z","shell.execute_reply":"2022-09-19T06:20:39.823117Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"def random_sinusoid(x,std=2.0):\n    \n    t=torch.normal(mean=1,std=std,size=(1,1)).item()\n    s=torch.normal(mean=1,std=std,size=(1,1)).item()\n    \n    u=torch.normal(mean=0,std=std,size=(1,1)).item()\n    v=torch.normal(mean=0,std=std,size=(1,1)).item()\n    \n    a=torch.normal(mean=0,std=2,size=(1,1)).item()\n    b=torch.normal(mean=0,std=2,size=(1,1)).item()\n    \n    return a*torch.sin(t*x+s) + b*torch.cos(u*x + v)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T06:20:42.732783Z","iopub.execute_input":"2022-09-19T06:20:42.733240Z","iopub.status.idle":"2022-09-19T06:20:42.748687Z","shell.execute_reply.started":"2022-09-19T06:20:42.733199Z","shell.execute_reply":"2022-09-19T06:20:42.747440Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"def poly_sinusoid(x):\n    \n    return (x) + 0.2*random_sinusoid(x,std=(0.5))","metadata":{"execution":{"iopub.status.busy":"2022-09-19T06:20:45.433727Z","iopub.execute_input":"2022-09-19T06:20:45.434179Z","iopub.status.idle":"2022-09-19T06:20:45.442958Z","shell.execute_reply.started":"2022-09-19T06:20:45.434132Z","shell.execute_reply":"2022-09-19T06:20:45.441837Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"#export\nclass BarlowTwins(Callback):\n    order,run_valid = 9,True\n    def __init__(self, aug_pipelines, lmb=5e-3, print_augs=False):\n        assert_aug_pipelines(aug_pipelines)\n        self.aug1, self.aug2 = aug_pipelines\n        if print_augs: print(self.aug1), print(self.aug2)\n        store_attr('lmb')\n        \n    def before_fit(self): \n        self.learn.loss_func = self.lf\n        nf = self.learn.model.projector[-1].out_features\n        self.I = torch.eye(nf).to(self.dls.device)\n            \n    def before_batch(self):\n        xi,xj = self.aug1(self.x), self.aug2(self.x)\n        self.learn.xb = (torch.cat([xi, xj]),)\n        \n        #Uncomment to run standard BT\n    \n#     def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n#         bs,nf = pred.size(0)//2,pred.size(1)\n\n#         z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n\n#         z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n#         z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n        \n#         C = (z1norm.T @ z2norm) / bs \n#         cdiff = (C - self.I)**2\n#         loss = (cdiff*self.I + cdiff*(1-self.I)*self.lmb).sum() \n#         return loss\n\n\n    def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n        bs,nf = pred.size(0)//2,pred.size(1)\n\n        #All standard, from BT\n        z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n        \n        \n        C = (z1norm.T @ z2norm) / bs \n        cdiff = (C - self.I)**2\n    \n        #polyprob=0.1\n        polyprob=0.5\n        temrand = random.random()\n        if temrand < polyprob: #With some probability we want off diag terms to be (quadratic) say.\n\n            p=Unif(1,2.5) \n            z1norm_2 = (1/p)*torch.abs(z1norm).pow(p)\n            z2norm_2 = z2norm\n                \n            C_2 = (z1norm_2.T @ z2norm_2) / bs\n            \n            cdiff_2 = (C_2)**2 #don't need to subtract I as only looking at off diag terms\n            \n        else:\n            cdiff_2 = cdiff\n            \n        l2 = cdiff_2*(1-self.I)*self.lmb #Is either the standard term - or not.\n\n        loss = (cdiff*self.I + l2).sum() \n        return loss\n\n    \n    @torch.no_grad()\n    def show(self, n=1):\n        bs = self.learn.x.size(0)//2\n        x1,x2  = self.learn.x[:bs], self.learn.x[bs:] \n        idxs = np.random.choice(range(bs),n,False)\n        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n        images = []\n        for i in range(n): images += [x1[i],x2[i]] \n        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T13:36:19.050256Z","iopub.execute_input":"2022-09-19T13:36:19.050642Z","iopub.status.idle":"2022-09-19T13:36:19.086273Z","shell.execute_reply.started":"2022-09-19T13:36:19.050609Z","shell.execute_reply":"2022-09-19T13:36:19.085253Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#Debugging cell - delete later (similar to cell below)\nps=500\nhs=500\nfastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\nmodel = create_barlow_twins_model(fastai_encoder, hidden_size=hs,projection_size=ps)# projection_size=1024)\n#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n#values for these which is tantamount to doing nothing\n#So if we choose resize_scale=(1,1) then the images look the same.\n#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\naug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=True)\n#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\nlearn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\nlearn.fit(100) #300                                        ","metadata":{"execution":{"iopub.status.busy":"2022-09-19T13:36:26.314293Z","iopub.execute_input":"2022-09-19T13:36:26.316743Z","iopub.status.idle":"2022-09-19T14:02:55.046511Z","shell.execute_reply.started":"2022-09-19T13:36:26.316709Z","shell.execute_reply":"2022-09-19T14:02:55.045453Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\nPipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>136.099976</td>\n      <td>41.519657</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>88.174271</td>\n      <td>13.525490</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>65.374908</td>\n      <td>26.159662</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>51.176849</td>\n      <td>61.788338</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>42.769154</td>\n      <td>18.507498</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>35.757847</td>\n      <td>53.210247</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>29.321001</td>\n      <td>7.492244</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>25.068064</td>\n      <td>47.930939</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>21.252014</td>\n      <td>39.461460</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>22.491571</td>\n      <td>9.456011</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>20.094383</td>\n      <td>6.028588</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>18.640779</td>\n      <td>30.501902</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>17.700325</td>\n      <td>43.671944</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>17.272219</td>\n      <td>8.423700</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>17.210470</td>\n      <td>10.748483</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>15.659920</td>\n      <td>24.120571</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>14.846135</td>\n      <td>6.756354</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>15.263037</td>\n      <td>11.268993</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>13.675999</td>\n      <td>23.289940</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>12.962232</td>\n      <td>23.591473</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>11.960022</td>\n      <td>23.934269</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>11.938625</td>\n      <td>15.741775</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>11.637924</td>\n      <td>5.615319</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>11.745298</td>\n      <td>25.862484</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>12.072393</td>\n      <td>8.580202</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>11.656176</td>\n      <td>7.950951</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>11.237738</td>\n      <td>19.888802</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>10.380304</td>\n      <td>20.198650</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>10.522672</td>\n      <td>5.839951</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>10.698586</td>\n      <td>8.650082</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>10.726996</td>\n      <td>8.416714</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>9.962544</td>\n      <td>21.553411</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>8.879060</td>\n      <td>17.598942</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>8.550371</td>\n      <td>17.672510</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>8.677141</td>\n      <td>4.442843</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>9.289356</td>\n      <td>6.173241</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>9.123738</td>\n      <td>22.646408</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>9.051206</td>\n      <td>4.152276</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>8.472610</td>\n      <td>5.586523</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>8.331004</td>\n      <td>18.930336</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>8.620958</td>\n      <td>16.810516</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>8.650442</td>\n      <td>20.396065</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>10.567488</td>\n      <td>23.154831</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>10.071981</td>\n      <td>6.979825</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>9.040540</td>\n      <td>17.374199</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>8.285096</td>\n      <td>17.676960</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>7.372391</td>\n      <td>16.099421</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>7.347343</td>\n      <td>4.708536</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>7.061883</td>\n      <td>16.241188</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>6.971256</td>\n      <td>4.591987</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>7.367466</td>\n      <td>7.196270</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>6.847926</td>\n      <td>19.978104</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>6.986516</td>\n      <td>15.763485</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>6.497555</td>\n      <td>20.062908</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>6.393426</td>\n      <td>3.991289</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>6.265011</td>\n      <td>5.496987</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>6.031432</td>\n      <td>3.350845</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>5.853767</td>\n      <td>4.386597</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>6.069004</td>\n      <td>5.176787</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>6.993255</td>\n      <td>5.324559</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>6.959907</td>\n      <td>5.364801</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>6.505136</td>\n      <td>19.528011</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>6.487292</td>\n      <td>18.893429</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>6.810162</td>\n      <td>5.557024</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>6.679731</td>\n      <td>16.343538</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>6.653837</td>\n      <td>17.111736</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>6.506557</td>\n      <td>30.987867</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>6.218663</td>\n      <td>15.546576</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>5.707881</td>\n      <td>3.292636</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>5.142344</td>\n      <td>15.744425</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>6.208507</td>\n      <td>16.068747</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>6.337828</td>\n      <td>6.336907</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>7.152177</td>\n      <td>17.302975</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>7.748394</td>\n      <td>18.454128</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>6.863809</td>\n      <td>5.590024</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>7.010086</td>\n      <td>14.225071</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>5.894124</td>\n      <td>14.371109</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>5.415387</td>\n      <td>4.860999</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>5.312091</td>\n      <td>3.530771</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>5.405177</td>\n      <td>15.206650</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>5.518850</td>\n      <td>3.735584</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>6.416381</td>\n      <td>8.619268</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>5.801594</td>\n      <td>14.686865</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>5.463457</td>\n      <td>15.216768</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>5.514243</td>\n      <td>13.402066</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>5.305382</td>\n      <td>3.452555</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>5.050882</td>\n      <td>4.526126</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>4.839047</td>\n      <td>7.202619</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>4.673242</td>\n      <td>3.137321</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>4.491747</td>\n      <td>4.735501</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>5.085823</td>\n      <td>13.627488</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>5.663584</td>\n      <td>7.418882</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>5.922481</td>\n      <td>19.261436</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>5.557586</td>\n      <td>3.855668</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>5.582334</td>\n      <td>13.260197</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>5.111384</td>\n      <td>12.867776</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>5.179231</td>\n      <td>12.756020</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>4.605758</td>\n      <td>3.144145</td>\n      <td>00:16</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>4.664121</td>\n      <td>14.543975</td>\n      <td>00:15</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>5.452983</td>\n      <td>6.058989</td>\n      <td>00:16</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"# #Get the dataloader and set batch size \n# ts=512 #training set size\n# bs=256 \n# device='cpu'\n# path = untar_data(URLs.MNIST)\n# items = get_image_files(path/'training') #i.e. NOT testing!!!\n# items=items.shuffle()\n\n# items1 = items[0:ts]\n# split = RandomSplitter(valid_pct=0.5) #randomly split training set into training and validation\n# #tds = Datasets(items,splits=split(items)) #Do we want this?\n# tds = Datasets(items1, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items1)) #Or do we want this?\n# dls = tds.dataloaders(bs=bs, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n\n# #Evaluate linear classifier on this guy\n# items2 = items[ts:]\n# split = RandomSplitter(valid_pct=0.99) #randomly split training set into training and validation\n# tds_new = Datasets(items2, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items2)) #Or do we want this?\n# dls_new = tds_new.dataloaders(bs=bs, after_item=[ToTensor(), IntToFloatTensor()], device=device)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T11:19:32.561864Z","iopub.execute_input":"2022-09-15T11:19:32.562468Z","iopub.status.idle":"2022-09-15T11:19:59.557414Z","shell.execute_reply.started":"2022-09-15T11:19:32.562421Z","shell.execute_reply":"2022-09-15T11:19:59.555967Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.03% [15687680/15683414 00:01<00:00]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"#Get the dataloader and set batch size \nts=16384 #training set size\nbs=512\ndevice='cuda'\npath = untar_data(URLs.MNIST)\nitems = get_image_files(path/'training') #i.e. NOT testing!!!\n\n#probably want random seed\n#TODO\nimport random\nrandom.seed(20)\nitems=items.shuffle()\n\n\nitems1 = items[0:ts]\nsplit = RandomSplitter(valid_pct=0.01) #randomly split training set into training and validation\n#tds = Datasets(items,splits=split(items)) #Do we want this?\ntds = Datasets(items1, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items1)) #Or do we want this?\ndls = tds.dataloaders(bs=bs, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n\n\nitems0 = items[ts:ts+2000] #for fine tuning - randomly just choose 2000 guys to extract 20 for fine tuning\nd = {'0':0,'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0,'8':0,'9':0}\nITEMS=[]\nfor i in items0:\n    s=str(i).split('/training/')[1][0]\n    if d[s] is 0 or d[s] is 1:\n        ITEMS.append(i)\n        d[s]+=1\n#items0=ITEMS\n\nfor i in items0:\n    if i not in ITEMS:\n        ITEMS.append(i)\n\nsplitter = IndexSplitter(list(range(20)))\n\nsplit = splitter#randomly split training set into training and validation\ntds_tune = Datasets(ITEMS, [PILImageBW.create, [parent_label, Categorize()]], splits=split(ITEMS)) #Or do we want this?\ndls_tune = tds_tune.dataloaders(bs=20, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n#So we call dls_tune.valid for fine tuning\n\n\n#Evaluate linear classifier on this guy\nitems2 = items[ts+2000:]\n\nsplit = RandomSplitter(valid_pct=0.01) #randomly split training set into training and validation\ntds_test = Datasets(items2, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items2)) #Or do we want this?\ndls_test = tds_test.dataloaders(bs=bs, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-19T13:35:19.936529Z","iopub.execute_input":"2022-09-19T13:35:19.936907Z","iopub.status.idle":"2022-09-19T13:35:26.313182Z","shell.execute_reply.started":"2022-09-19T13:35:19.936872Z","shell.execute_reply":"2022-09-19T13:35:26.312223Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"#A \"reasonable\" composite augmentation: initially copy pasted BT. We run this cell a few times to check it makes sense\n#Also define encoder and model\nfastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\nmodel = create_barlow_twins_model(fastai_encoder, hidden_size=10,projection_size=10)# projection_size=1024)\n#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n#values for these which is tantamount to doing nothing\n#So if we choose resize_scale=(1,1) then the images look the same.\n#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\naug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=False)\n#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\nlearn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n\n#dls.valid.bs = len(dls.valid_ds) #Set the validation dataloader batch size to be the length of the validation dataset\n\nb = dls.one_batch()\nlearn._split(b)\nlearn('before_batch')\naxes = learn.barlow_twins.show(n=2)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T10:12:13.514342Z","iopub.execute_input":"2022-09-19T10:12:13.515047Z","iopub.status.idle":"2022-09-19T10:12:22.096586Z","shell.execute_reply.started":"2022-09-19T10:12:13.515008Z","shell.execute_reply":"2022-09-19T10:12:22.095608Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\nPipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x432 with 4 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#Simple linear classifier\nclass LinearClassifier(nn.Module):\n    \n    def __init__(self,zdim):\n        super().__init__()\n        self.fc1 = nn.Linear(zdim,10) #As 10 classes for mnist\n        \n    def forward(self,x):\n        x = cast(self.fc1(x),Tensor) #so we have to use cross entropy loss. cast is because using old version fastai \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-09-19T10:51:53.056515Z","iopub.execute_input":"2022-09-19T10:51:53.058819Z","iopub.status.idle":"2022-09-19T10:51:53.067915Z","shell.execute_reply.started":"2022-09-19T10:51:53.058774Z","shell.execute_reply":"2022-09-19T10:51:53.067001Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\n#Train Classifier on encoder(mnist) for (at the moment) one epoch\n\nfastai_encoder.eval()\n\nzdim=1024 #see above\nhead = LinearClassifier(zdim=zdim)\ndevice='cuda'\nhead.to(device)\noptimizer = torch.optim.Adam(head.parameters())\ncriterion = nn.CrossEntropyLoss()\n#EPOCHS=100\n\nfor epoch in range(100):\n    for x,y in dls_tune.valid:\n        #break \n        #b = dls.train.one_batch() #Seems need dls[0] or dls.train for training ... dls[1] is validation see here https://docs.fast.ai/data.core.html#DataLoaders.__getitem__\n        #x,y = b[0],b[1]\n\n        loss = criterion(head(fastai_encoder(x)),y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        #print(loss)\nprint('done')\n        ","metadata":{"execution":{"iopub.status.busy":"2022-09-19T14:06:59.108059Z","iopub.execute_input":"2022-09-19T14:06:59.108549Z","iopub.status.idle":"2022-09-19T14:07:17.815701Z","shell.execute_reply.started":"2022-09-19T14:06:59.108504Z","shell.execute_reply":"2022-09-19T14:07:17.814530Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#Test result of above cell on the validation set - assumes that batch size of valid-dataloader is = number of valid samples                                        \n\n# print('The validation batch size is: {} '.format(dls.valid.bs))\n# input()\n\n#b = dls.valid.one_batch()\n\nfastai_encoder.eval()\nN=len(dls_test.train)*bs #close to len(dls_test.train_ds) but not quite...\n\nnum_correct=0\nfor x,y in dls_test.train:\n\n    ypred = head(fastai_encoder(x))\n    correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n    num_correct += correct.sum()\nprint(num_correct/N)\nprint('done')\nprint(num_correct)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T14:07:17.818012Z","iopub.execute_input":"2022-09-19T14:07:17.818440Z","iopub.status.idle":"2022-09-19T14:07:53.561108Z","shell.execute_reply.started":"2022-09-19T14:07:17.818393Z","shell.execute_reply":"2022-09-19T14:07:53.559922Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"TensorCategory(0.8089)\ndone\nTensorCategory(33132.)\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"(0.8047, 0.8027)"},"metadata":{}}]},{"cell_type":"markdown","source":"random.seed(10)  \n**NB: Baseline with BT:\nrandom.seed(10), 500 epochs. \nBT: (0.7837,0.7964,0.7890)**  \nNow, hacking experiments\n100 learn epochs  \nQuad_polyprob10 = (0.7265,0.7308)  \nrandom_polynomial = (0.7233,0.7151)    \nlow_deg = (0.7153,0.7106).  \npoly_sinusoid_polyprob20 = (0.7229,0.7250)  \nrandom_quad_new2_polyprob100 = (0.6357) - this is not good.     \n300 learn_epochs  \npoly_sinusoid = 0.7541 \nCan see above for other base hps\n\nComments Quad_polyprob10 is literally just .pow(2)","metadata":{}},{"cell_type":"markdown","source":"Note: We should at least try training linear classifier head on dls.valid (i.e. on different data to what BT was trained on - I think right?). When we do this we get:\n\n","metadata":{}},{"cell_type":"markdown","source":"Hacking since ran out of GPU\nBase HPs: ts=512,bs=256, ps=hs=500,pp=1, learn_epochs=**200**, tune_epochs=**10**.\nRun_1: BT=0.6795, MBT=0.7303","metadata":{}},{"cell_type":"markdown","source":"Base HPs as before: ts=512,bs=256, ps=hs=500,pp=1, learn_epochs=1000, tune_epochs=100.\nSee random_polynomial above for implementation\n\n**Note: Using same random_polynomial as Version 6 notebook - so we record those \n(3) runs here and continue on given that mean was \"best so far\" (aside: although really best so far is ~ 0.92-ish, averaged over 5 or 6 runs (see some earlier notebooks). So we want to see how this random function does once we have 5 or 6 runs)**  \n**Run_1: 0.9274, Run_2: 0.9309, Run_3: 0.9202, Run_4: 0.9302, Run_5: 0.9236**   \n**Mean = 0.92646, which is basically what it was after 3 runs. Cool**\n\nComment: So ~92.5 is best mean performance so far. 92.6 with current system, got ~92.3-5 on some others. \n\n","metadata":{}},{"cell_type":"code","source":"from statistics import mean\nmean([0.9274,0.9309,0.9202])#,0.9302,0.9236])","metadata":{"execution":{"iopub.status.busy":"2022-09-14T08:45:51.812073Z","iopub.execute_input":"2022-09-14T08:45:51.812577Z","iopub.status.idle":"2022-09-14T08:45:51.846053Z","shell.execute_reply.started":"2022-09-14T08:45:51.812465Z","shell.execute_reply":"2022-09-14T08:45:51.844736Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"0.9261666666666667"},"metadata":{}}]},{"cell_type":"markdown","source":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"# #Just train a linear classifier (no encoder)\n# #Basically cell above but remove encoder and some re-shaping\nzdim=500 #see above\nhead = LinearClassifier(zdim=zdim)\nhead.to(device)\noptimizer = torch.optim.Adam(head.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n\nfor x,y in dls.train:\n    #break\n    #b = dls.train.one_batch() #see here https://docs.fast.ai/data.core.html#DataLoaders.__getitem__\n    #x,y = b[0],b[1]\n\n    x=x.view(bs,zdim)\n    x=cast(x, Tensor) #Have to do this when using old version of fastai for some reason...\n    \n    out = head(x)\n    loss = criterion(out,y)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Test result of above cell, (i.e. just a linear classifier), on the validation set - assumes that batch size of valid-dataloader is = number of valid samples                                        \n# num_correct=0\n# for x,y in dls_new.valid:\n\n#     x=x.view(x.shape[0],zdim)\n#     x=cast(x, Tensor) #Have to do this when using old version of fastai for some reason...\n    \n#     ypred = head(x)\n#     correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n#     num_correct += correct.sum()\n    \n# print(num_correct/len(dls_new.valid_ds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}