{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamish-haggerty/AI-hacking/blob/master/SSL/MNIST_Val_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qlm5tLGWad5",
        "outputId": "27184504-aa47-4563-f070-f635cb8c8f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting base_rbt\n",
            "  Cloning https://github.com/hamish-haggerty/base_rbt.git to /tmp/pip-install-2wqlmtzt/base-rbt_8160c4031f0748a5a76bffa42b46a7ed\n",
            "  Running command git clone -q https://github.com/hamish-haggerty/base_rbt.git /tmp/pip-install-2wqlmtzt/base-rbt_8160c4031f0748a5a76bffa42b46a7ed\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.8/dist-packages (from base_rbt) (1.5.27)\n",
            "Collecting kornia>=0.6.8\n",
            "  Downloading kornia-0.6.8-py2.py3-none-any.whl (551 kB)\n",
            "\u001b[K     |████████████████████████████████| 551 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fastai>=2.7.10 in /usr/local/lib/python3.8/dist-packages (from base_rbt) (2.7.10)\n",
            "Collecting self_supervised\n",
            "  Downloading self_supervised-1.0.4-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 403 kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (21.3)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (0.13.1+cu113)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (6.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (1.0.3)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (1.0.2)\n",
            "Requirement already satisfied: torch<1.14,>=1.7 in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (1.12.1+cu113)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (21.1.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (1.7.3)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (0.0.7)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.8/dist-packages (from fastai>=2.7.10->base_rbt) (3.4.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (2.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (4.64.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (1.21.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (1.0.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (1.10.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (3.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (2.4.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (8.1.5)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (0.7.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (3.0.10)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai>=2.7.10->base_rbt) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->fastai>=2.7.10->base_rbt) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<4->fastai>=2.7.10->base_rbt) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<4->fastai>=2.7.10->base_rbt) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fastai>=2.7.10->base_rbt) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fastai>=2.7.10->base_rbt) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fastai>=2.7.10->base_rbt) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fastai>=2.7.10->base_rbt) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai>=2.7.10->base_rbt) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai>=2.7.10->base_rbt) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4->fastai>=2.7.10->base_rbt) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<4->fastai>=2.7.10->base_rbt) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fastai>=2.7.10->base_rbt) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fastai>=2.7.10->base_rbt) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fastai>=2.7.10->base_rbt) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->fastai>=2.7.10->base_rbt) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->fastai>=2.7.10->base_rbt) (2022.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fastai>=2.7.10->base_rbt) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fastai>=2.7.10->base_rbt) (1.2.0)\n",
            "Collecting timm>=0.4.5\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[K     |████████████████████████████████| 549 kB 74.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 90.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm>=0.4.5->self_supervised->base_rbt) (3.8.0)\n",
            "Building wheels for collected packages: base-rbt\n",
            "  Building wheel for base-rbt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for base-rbt: filename=base_rbt-0.0.1-py3-none-any.whl size=20565 sha256=bb87f8376a18e7b181ec2156bcb7991092f773a9130dd6fa6e97fa68204f3ee3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ga8ofcu4/wheels/b3/25/be/8368facea57a956938db327bdd708e7f93ca5738de036e2c6e\n",
            "Successfully built base-rbt\n",
            "Installing collected packages: huggingface-hub, timm, kornia, self-supervised, base-rbt\n",
            "Successfully installed base-rbt-0.0.1 huggingface-hub-0.11.1 kornia-0.6.8 self-supervised-1.0.4 timm-0.6.12\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/hamish-haggerty/base_rbt.git#egg='base_rbt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx1uWKxoWSVf"
      },
      "outputs": [],
      "source": [
        "from base_rbt.base_model import * \n",
        "from base_rbt.base_lf import *\n",
        "from base_rbt.base_linear import *\n",
        "from base_rbt.helper import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1kEl1-wWSVg"
      },
      "outputs": [],
      "source": [
        "import self_supervised\n",
        "import torch\n",
        "from fastai.vision.all import *\n",
        "from self_supervised.augmentations import *\n",
        "from self_supervised.layers import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hKK_OSpWSVn"
      },
      "source": [
        "Step 1): We need the data, and to set all the hps. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1-_00FBWSVn"
      },
      "outputs": [],
      "source": [
        "#hps's\n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "cuda = (device=='cuda')\n",
        "seed=20 #Will have to try with different random seeds. Two times is probably enough \n",
        "n_in=1\n",
        "indim=1024 #find this by inspection, e.g. for resnet18 is 1024\n",
        "size=28\n",
        "ps=1024 #Will also try with other values e.g. 125, 1000 etc\n",
        "bs=128 #for training BT\n",
        "bs_val=20 #for training linear head\n",
        "bs_test=500\n",
        "ts_val=bs_val*4 #so 512, ~ 1% of 50000\n",
        "ts=10000\n",
        "\n",
        "n_epochs=300 #epochs for BT \n",
        "numfit = 200 #epochs for linear classifer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_nHsUKwH7nX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "92b022ed-3762-4a08-8db4-69ff371fef40"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.03% [15687680/15683414 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Let's get MNIST data in a nicer way\n",
        "\n",
        "path = untar_data(URLs.MNIST)\n",
        "items = get_image_files(path/'training') #i.e. NOT testing!!!\n",
        "items.sort()\n",
        "seed_everything(seed=seed)\n",
        "items=items.shuffle()\n",
        "label_func=RegexLabeller(pat = r'/training/(\\d)/')\n",
        "labels = [label_func(i) for i in items]\n",
        "\n",
        "items_train = items[0:ts] #train on ts samples\n",
        "labels_train = labels[0:ts]\n",
        "dls_train = ImageDataLoaders.from_lists(path,items_train, labels_train,bs=bs,\n",
        "                                  valid_pct=0.0,num_workers=2*(device=='cuda'),device=device,item_tfms=[ToTensor()],\n",
        "                                  img_cls=PILImageBW)\n",
        "\n",
        "items_tune = items[ts:ts+3000]\n",
        "labels_tune = labels[ts:ts+3000]\n",
        "\n",
        "items_test = items[ts+3000:ts+3000+ts] #test on ts samples. 3k held out for tuning\n",
        "labels_test = labels[ts+3000:ts+3000+ts]\n",
        "dls_test = ImageDataLoaders.from_lists(path,items_test, labels_test,bs=bs_test,\n",
        "                                  valid_pct=0.0,num_workers=2*(device=='cuda'),device=device,\n",
        "                                  img_cls=PILImageBW\n",
        "                                      )\n",
        "def tune_set(items0,seed=42):\n",
        "\n",
        "    seed_everything(seed=seed)\n",
        "    items=items0.shuffle()\n",
        "    raw=[]\n",
        "    items_tune20 = []\n",
        "    labels_tune20 = []\n",
        "\n",
        "    d = {'0':0,'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0,'8':0,'9':0}\n",
        "\n",
        "    for i in items:\n",
        "    \n",
        "        label = label_func(i)\n",
        "        if d[label] == 0 or d[label] == 1:\n",
        "            items_tune20.append(i)\n",
        "            labels_tune20.append(label)\n",
        "            d[label] += 1\n",
        "            raw.append(i)\n",
        "\n",
        "    dls_val = ImageDataLoaders.from_lists(path, items_tune20, labels_tune20,bs=20,\n",
        "                                  valid_pct=0.0,num_workers=2*(device=='cuda'),device=device,\n",
        "                                      img_cls=PILImageBW)\n",
        "\n",
        "    d = {'items_tune20':items_tune20,'labels_tune20':labels_tune20,'raw':raw,'dls_val':dls_val}\n",
        "    \n",
        "    return d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkInRE_hXwIW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "35af84eb-f379-4bab-fef0-373fbcca83a1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b86d2878099d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Test dls_train, dls_val, dls_test and that function `tune_set` is working\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/fastcore/test.py\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m\"`test` that `a==b`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# %% ../nbs/00_test.ipynb 25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/fastcore/test.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m\"`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# %% ../nbs/00_test.ipynb 16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: ==:\n20\n42"
          ]
        }
      ],
      "source": [
        "#Test dls_train, dls_val, dls_test and that function `tune_set` is working \n",
        "\n",
        "test_eq(seed,42)\n",
        "test_eq(ts,10000)\n",
        "\n",
        "x,y = dls_train.one_batch()\n",
        "test_eq(x.shape, [bs, 1, 28, 28])\n",
        "\n",
        "test_eq(len(dls_train.train_ds),ts)\n",
        "test_eq(len(dls_test.train_ds),ts)\n",
        "\n",
        "test_eq(len(dls_test.train)*bs_test,len(dls_test.train_ds))\n",
        "\n",
        "_tune_set = tune_set(items_tune,seed=seed+1)\n",
        "items_tune20,labels_tune20,dls_val,raw = _tune_set['items_tune20'],_tune_set['labels_tune20'], _tune_set['dls_val'],_tune_set['raw']\n",
        "\n",
        "\n",
        "my_dict = {i:labels_tune20.count(i) for i in labels_tune20}\n",
        "for i in my_dict.values():\n",
        "    test_eq(i,2)\n",
        "\n",
        "#test size\n",
        "test_eq(len(dls_val.train),1)\n",
        "test_eq(len(dls_val.train_ds),20)\n",
        "\n",
        "#test random seed (please note that this depends on random seed chosen above to sort initially, i.e. seed=42)\n",
        "_raw = tune_set(items_tune,seed=1)['raw']\n",
        "test_eq(_raw[0].name,'28316.png')\n",
        "\n",
        "_raw = tune_set(items_tune,seed=10)['raw']\n",
        "test_eq(_raw[11].name,'11658.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXzxMiteGiJo"
      },
      "source": [
        "Test the random seed:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ6k-Q3DWSVo"
      },
      "source": [
        "Patch in definition of loss function (BT for now):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#| export\n",
        "#Here we give the model API for `new idea` or `RAT` -> i.e. two projector networks\n",
        "\n",
        "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
        "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
        "class P4BarlowTwinsModel(Module):\n",
        "    \"\"\"An encoder followed by a projector\n",
        "    \"\"\"\n",
        "    def __init__(self,encoder,projector,projector2):\n",
        "        self.encoder = encoder\n",
        "        self.projector = projector\n",
        "        self.projector2 = projector2\n",
        "        \n",
        "    def forward(self,x): \n",
        "        tem = self.encoder(x)\n",
        "\n",
        "        return tem,self.projector(tem),self.projector(tem)\n",
        "\n",
        "def create_p4barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
        "    \"Create Barlow Twins model\"\n",
        "    n_in  = in_channels(encoder)\n",
        "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
        "    \n",
        "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
        "    apply_init(projector)\n",
        "    \n",
        "    projector2 = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
        "    apply_init(projector2)\n",
        "    \n",
        "    \n",
        "    return P4BarlowTwinsModel(encoder, projector,projector2)\n",
        "\n"
      ],
      "metadata": {
        "id": "4c0DoRzqmElH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92q7Qj1LYMHc"
      },
      "outputs": [],
      "source": [
        "#Eventually have to edit elsewhere i.e. in package (once stable)\n",
        "\n",
        "def C_z1z2(z1norm,z1norm_2,z2norm,z2norm_2,indep=True):\n",
        "\n",
        "    bs = z1norm.shape[0]\n",
        "\n",
        "    if indep == False:\n",
        "        assert z1norm.shape == z1norm_2.shape\n",
        "        C1 =  (z1norm.T @ z2norm_2) / bs\n",
        "        C2 = (z1norm_2.T @ z2norm) / bs\n",
        "        cdiff = (0.5*C1.pow(2) + 0.5*C2.pow(2))\n",
        "        \n",
        "    elif indep == True:\n",
        "        C =  (z1norm_2.T @ z2norm_2) / bs\n",
        "        cdiff = C.pow(2)\n",
        "    \n",
        "    return cdiff\n",
        "\n",
        "class Max_Corr(nn.Module):\n",
        "    def __init__(self,qs,act1='relu',act2='relu'):\n",
        "        super().__init__()\n",
        "        self.qs=qs\n",
        "        \n",
        "        self.fc1 = nn.Linear(qs,qs)\n",
        "        self.fc11 = nn.Linear(qs,qs)\n",
        "        self.fc2 = nn.Linear(qs,qs)\n",
        "        self.fc22 = nn.Linear(qs,qs)\n",
        "\n",
        "        # torch.nn.init.uniform_(self.fc1.weight, a=-0.01, b=0.01)\n",
        "        # torch.nn.init.uniform_(self.fc11.weight, a=-0.01, b=0.01)\n",
        "\n",
        "        # torch.nn.init.uniform_(self.fc2.weight, a=-0.01, b=0.01)\n",
        "        # torch.nn.init.uniform_(self.fc22.weight, a=-0.01, b=0.01)\n",
        "\n",
        "        if act1=='relu': self.act1=nn.ReLU() \n",
        "        elif act1 == 'sigmoid': self.act1 = nn.Sigmoid()\n",
        "\n",
        "        if act2=='relu': self.act2=nn.ReLU() \n",
        "        elif act2 == 'sigmoid': self.act2 = nn.Sigmoid()\n",
        "        \n",
        "        self.m1 = nn.Sequential(self.fc1,self.act1,self.fc11)\n",
        "        self.m2 = nn.Sequential(self.fc2,self.act2,self.fc22)\n",
        "\n",
        "    def forward(self,x,y):\n",
        "        return self.m1(x),self.m2(y)\n",
        "        \n",
        "#| export\n",
        "class Cdiff_Sup:\n",
        "    \n",
        "    def __init__(self,I,qs,inner_steps,indep=True,act1='relu',act2='sigmoid',mask=True):\n",
        "        \n",
        "        self.I=I\n",
        "        self.qs=qs\n",
        "        self.inner_steps=inner_steps\n",
        "        self.indep=indep\n",
        "\n",
        "        self.act1=act1\n",
        "        self.act2=act2\n",
        "\n",
        "        self.max_corr = Max_Corr(qs=qs,act1=self.act1,act2=self.act2)\n",
        "        if default_device().type == 'cuda':\n",
        "            self.max_corr.cuda()\n",
        "        \n",
        "    def inner_step(self,z1norm,z2norm):\n",
        "    \n",
        "        max_corr=self.max_corr\n",
        "        inner_steps=self.inner_steps\n",
        "        z1norm=z1norm.detach()\n",
        "        z2norm=z2norm.detach()\n",
        "\n",
        "        optimizer = torch.optim.Adam(list(max_corr.parameters()),lr=0.001)\n",
        "        #optimizer = torch.optim.SGD(list(max_corr.parameters()),lr=0.01)\n",
        "        \n",
        "        for i in range(inner_steps):\n",
        "\n",
        "            z1norm_2,z2norm_2=max_corr(z1norm,z2norm)\n",
        "            cdiff_2 = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,indep=self.indep)\n",
        "            inner_loss=-1*(cdiff_2*(1-self.I)).mean()\n",
        "            optimizer.zero_grad()\n",
        "            inner_loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        for p in max_corr.parameters():\n",
        "            p.requires_grad=False\n",
        "            \n",
        "        return max_corr\n",
        "    \n",
        "    def __call__(self,z1norm,z2norm):\n",
        "        \n",
        "            max_corr =  self.inner_step(z1norm,z2norm)\n",
        "            z1norm_2,z2norm_2 = max_corr(z1norm,z2norm)\n",
        "            cdiff_sup = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,indep=self.indep)\n",
        "            \n",
        "            return cdiff_sup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JJFBgdbvjHc"
      },
      "outputs": [],
      "source": [
        "class AttributeDict(dict):\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "\n",
        "HP = AttributeDict(t=0.5, #convexity level\n",
        "               indep_rand=True,indep_sup=False,enc_rand=False,enc_sup=True, \n",
        "               inner_steps=15,act1='relu',act2='sigmoid', #belong to sup term\n",
        "               K=10,phase_std=0.2,amp_std=0.2,off_std=1)\n",
        "\n",
        "\n",
        "def lf_rbt_enc(pred,I,lmb,\n",
        "               hp,\n",
        "               ):\n",
        "\n",
        "    pred_enc = pred[0]\n",
        "    pred = pred[1]\n",
        "    \n",
        "    bs,nf = pred.size(0)//2,pred.size(1)\n",
        "\n",
        "    #All standard, from BT\n",
        "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
        "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
        "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
        "    \n",
        "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:] #so z1 is bs*projection_size, likewise for z2\n",
        "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False) + 1e-7)\n",
        "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False) + 1e-7)\n",
        "\n",
        "    nf_enc = z1_enc.shape[1]\n",
        "    I_enc = torch.eye(nf_enc).to(device)\n",
        "\n",
        "    if hp.enc_rr:\n",
        "        z1norm_sup = z1norm_enc\n",
        "        z2norm_sup = z2norm_enc\n",
        "        qs_sup = nf_enc\n",
        "        I_sup = I_enc\n",
        "\n",
        "    else:\n",
        "        z1norm_sup = z1norm\n",
        "        z2norm_sup = z2norm\n",
        "        qs_sup = nf\n",
        "        I_sup = I\n",
        "    \n",
        "    if hp.enc_inv:\n",
        "        assert False\n",
        "        C = (z1norm_enc.T @ z2norm_enc) / bs\n",
        "        I_inv = I_enc\n",
        "        cdiff = (C - I_inv)**2\n",
        "\n",
        "    else:\n",
        "        C = (z1norm.T @ z2norm) / bs \n",
        "        I_inv = I\n",
        "        cdiff = (C - I)**2\n",
        "\n",
        "\n",
        "    #new stuff\n",
        "    C1 = (z1norm_enc.T @ z2norm) / bs\n",
        "    C2 = (z2norm_enc.T @ z1norm) / bs\n",
        "    cdiff_2 = 0.5*(C1-I).pow(2) + 0.5*(C2-I).pow(2)\n",
        "\n",
        "\n",
        "    CdiffSup = Cdiff_Sup(I=I_sup,qs=qs_sup,inner_steps=hp.inner_steps,indep=hp.indep_sup)\n",
        "    cdiff_sup = CdiffSup(z1norm_sup,z2norm_sup) #same shape as cdiff\n",
        "\n",
        "    rr=hp.t*(cdiff_sup*(1-I_sup)).sum()\n",
        "\n",
        "    #Uncomment\n",
        "    #loss = (cdiff*I_inv).sum() + rr  #sum of redundancy reduction term and invariance term\n",
        "    \n",
        "    loss = (cdiff_2*I_inv).sum() + lmb*(cdiff*(1-I)).sum()\n",
        "\n",
        "    #loss = (cdiff*I).sum() + lmb*(cdiff*(1-I)).sum() #standard BT\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#New. Temporary (maybe...)\n",
        "class AttributeDict(dict):\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "\n",
        "HP = AttributeDict(t=0.5, #convexity level\n",
        "               indep_rand=True,indep_sup=False,enc_rand=False,enc_sup=True, \n",
        "               inner_steps=15,act1='relu',act2='sigmoid', #belong to sup term\n",
        "               K=10,phase_std=0.2,amp_std=0.2,off_std=1)\n",
        "\n",
        "\n",
        "def lf_rbt_enc(pred,I,lmb,\n",
        "               hp,\n",
        "               ):\n",
        "\n",
        "    pred_enc = pred[0]\n",
        "    pred1 = pred[1]\n",
        "    pred2 = pred[2]\n",
        "    \n",
        "    bs,nf = pred1.size(0)//2,pred1.size(1)\n",
        "\n",
        "    #All standard, from BT\n",
        "    z1, z2 = pred1[:bs],pred1[bs:] #so z1 is bs*projection_size, likewise for z2\n",
        "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
        "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
        "    \n",
        "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:] #so z1 is bs*projection_size, likewise for z2\n",
        "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False) + 1e-7)\n",
        "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False) + 1e-7)\n",
        "\n",
        "    z1, z2 = pred2[:bs],pred2[bs:] #so z1 is bs*projection_size, likewise for z2\n",
        "    z1norm_2 = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
        "    z2norm_2 = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
        "\n",
        "    cdiff_inv = ((z1norm.T @ z2norm) / bs - I).pow(2)\n",
        "\n",
        "    cdiff_rr = ((z1norm_2.T @ z2norm_2) / bs).pow(2)\n",
        "  \n",
        "    loss = (cdiff_inv*I).sum() + lmb*(cdiff_rr*(1-I)).sum() #standard BT\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "_iSYtc4OkNxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hsvwxb-vQqt"
      },
      "outputs": [],
      "source": [
        "# #Using RBT_enc\n",
        "@patch\n",
        "def lf(self:BarlowTwins, pred,*yb): return lf_rbt_enc(pred,I=self.I,lmb=self.lmb,hp=HP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6skkWU7_gP_X"
      },
      "source": [
        "We also patch `before_epoch` so that we are training linear classifier:\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OyqJJ5q71X8"
      },
      "source": [
        "Setup for linear evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNh_jz3lp-G4"
      },
      "outputs": [],
      "source": [
        "aug_pipelines_val=[get_linear_batch_augs(size=28,stats=mnist_stats,resize=True,resize_scale=(0.4, 1.0))]\n",
        "\n",
        "# main_linear_eval = Main_Linear_Eval(size=size,n_in=n_in,numfit=numfit,indim=1024, #size,n_in=3 (color channels),number of epochs to fit linear, and output dimension of encoder\n",
        "#                     dls_val=dls_val,dls_test=dls_test, #dls for training linear and evaluating linear\n",
        "#                     stats=mnist_stats,\n",
        "#                     aug_pipelines_val=aug_pipelines_val, #aug_pipeline for training \n",
        "#                     encoder=None#encoder\n",
        "#                                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05S-yb_-8ZRq"
      },
      "source": [
        "Optional: Show linear augmentations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "u7xWsNHz8YWe",
        "outputId": "7e1804fb-a1a6-48e1-d541-a947032d6145"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline: RandomResizedCrop -> Normalize -- {'mean': tensor([[[[0.1310]]]], device='cuda:0'), 'std': tensor([[[[0.3080]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Pipeline: \n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_linear_batch(dls=dls_val,n_in=n_in,n=2,aug=aug_pipelines_val,print_augs=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5cJyxh77e2l"
      },
      "source": [
        "Patch linear evaluation into `after_epoch:`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWRf2xcaWSVo"
      },
      "source": [
        "Define encoder and model; Define augmentation pipelines; Define learner.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rio3NmayWSVp"
      },
      "outputs": [],
      "source": [
        "fastai_encoder = create_fastai_encoder(xresnet18(),pretrained=False,n_in=n_in)\n",
        "\n",
        "#If we are using a different model, this call will just look like `create_rat_model(...)`\n",
        "model = create_p3barlow_twins_model(fastai_encoder, hidden_size=ps,projection_size=ps,nlayers=3)\n",
        "\n",
        "aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=28,blur_r=(0.5,2),\n",
        "                    rotate=True,jitter=False,noise=True,bw=False,blur=True,solar=True, #Whether to use aug or not\n",
        "                    resize_scale=(0.5, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.05, rotate_deg=25,blur_s=11,sol_t=0.025,sol_a=0.025, #hps of augs\n",
        "                    flip_p=0.1, rotate_p=0.5,noise_p=0.5, jitter_p=0.3, bw_p=0.3, blur_p=0.5,sol_p=0.1, #prob of performing aug\n",
        "                    same_on_batch=False,stats=mnist_stats, cuda=(device=='cuda'))\n",
        "\n",
        "aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=28,blur_r=(0.5,2),\n",
        "                    rotate=True,jitter=False,noise=True,bw=False,blur=True,solar=True, #Whether to use aug or not\n",
        "                    resize_scale=(0.5, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.05, rotate_deg=25,blur_s=11,sol_t=0.025,sol_a=0.025, #hps of augs\n",
        "                    flip_p=0.1, rotate_p=0.5,noise_p=0.5, jitter_p=0.3, bw_p=0.3, blur_p=0.5,sol_p=0.1, #prob of performing aug\n",
        "                    same_on_batch=False,stats=mnist_stats, cuda=(device=='cuda'))\n",
        "\n",
        "\n",
        "#aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=True)\n",
        "\n",
        "# noise=True,rotate=True,jitter=True,bw=True,blur=True,solar=True, #Whether to use  given aug or not\n",
        "# resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.025, rotate_deg=30,jitter_s=.6,blur_s=(4,32),s1=None,sol_t=0.05,sol_a=0.05, #hps of diff augs\n",
        "# flip_p=0.5, rotate_p=0.3,noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3,sol_p=0.1, #prob of performing aug\n",
        "# same_on_batch=False,stats=imagenet_stats,cuda=default_device().type == 'cuda',xtra_tfms=[])\n",
        "\n",
        "aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
        "\n",
        "#If we are using a different `callback` to `BarlowTwins` then we can simply replace `BarlowTwins` with \n",
        "#e.g. `BarlowTriplets`. We can define in base_model and just import with no issues. \n",
        "learn = Learner(dls_train,model, cbs=[BarlowTwins(aug_pipelines,n_in=n_in,lmb=1/ps,print_augs=False)])\n",
        "#Set path of learn correctly\n",
        "#learn.path = Path('/content/drive/MyDrive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UScwnSGWSVp"
      },
      "source": [
        "Step 3): (Optional): View the augmentations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "asVfpgP2WSVp",
        "outputId": "dfb623e8-1e3c-4501-f8f3-92862c159a26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianNoise -> RandomGaussianBlur -- {'p': 1.0, 'prob': 0.5, 's': 11, 's1': None, 'blur_r': (0.5, 2), 'same_on_batch': False} -> RandomSolarize -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0} -> Normalize -- {'mean': tensor([[[[0.1310]]]], device='cuda:0'), 'std': tensor([[[[0.3080]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianNoise -> RandomGaussianBlur -- {'p': 1.0, 'prob': 0.5, 's': 11, 's1': None, 'blur_r': (0.5, 2), 'same_on_batch': False} -> RandomSolarize -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0} -> Normalize -- {'mean': tensor([[[[0.1310]]]], device='cuda:0'), 'std': tensor([[[[0.3080]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_bt_batch(dls=dls_train,n_in=n_in,aug=aug_pipelines,n=2,print_augs=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud1-aYvsWSVp"
      },
      "source": [
        "Step 4): Fit the learner:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COaBKO8z5vjl"
      },
      "source": [
        "All we have changed from \"best so far\" on current run is have _enc on both terms (sup and rand)\n",
        "instead of just on the _proj term"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vq_H-o2qJm0h"
      },
      "outputs": [],
      "source": [
        "def sample_hp():\n",
        "    \"Sample hps for training bt -- need number of inner_steps and a bunch of other stuff\"\n",
        "\n",
        "    t = random.uniform(0.04,0.09)\n",
        "\n",
        "    return AttributeDict({'t':0.01,\n",
        "    'inner_steps':0,\n",
        "   'indep_sup': False, #This will always be false for now\n",
        "   'enc_rr': False, #use encoder for rr term (else use projector)\n",
        "   'enc_inv':False}) #use encoder for invariance term (else use projector)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSyzMu_KDemu"
      },
      "outputs": [],
      "source": [
        "def train_rbt(hp):\n",
        "        \n",
        "    @patch\n",
        "    def lf(self:BarlowTwins, pred,*yb): return lf_rbt_enc(pred,I=self.I,lmb=self.lmb,hp=hp) #pass them to loss function\n",
        "  \n",
        "    #train\n",
        "    fastai_encoder = create_fastai_encoder(xresnet18(),pretrained=False,n_in=n_in)\n",
        "    model = create_p4barlow_twins_model(fastai_encoder, hidden_size=ps,projection_size=ps,nlayers=3)\n",
        "    learn = Learner(dls_train,model, cbs=[BarlowTwins(aug_pipelines,n_in=n_in,lmb=1/ps,print_augs=False)])\n",
        "    learn.fit(100)\n",
        "\n",
        "    return fastai_encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdB00UxSvQq3"
      },
      "outputs": [],
      "source": [
        "#Tune run for given hps\n",
        "\n",
        "def tune_valid(fastai_encoder):\n",
        "    fastai_encoder.eval() #eval mode\n",
        "    fastai_encoder = grad_on(fastai_encoder,on=False) #turn off gradients\n",
        "    acc_dict={}\n",
        "    for i in range(1):\n",
        "        dls_val = tune_set(items_tune,seed=seed+i)['dls_val']\n",
        "\n",
        "        main_linear_eval = Main_Linear_Eval(size=size,n_in=n_in,numfit=numfit,indim=1024, #size,n_in=3 (color channels),number of epochs to fit linear, and output dimension of encoder\n",
        "                                dls_val=dls_val,dls_test=dls_test, #dls for training linear and evaluating linear\n",
        "                                stats=mnist_stats,\n",
        "                                aug_pipelines_val=aug_pipelines_val, #aug_pipeline for training \n",
        "                                encoder=fastai_encoder #encoder\n",
        "                                            )\n",
        "        #main_linear_eval.encoder = self.encoder (usage within BT training)\n",
        "        acc=main_linear_eval()\n",
        "        acc_dict[i]=acc\n",
        "        \n",
        "    acc_dict['mean'] = (sum(list(acc_dict.values()))/len(acc_dict.values()))\n",
        "    print((sum(list(acc_dict.values()))/len(acc_dict.values())))\n",
        "    \n",
        "    return acc_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m-4RAd7OQNjo",
        "outputId": "0e0fa874-d6bd-4b2f-8270-a99dafd6fa9e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>295.284607</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>210.487518</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>160.665253</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>135.393188</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>119.851784</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>108.199944</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>100.637131</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>99.900658</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>89.592049</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>84.261963</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>78.276863</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>78.593376</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>74.584778</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>67.013893</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>63.979633</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>62.948814</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>62.205776</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>59.397881</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>55.956356</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>57.199902</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>55.128464</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>51.420559</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>51.897797</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>50.097950</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>51.039284</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>50.865402</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>49.543686</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>46.576950</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>44.726749</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>45.485699</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>46.392143</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>47.875381</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>45.408783</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>45.129311</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>41.745483</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>40.826012</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>41.710499</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>42.371437</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>43.368206</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>42.163521</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>40.014843</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>41.472881</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>40.551655</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>40.081921</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>37.790779</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>38.836742</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>38.682041</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>36.416916</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>36.353504</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>36.363506</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>37.489925</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>38.158707</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>37.686966</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>35.336384</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>35.491497</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>37.266815</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>36.399708</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>34.135475</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>36.376015</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>35.203075</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>32.754005</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>34.128704</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>34.567799</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>33.515163</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>33.948723</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>33.371479</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>35.498077</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>32.928139</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>33.545261</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>32.158913</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>32.661034</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>32.613052</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>33.304482</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>32.836948</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>33.048733</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>32.598991</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>32.291050</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>31.185490</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>29.988995</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>31.517996</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>30.911665</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>31.058632</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>30.015360</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>30.153761</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>29.193893</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>29.670143</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>30.373363</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>29.626490</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>29.458870</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>28.842093</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>28.901350</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>28.681997</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>29.433252</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>28.640751</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>28.325676</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>29.018648</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>29.009720</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>28.139124</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>29.153177</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>28.505814</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.509915</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.367116</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.243054</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.118436</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.997860</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.879673</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.772076</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.667195</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.565192</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.466016</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.378634</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.305335</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.228335</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.157006</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.090097</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.028422</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.970340</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.917945</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.880627</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.836381</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.793715</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.754164</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.720328</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.699316</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.668283</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.638810</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.611261</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.585239</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.560622</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.537654</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.516212</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.496473</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.477305</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.459707</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.442550</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.426669</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.411714</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.397303</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.383584</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.370467</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.358126</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.346289</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.335023</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.324201</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.313937</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.304204</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.294895</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.285910</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.277265</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.269026</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.261030</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.253507</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.246163</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.239139</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.232346</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.225819</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.219564</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.220903</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.214936</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.209137</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.203709</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.198438</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.193349</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.188503</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.183772</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.183965</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.179461</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.175101</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.170997</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.166949</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.163151</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.163784</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.159910</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.156185</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.152617</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.152884</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.149517</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.146328</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.143206</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.140261</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.137411</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.134510</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.131588</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.128697</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.126111</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.123326</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.120638</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.117964</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.115433</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.112974</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.110548</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.108196</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.105898</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.103710</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.101489</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.099324</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.097215</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.095170</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.093166</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.091234</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>0.089364</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.087495</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.085713</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>0.084003</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.082287</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>0.080609</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>0.078962</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>0.077365</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>0.079984</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.078379</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.076817</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>0.075348</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>0.079262</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.077782</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.076466</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>0.075156</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.073954</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>0.072766</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>0.071573</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.070337</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>0.069229</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>0.067977</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>0.066789</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>0.065541</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.064312</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>0.063100</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>0.061927</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>0.060752</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>0.064394</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.063151</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>0.061924</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>0.063922</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>0.062708</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>0.063641</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.062560</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>0.063379</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>0.062608</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>0.061957</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>0.061398</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.060761</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>0.059938</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>0.059059</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>0.058064</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.057027</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.056075</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>0.055024</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>0.057396</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>0.056309</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>0.055343</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.054299</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>0.053703</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>0.052686</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>0.051709</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>0.050757</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.049830</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>0.048890</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>0.047986</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>0.047109</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>0.049302</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.051082</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>0.050193</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>0.049812</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>0.049062</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>0.048487</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.047833</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>0.047166</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>0.046517</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>0.045970</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>0.045525</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.044784</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>0.044290</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>0.043666</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>0.042872</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>0.042081</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.041305</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>0.040556</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>0.039843</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>0.039142</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>0.038582</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.038604</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>0.037941</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>0.037261</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>0.036625</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>0.035964</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.035307</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.034659</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>0.034051</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>0.033446</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>0.032838</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.032271</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>0.031678</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.031129</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>0.030566</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>0.033986</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.033374</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>0.032771</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>0.032223</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>0.034048</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>0.033461</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6248999834060669\n",
            "{0: 0.6248999834060669, 'mean': 0.6248999834060669}\n",
            "0.6248999834060669\n",
            "{'t': 0.01, 'inner_steps': 0, 'indep_sup': False, 'enc_rr': False, 'enc_inv': False}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result={} #store the hp dict in here and the acc_dict results for the given hp\n",
        "for i in range(1):\n",
        "    hp = sample_hp() #sample hps\n",
        "    fastai_encoder = train_rbt(hp) #train encoder\n",
        "    acc_dict = tune_valid(fastai_encoder) #train head and evaluate\n",
        "    result[i] = {'hp':hp,'acc_dict':acc_dict} #so we are looking for the hp that has highest mean value for acc_dict\n",
        "    print(result[i]['acc_dict']) \n",
        "    print(result[i]['acc_dict']['mean'])\n",
        "    print(result[i]['hp'])\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BT baseline:\n",
        "- 300 epochs, ps=1024, seed=20:\n"
      ],
      "metadata": {
        "id": "k6rUqR3l-8RP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BT={0: 0.8694000244140625, 1: 0.845300018787384, 2: 0.9122999906539917, 3: 0.838100016117096, 4: 0.9002000093460083, 5: 0.8216999769210815, 6: 0.9039000272750854, 7: 0.9164999723434448, 8: 0.8743000030517578, 9: 0.8971999883651733, 'mean': 0.8778900027275085}\n"
      ],
      "metadata": {
        "id": "Xo-EGeNt_Dn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best results, with same setup as BT baseline. All using default weight initialization. \n"
      ],
      "metadata": {
        "id": "dNsKdE3ReXgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Result1:\n",
        "{'t': 0.02, 'inner_steps': 0, 'indep_sup': False, 'enc_rr': False, 'enc_inv': False}\n",
        "{0: 0.8932999968528748, 1: 0.8452000021934509, 2: 0.9171000123023987, 3: 0.8377000093460083, 4: 0.8809999823570251, 5: 0.8122000098228455, 6: 0.9028000235557556, 7: 0.9304999709129333, 8: 0.8733000159263611, 9: 0.9016000032424927, 'mean': 0.8794700026512146}\n",
        "\n",
        "#Result2: (best so far)\n",
        "{'t': 0.01, 'inner_steps': 0, 'indep_sup': False, 'enc_rr': False, 'enc_inv': False}\n",
        "{0: 0.8834999799728394, 1: 0.857200026512146, 2: 0.9282000064849854, 3: 0.847000002861023, 4: 0.9240999817848206, 5: 0.8668000102043152, 6: 0.8888999819755554, 7: 0.9265000224113464, 8: 0.8475000262260437, 9: 0.8841999769210815, 'mean': 0.8853900015354157}\n",
        "\n",
        "#Result3:\n",
        "{'t': 0.005, 'inner_steps': 0, 'indep_sup': False, 'enc_rr': False, 'enc_inv': False}\n",
        "{0: 0.8673999905586243, 1: 0.8457000255584717, 2: 0.8650000095367432, 3: 0.8216000199317932, 4: 0.9078999757766724, 5: 0.8263999819755554, 6: 0.8641999959945679, 7: 0.9205999970436096, 8: 0.8467000126838684, 9: 0.8812999725341797, 'mean': 0.8646799981594085}\n",
        "\n"
      ],
      "metadata": {
        "id": "sWSLeYY5eb0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimenting with weight intialization; same setup as BT baseline.\n"
      ],
      "metadata": {
        "id": "QE3i1JmZyJ--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normal, std=0.02, -> mean=0.8800599"
      ],
      "metadata": {
        "id": "6KmE9apZyLvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So basically the same as BT. Encouraging. Hypothesis."
      ],
      "metadata": {
        "id": "pRYcJ8rnekWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#This is with ps = 1024 = encoder dimension\n",
        "\n",
        "#So best value ~ 0.8 for {'t': t,'inner_steps': 0, 'indep_sup': False, 'enc_rr': True, 'enc_inv': True},\n",
        "#with the values of t given by:\n",
        "# t=0.02, mean = 0.762499988079071\n",
        "# t=0.01, ,mean = 0.79670 \n",
        "# t=0.005, mean = 0.762\n",
        "\n",
        "#{'t': t, 'inner_steps': 0, 'indep_sup': False, 'enc_rr': False, 'enc_inv': False}\n",
        "#t = 0.04, mean = 0.8391\n",
        "#t = 0.02, mean=0.84439\n",
        "#t = 0.01, mean=0.827700\n",
        "\n"
      ],
      "metadata": {
        "id": "CUvu-USNd-Re"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}