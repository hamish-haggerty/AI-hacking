{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamish-haggerty/AI-hacking/blob/master/SSL/BT_MNIST_new3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8jFsEXz_61O",
        "outputId": "0a6542bd-4fac-45bc-9a43-2210b9c1024f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: torchvision==0.12.0 in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: torchaudio==0.11.0 in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0) (2022.6.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastai==2.6.3 in /usr/local/lib/python3.7/dist-packages (2.6.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: self_supervised in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from self_supervised) (21.1.3)\n",
            "Requirement already satisfied: timm>=0.4.5 in /usr/local/lib/python3.7/dist-packages (from self_supervised) (0.6.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from self_supervised) (21.3)\n",
            "Requirement already satisfied: fastai>=2.2.7 in /usr/local/lib/python3.7/dist-packages (from self_supervised) (2.6.3)\n",
            "Requirement already satisfied: kornia>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from self_supervised) (0.6.7)\n",
            "Requirement already satisfied: fastcore<1.5,>=1.3.27 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (1.4.5)\n",
            "Requirement already satisfied: torch<1.12,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (6.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (1.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (3.2.2)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (7.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (1.3.5)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (0.0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (1.7.3)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (0.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (2.23.0)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (3.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai>=2.2.7->self_supervised) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.0.10)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.4.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (4.64.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.4.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (8.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.11.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.9.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.0.7)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.21.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4->fastai>=2.2.7->self_supervised) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->self_supervised) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4->fastai>=2.2.7->self_supervised) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.2.7->self_supervised) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.2.7->self_supervised) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.2.7->self_supervised) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.2.7->self_supervised) (2022.6.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai>=2.2.7->self_supervised) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai>=2.2.7->self_supervised) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4->fastai>=2.2.7->self_supervised) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.2.7->self_supervised) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.2.7->self_supervised) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.2.7->self_supervised) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai>=2.2.7->self_supervised) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai>=2.2.7->self_supervised) (2022.2.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai>=2.2.7->self_supervised) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai>=2.2.7->self_supervised) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (7.1.3)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.11.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest) (21.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (22.1.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (2.0.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytest) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipytest in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipytest) (7.9.0)\n",
            "Requirement already satisfied: pytest>=5.4 in /usr/local/lib/python3.7/dist-packages (from ipytest) (7.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ipytest) (21.3)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (1.11.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (1.1.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (22.1.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (2.0.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (4.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (2.0.10)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (57.4.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.18.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->ipytest) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipytest) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipytest) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ipytest) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipytest) (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0\n",
        "!pip install fastai==2.6.3 --no-deps\n",
        "!pip install self_supervised\n",
        "\n",
        "!pip install pytest\n",
        "!pip install ipytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BOv4kkJDag8r",
        "outputId": "d327617b-c6a0-4155-8c78-119e351ed3d3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Pk01WY_Dag8s"
      },
      "outputs": [],
      "source": [
        "import fastai\n",
        "import self_supervised\n",
        "import torch\n",
        "if torch.cuda.is_available():device='cuda'\n",
        "else:device='cpu'\n",
        "assert(fastai.__version__ == '2.6.3') #Check that version is 2.6.3\n",
        "from fastai.vision.all import *\n",
        "from self_supervised.augmentations import *\n",
        "from self_supervised.layers import *\n",
        "import inspect\n",
        "import warnings\n",
        "import random\n",
        "import math\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "AOjr_YCLag8t"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n",
        "from self_supervised.augmentations import *\n",
        "from self_supervised.layers import *\n",
        "import inspect\n",
        "import warnings\n",
        "import random\n",
        "import math\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import ipytest\n",
        "ipytest.autoconfig()\n",
        "import pytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "XTSdKC6bag8t"
      },
      "outputs": [],
      "source": [
        "#Like most other SSL algorithms BT's model consists of an encoder and projector (MLP) layer.\n",
        "#Definition is straightforward:\n",
        "#https://colab.research.google.com/github/KeremTurgutlu/self_supervised/blob/master/nbs/14%20-%20barlow_twins.ipynb#scrollTo=1M6QcUChcvpz\n",
        "class BarlowTwinsModel(Module):\n",
        "    \"\"\"An encoder followed by a projector\n",
        "    \"\"\"\n",
        "    def __init__(self,encoder,projector):self.encoder,self.projector = encoder,projector\n",
        "        \n",
        "    def forward(self,x): return self.projector(self.encoder(x))\n",
        "\n",
        "\n",
        "#HOWEVER instead of directly using the above, by passing both an encoder and a projector, create_barlow_twins_model\n",
        "#function can be used by minimally passing a predefined encoder and the expected input channels.\n",
        "\n",
        "#In the paper it's mentioned that MLP layer consists of 3 layers... following function will create a 3 layer\n",
        "#MLP projector with batchnorm and ReLU by default. Alternatively, you can change bn and nlayers. \n",
        "\n",
        "#Questions: Why torch.no_grad() when doing this?\n",
        "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
        "    \"Create Barlow Twins model\"\n",
        "    n_in  = in_channels(encoder)\n",
        "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
        "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
        "    apply_init(projector)\n",
        "    return BarlowTwinsModel(encoder, projector)\n",
        "\n",
        "\n",
        "#BarlowTwins Callback\n",
        "#The following parameters can be passed:\n",
        "# - aug_pipelines\n",
        "# Imb lambda is the weight for redundancy reduction term in the loss function\n",
        "\n",
        "@delegates(get_multi_aug_pipelines)\n",
        "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(n=2,size=size,**kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "zU4GwLruU5AD"
      },
      "outputs": [],
      "source": [
        "def random_sinusoid(x,std=0.1,seed=0):\n",
        "    \n",
        "    seed_everything(seed=seed)    \n",
        "    t=(std) * torch.randn(1,500).to(device)\n",
        "    s=(std) * torch.randn(1,500).to(device)\n",
        "    \n",
        "    u=torch.randn(1,500).to(device)\n",
        "    v=torch.randn(1,500).to(device)\n",
        "\n",
        "    a=(0.1) * torch.randn(1,500).to(device)\n",
        "    b=(0.1) * torch.randn(1,500).to(device)\n",
        "\n",
        "\n",
        "    return a*torch.sin(t*x[:,]*math.pi+u) + b*torch.cos(s*x[:,]*math.pi+v)\n",
        "\n",
        "def C_z1z2(z1norm,z1norm_2,z2norm,z2norm_2,bs):\n",
        "    \n",
        "    C1 = (z1norm.T @ z2norm_2) / bs\n",
        "    C2 = (z1norm_2.T @ z2norm) / bs\n",
        "    \n",
        "    return 0.5*C1.pow(2) + 0.5*C2.pow(2)\n",
        "\n",
        "\n",
        "class Max_Corr(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(ps,ps)\n",
        "        self.fc2 = nn.Linear(ps,ps)\n",
        "\n",
        "        self.fc3 = nn.Linear(ps,ps)\n",
        "        self.fc4 = nn.Linear(ps,ps)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self,x,y):\n",
        "\n",
        "        x=self.sigmoid(self.fc1(x)) #when (sigmoid,relu) GREAT results, with (sigmoid,sigmoid) TERRIBLE. Currently testing (relu,relu)\n",
        "        x=self.fc2(x)\n",
        "       \n",
        "        y=self.relu(self.fc3(y)) #originally had relu and got really good results. If we can't reproduce those results, possible reasons:\n",
        "                                    #results were due to chance; or having relu on one branch (and sigmoid on the other) helps via breaking\n",
        "                                      #the symmetry! Other idea: set fc1=fc3, fc2=fc4. \n",
        "        y=self.fc4(y)\n",
        "\n",
        "        return x,y\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Cdiff_Rand:\n",
        "    \n",
        "    def __init__(self,seed,bs,std=0.1,K=2):\n",
        "        self.seed=seed\n",
        "        self.std=std\n",
        "        self.K=2\n",
        "        self.bs=bs\n",
        "\n",
        "    def __call__(self,z1norm,z2norm):\n",
        "        \n",
        "        cdiff_rand=0\n",
        "        for i in range(self.K):\n",
        "\n",
        "            z1norm_2,z2norm_2 = random_sinusoid(z1norm,std=self.std,seed=self.seed+i), random_sinusoid(z2norm,std=self.std,seed=2*self.seed+i)\n",
        "            cdiff_rand = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,bs=bs)\n",
        "\n",
        "        cdiff_rand=(1/self.K)*cdiff_rand\n",
        "    \n",
        "        return cdiff_rand\n",
        "  "
      ],
      "metadata": {
        "id": "wmu0k-GylYT2"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Cdiff_Sup:\n",
        "    \n",
        "    def __init__(self,I,inner_steps,bs):\n",
        "        \n",
        "        self.I=I\n",
        "        self.inner_steps=inner_steps\n",
        "        self.bs=bs\n",
        "        self.max_corr = Max_Corr()\n",
        "        if device == 'cuda':\n",
        "            self.max_corr.cuda()\n",
        "        \n",
        "    def inner_step(self,z1norm,z2norm):\n",
        "        max_corr = self.max_corr\n",
        "        I=self.I\n",
        "        bs=self.bs\n",
        "        z1norm=z1norm.detach()\n",
        "        z2norm=z2norm.detach()\n",
        "        optimizer = torch.optim.Adam(list(max_corr.parameters()),lr=0.001)\n",
        "    \n",
        "        for i in range(self.inner_steps):\n",
        "\n",
        "            z1norm_2,z2norm_2=max_corr(z1norm,z2norm)   \n",
        "            \n",
        "            assert (z1norm_2.shape,z2norm_2.shape) == (z1norm.shape,z2norm.shape)\n",
        "\n",
        "            cdiff_2 = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,bs=bs)\n",
        "            inner_loss=-1*(cdiff_2*(1-I)).mean()\n",
        "            optimizer.zero_grad()\n",
        "            inner_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        for p in max_corr.parameters():\n",
        "            p.requires_grad=False\n",
        "\n",
        "        return max_corr(z1norm,z2norm)\n",
        "    \n",
        "    def __call__(self,z1norm,z2norm):\n",
        "        \n",
        "            z1norm_2,z2norm_2 = self.inner_step(z1norm,z2norm)\n",
        "            cdiff_sup = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,bs=bs)\n",
        "    \n",
        "            return cdiff_sup\n"
      ],
      "metadata": {
        "id": "DpxxA0fXla87"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "a2Exs2s3ag8z"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class BarlowTwins(Callback):\n",
        "    order,run_valid = 9,True\n",
        "    def __init__(self, aug_pipelines, lmb=5e-3, print_augs=False):\n",
        "        assert_aug_pipelines(aug_pipelines)\n",
        "        self.aug1, self.aug2 = aug_pipelines\n",
        "        if print_augs: print(self.aug1), print(self.aug2)\n",
        "        store_attr('lmb')\n",
        "        \n",
        "    def before_fit(self): \n",
        "        self.learn.loss_func = self.lf\n",
        "        nf = self.learn.model.projector[-1].out_features\n",
        "        self.I = torch.eye(nf).to(self.dls.device)\n",
        "\n",
        "    def update_seed(self):\n",
        "        \n",
        "        indexmod=2\n",
        "        if self.index%indexmod == 0: #every `indexmod` index update the seed (best we have found so far)\n",
        "            self.seed = np.random.randint(0,10000)\n",
        "\n",
        "    def before_epoch(self):\n",
        "        self.index=-1\n",
        "            \n",
        "    def before_batch(self):\n",
        "        xi,xj = self.aug1(self.x), self.aug2(self.x)\n",
        "        self.learn.xb = (torch.cat([xi, xj]),)\n",
        "\n",
        "        self.index=self.index+1\n",
        "        self.update_seed()\n",
        "\n",
        "\n",
        "    def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n",
        "        bs,nf = pred.size(0)//2,pred.size(1)\n",
        "\n",
        "        print(bs)\n",
        "\n",
        "        #All standard, from BT\n",
        "        z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
        "        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
        "        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
        "        C = (z1norm.T @ z2norm) / bs \n",
        "        cdiff = (C - self.I)**2 #We use cdiff to get diagonal components of loss\n",
        "\n",
        "        CdiffSup = Cdiff_Sup(I=self.I,inner_steps=5,bs=bs) \n",
        "        cdiff_sup = CdiffSup(z1norm,z2norm) #`sup` off diagonal components of loss\n",
        "\n",
        "        CdiffRand = Cdiff_Rand(seed=self.seed,std=0.1,K=2,bs=bs)\n",
        "        \n",
        "        cdiff_rand = CdiffRand(z1norm,z2norm)#`random` off diagonal components\n",
        "        \n",
        "        cdiff_2 = 0.5*cdiff_rand + 0.5*cdiff_sup #convex combination of random component and sup component. We use\n",
        "                                                  #cdiff_2 to get off diagonal components of loss. \n",
        "        #First summand: Diagonal component    #Second summand: off diag component\n",
        "        loss = (cdiff*self.I + cdiff_2*(1-self.I)*self.lmb).sum()\n",
        "        torch.cuda.empty_cache()\n",
        "        return loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def show(self, n=1):\n",
        "        bs = self.learn.x.size(0)//2\n",
        "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:] \n",
        "        idxs = np.random.choice(range(bs),n,False)\n",
        "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
        "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
        "        images = []\n",
        "        for i in range(n): images += [x1[i],x2[i]] \n",
        "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "vbS1WtLiag80",
        "outputId": "23d85bcd-8bd1-4b2d-9b98-85b51eb13895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n",
            "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='0' class='' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/200 00:00&lt;?]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "      <progress value='15' class='' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      46.88% [15/32 00:03&lt;00:04 201.2159]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-016bc17bf181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#learn = Learner(dls, model,opt_func=opt_func, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-116-fb431cb95dd3>\u001b[0m in \u001b[0;36mlf\u001b[0;34m(self, pred, *yb)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mCdiffSup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCdiff_Sup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minner_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mcdiff_sup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCdiffSup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2norm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#`sup` off diagonal components of loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mCdiffRand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCdiff_Rand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-97-dda305c2cf57>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, z1norm, z2norm)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz1norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mz1norm_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2norm_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mcdiff_sup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_z1z2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz1norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz1norm_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz1norm_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz2norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2norm_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz2norm_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-97-dda305c2cf57>\u001b[0m in \u001b[0;36minner_step\u001b[0;34m(self, z1norm, z2norm)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz1norm_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2norm_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz1norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mcdiff_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_z1z2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz1norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz1norm_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz1norm_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz2norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2norm_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz2norm_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0minner_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdiff_2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-109-9cee906ac98d>\u001b[0m in \u001b[0;36mC_z1z2\u001b[0;34m(z1norm, z1norm_2, z2norm, z2norm_2, bs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mC1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz1norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mz2norm_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mC2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz1norm_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mz2norm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mC1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mC2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_torch_handled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_default_nowrap_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Debugging cell - delete later (similar to cell below)\n",
        "ps=500\n",
        "hs=500\n",
        "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
        "model = create_barlow_twins_model(fastai_encoder, hidden_size=hs,projection_size=ps)# projection_size=1024)\n",
        "#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n",
        "#values for these which is tantamount to doing nothing\n",
        "#So if we choose resize_scale=(1,1) then the images look the same.\n",
        "#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\n",
        "aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=True)\n",
        "#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwRMSProp(model.parameters(),lr=0.1, mom=0.9)ins(aug_pipelines, print_augs=True)])\n",
        "opt = torch.optim.RMSprop\n",
        "#partial(OptimWrapper, opt=opt)\n",
        "learn = Learner(dls,model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
        "#learn = Learner(dls, model,opt_func=opt_func, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
        "\n",
        "learn.fit(200) #300                            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Y5FN3Safag80"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=42):\n",
        "    \"\"\"\"\n",
        "    Seed everything.\n",
        "    \"\"\"   \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def tune_set(items0,tune_s=1000):\n",
        "    \n",
        "    items0=items0.shuffle()\n",
        "    d = {'0':0,'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0,'8':0,'9':0}\n",
        "    ITEMS=[]\n",
        "    for i in items0:\n",
        "        s=str(i).split('/training/')[1][0]\n",
        "        if d[s] is 0 or d[s] is 1:\n",
        "            ITEMS.append(i)\n",
        "            d[s]+=1\n",
        "    #items0=ITEMS\n",
        "\n",
        "    for i in items0:\n",
        "        if i not in ITEMS:\n",
        "            ITEMS.append(i)\n",
        "            \n",
        "    split = IndexSplitter(list(range(20)))\n",
        "\n",
        "    tds_tune = Datasets(ITEMS, [PILImageBW.create, [parent_label, Categorize()]], splits=split(ITEMS)) #Or do we want this?\n",
        "    dls_tune = tds_tune.dataloaders(bs=20, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n",
        "    \n",
        "    return dls_tune\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv4RE3O0ag81",
        "outputId": "5db4e0f0-1253-477f-d7da-49b00d2adcc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assert passed\n"
          ]
        }
      ],
      "source": [
        "#TODO: Do this in a slicker way. Write more tests \n",
        "#Get the dataloader and set batch size \n",
        "ts=16384 #training set size - most everything\n",
        "bs=512\n",
        "device='cuda'\n",
        "path = untar_data(URLs.MNIST)\n",
        "\n",
        "items = get_image_files(path/'training') #i.e. NOT testing!!!\n",
        "items.sort() \n",
        "\n",
        "seed=42\n",
        "seed_everything(seed=seed)\n",
        "labeller = using_attr(RegexLabeller(pat = r'(\\d+).png$'), 'name') \n",
        "\n",
        "items=items.shuffle()\n",
        "items1 = items[0:ts] #train on these guys\n",
        "\n",
        "l=labeller(items1[0])\n",
        "if seed is 42:\n",
        "    print('assert passed')\n",
        "    assert labeller(items1[0]) == '19825' #check that random seed is working\n",
        "\n",
        "else:\n",
        "    input('Careful! New random seed ~= 42. Is that ok?')\n",
        "\n",
        "split = RandomSplitter(valid_pct=0.0) #randomly split training set into training and validation\n",
        "#tds = Datasets(items,splits=split(items)) #Do we want this?\n",
        "tds = Datasets(items1, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items1)) #Or do we want this?\n",
        "dls = tds.dataloaders(bs=bs,num_workers=6, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n",
        "\n",
        "tune_s=2000 #we choose 20 guys (randomly) out of 1000 to tune on\n",
        "items0 = items[ts:ts+tune_s] #for fine tuning - just choose 2000 guys to extract 20 for fine tuning \n",
        "dls_tune=tune_set(items0,tune_s=tune_s)\n",
        "\n",
        "\n",
        "#NB: Uncomment and compare in colab and kaggle\n",
        "# for x,y in dls_tune.train:\n",
        "#   print(x.mean())\n",
        "#   input()\n",
        "#   break\n",
        "\n",
        "# for x,y in dls_tune.train:\n",
        "#   print(x.mean())\n",
        "#   input()\n",
        "#   break\n",
        "\n",
        "\n",
        "#Evaluate linear classifier on this guy\n",
        "test_bs=578\n",
        "items2 = items[ts+tune_s:]\n",
        "split = RandomSplitter(valid_pct=0.0) #randomly split training set into training and validation\n",
        "tds_test = Datasets(items2, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items2)) #Or do we want this?\n",
        "dls_test = tds_test.dataloaders(bs=test_bs, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n",
        "\n",
        "#Check that test_bs divides length of test set\n",
        "tem=len(dls_test.train_ds)/test_bs\n",
        "assert tem-math.floor(tem) == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "AKbw2pxMag82",
        "outputId": "07e65765-a9ae-42b5-9e8a-c05f4dab18b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n",
            "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAFUCAYAAACObE8FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVu0lEQVR4nO3d2XMdxRUH4LaNbXmTV3llMQFCUSkq+f/fU3lIUqmsBYmDXRhvgBdJxpJX8kCe6F+bmZKOLV193+PhzszVdc9hak6f7n0//vhjA6DG/rf9BQAWmSQLUEiSBSgkyQIUkmQBCkmyAIXe+YX/bn4X223f2/4C/2dss93i2PYkC1BIkgUoJMkCFJJkAQpJsgCFJFmAQpIsQCFJFqCQJAtQSJIFKCTJAhSSZAEKSbIAhSRZgEK/tNThrvHq1asu9uLFi0mx0fEvX77sYml333feyT/jgQMHutj+/f3/19LnRvF9+3bKSoHsFmnMpvGePpfG6+vi9PxSAIUkWYBCkixAIUkWoNCuK3yll/Ot5YLWkydPutjq6mo8fm1trYutr693sWfPnnWxpaWleM4UP3r0aBc7cuRIPD599tChQ13s4MGD8fhUnJgaa216kU0xbmeYc288ffq0i6VC70j6N0+F2tHYTMXiRS2mLeZfBbBDSLIAhSRZgEKSLEAhSRag0I6eXZCqpaMK6ObmZhe7e/duF7t582Y8/tq1a5OOTzMWjh07Fs+Z4idOnOhip06disefPXt20vFpFkJrrR0+fLiLpdkJo9kNKZ6qxaMK8tS2YuZL98aoZTzdGw8ePOhiaTZNmoXQWr4P0zhMY7i1PI7TeB21nO+mcbR7vinALiTJAhSSZAEKSbIAhXZ04SuteTl6EX///v0u9uWXX3axv/71r/H4GzdudLGHDx/+wjf8yZkzZ2I8vdyf2mrbWi6cpc+Ojk9FrvTZ06dPx+PPnTvXxVKRbnl5OR6fCmKpuMHrTS1ybWxsxOPv3bvXxb7++usulorC33//fTxnug/T2Pj444/j8ZcuXepiabyNxlYa2zu1VfftfwOABSbJAhSSZAEKSbIAhXZM4St1kKS1W0fFqK+++qqL/f73v+9i//jHP+Lx6aV/un56OZ8KXK1N39xxVMxL0u80Oj4VAn744YcuNlqHNBWpUuFu1PG2E4oOu8mc9WBTkevbb7+Nx//rX//qYqkAnIph3333XTxnujdWVla62O3bt+PxV65c6WIfffRRF3vvvffi8amT7Pjx411sVGhNYzOtkbsdayW7CwAKSbIAhSRZgEKSLEAhSRag0BufXTCqoD5//ryLpfUtv/nmm3j8n/70py6WqqrXr1+ffP1ULf3Vr37VxVKltLXcwjqnWpnW0kzHz6nip98/zYKYY/Rvytic9WCnziRI4721PMvmP//5TxdLreVp3dnWctU+ff/R35RmCaWZDKkluLXWrl692sXOnz/fxUYt42lGTGrVnbOe7eje9iQLUEiSBSgkyQIUkmQBCr3xwteczd7u3LnTxf7+97/H49NL/9QmmFpNW8stfZ9++mkX+81vftPF0kv41vJ6qnPaYtNvkgp0o980XSu9sE+tsq1N3whxO1oPF9nUDUHTv3druSD0xRdfdLE//OEP8fi//e1vXezWrVtdLLVcj+6XVBRO6yqPCkfpWqmYl8Z7a3md2/Sd3n///Xj85cuXu1hq1R2t1Zzu7WGRLEYB2BaSLEAhSRagkCQLUKi08JVe+I9eZKfOktSVMtoIMcXTi/SLFy/G49OL8N/+9rdd7He/+10XS5vCtZa7YuZ0+qQ1O7da+Eqx0Qv7I0eOdLFUCBgVR6wn+5OpG4KONi1M98Ef//jHLvbvf/87Hp+6ptLYfPfdd7vYhQsX4jlTPK3nmgpco3i6N0abQ6Zi4NraWhdLXaMjc7op0z2j8AXwFkiyAIUkWYBCkixAIUkWoNCOnl2QdqC9du1aPD5VYJ88edLFRrtXppbGVAFOleJRW2lanzJV4kfHp99vamzuZ5Op1dbR99du+5M0oyNVvVMbeGt5reR//vOfXWw0uyBVvVMb+WeffdbFUht5a3mWTvr3vn//fjw+7WK7urraxUYt5+k3TdcfrZU89X4f5as5azB7kgUoJMkCFJJkAQpJsgCF3vh6sqMXxulFdmorHbXZpRfUqUgzakFNhYi7d+92sfTCPhW4WstFptR6ODp+1K7KzjQqKqaxnVpA//vf/8bjU0Hrz3/+cxcbFZlSu2xa+/Xzzz/vYqm1fHR8Kjw9fvw4Hp82JE1txak1vrW8EWPKFydOnIjHpzWU0/02apWdU9T1JAtQSJIFKCTJAhSSZAEKvfGOr1QEGH02vXQeFYPSOqep8HXs2LHJ10/FievXr8fjk1SMS+twnjx5Mh6futOs0bpzjQpfqdiaCrip46m1XBBK66nOWbs1fac591sqHKXNBUf3WyqcpXsjFe1aa+3Ro0ddLBXZRt8/3XNp/eTtWCvZHQtQSJIFKCTJAhSSZAEKzS58zelqSYWf0cv5qS+yRx1jqUiUYqnjqrX80j51kKSCw+g7TV0WcbgBW3i5nrrDLClYa+qSkaNuwrSEXlpqL4230bVSkWY0DtP4SPdhKrCl4m9ruXCU7qEUG8XT2B51bJ0/f76Lpd95VGhP91bKF6Pvr/AFsENIsgCFJFmAQpIsQCFJFqDQa2cXpKrmqIKZZhKk1sG0uWFruTKYqo2XL1+Ox6dqX5pJkNr5Wmvt3LlzXWx5ebmLpd8kbQLZ2vQ2xdF6sqnaOWfNS+YZzZxJYz7NJBht+pcq9GnMpBk2rY3vmZ8bjaOp57xz504XG63nmqr+6fpzZs6kSv6ctt45bfxTN0Kc8/1HPMkCFJJkAQpJsgCFJFmAQrMLX6PiwFSjl/MrKytd7JNPPuliad3Y1nLRIRWuUoGrtVwQSy+900aKX3/9dTxnKm6kF/mpRbK1XFxIL/xHL+G1226PVCRJhd7RpoFp078568Gmf980Nkb3ZioAp8Jd+p7ffPNNPOfp06cnXWdOW20ar3PG8FaPr+JJFqCQJAtQSJIFKCTJAhQq3UgxGXVQpIJO2lhttDFbKqilYtao4yudN3WLpM+lgkFruYPn/v37XezWrVvx+FQMTN9/1BWzE1767yZzOr5SbKubhI7G9tWrV7vYpUuXuticf+80ZtLfNOpCS/GzZ892sdHflK5fMV53wj3gSRagkCQLUEiSBSgkyQIUkmQBCpXOLkjtgKNKeGqXTcenintruTU1tfmNdqtNsxOmtk6mmRGt5cpm2qV0NDshXWtUwWbrRrMLpq6rPGft0jQOP/zww3j8lStXulhaa3g0cye1nKfZAWmN2dEOumnMprbgOTMuFpUnWYBCkixAIUkWoJAkC1DotYWvOeszppfuUzcCbG36+pijl/spPnUjw9ZykS0VLNLfP3qJn176p2LaqLiQ1vzcSwWDSlv9HdN4GY3NVJRN6xqne6C1PGZToXi0LnEaXzdv3uxiN27c6GJpvLaWi1ypUDs6fi/xJAtQSJIFKCTJAhSSZAEKzS58zSk87SapSJUKBuvr611stIHexsZGF0u/6agYlzabG22ayDzp32H0247+fX7u1KlTMZ46AtNnU6G1telF5dEmpWkcpi6w1MW1uroaz5kKWumco8JX+lt3ew4ZcccCFJJkAQpJsgCFJFmAQpIsQKE3vlvtSGpznNP6OPWzo/Ut00yCtLNsaj28e/duPGdanzO1To529ExrjqYK7E7YkXMRjH7HNLsgxVLFv7Xc7prG4ZzxnmZCjGZHpPNObZkfnTO1fKfYaMbE1Pt9Eca2J1mAQpIsQCFJFqCQJAtQaHbha85mcyk2KjxNfZGeYq3lwtXU1r/W8sZy165d62J/+ctfuti9e/fiOVPBIxW+Ll++HI8/efJkF1vU1sNFsNXC2RxzCsXpnkmt4KlQO7rfpn6n0d85Z63q3c6TLEAhSRagkCQLUEiSBSg0++37qIMjFZRSbLT2alrLcm1tbdI5W8sbu6V1NEfXT91dt2/f7mKpu2tUcDh//nwXu3LlShe7ePFiPF7HFyNpzI3ujXRvpVi6X0aF6rTW8dRYa3trXeS985cCvAWSLEAhSRagkCQLUEiSBShUup5sqoDOWV8yfXZ0/NTPzlmzM1VGz54928VG68FevXq1i33yySddbGVlJR6fdh81k2DvSeM4tZGnGQOttXbr1q0ullrBNzc3u9hoFkCa+bK8vNzF5rTVLipPsgCFJFmAQpIsQCFJFqDQjt5IscLohXsqcp06daqLpcJXap9trbWPPvqoi6W22lQwGH2nvVQw4Cfp3kiFr9G6xl988UUXSy3jqcB2+vTpeM50H6TPKnx5kgUoJckCFJJkAQpJsgCFSgtf6eX2qIMkrZOaXpqPCmRp3ct0rdH6lqlrK10/bYQ4KnydO3eui6Vi2tLSUjzepol7y2hsp4JUWjv2+++/j8enNZDX19e7WOowTLHWcpdiGtsKX55kAUpJsgCFJFmAQpIsQCFJFqDQtu1Wm9r8Hj161MVGFdDUEvjgwYPJ32urbbmpCnrkyJEulmYXpLU1R8en2Q1mEfA6aeZM2lk23W+jz6b7JY3DUcv3mTNnuliaJWNse5IFKCXJAhSSZAEKSbIAhfa9qXVcAfYiT7IAhSRZgEKSLEAhSRagkCQLUEiSBSgkyQIUkmQBCkmyAIUkWYBCkixAIUkWoJAkC1BIkgUoJMkCFJJkAQpJsgCFJFmAQpIsQCFJFqCQJAtQSJIFKCTJAhSSZAEKSbIAhSRZgEKSLEAhSRagkCQLUOidX/jvP76Rb/EGPX/+PMZfvHjRxV69erWla73zTv/zHjx4sIvt37+n/l+3721/gf9buLE9ksb8Vsd2Ymznsb2nfgGAN02SBSgkyQIU+qV3srtaeu+U3r221trm5ubkz/7cgQMHYnzfvv4VTXpPC9th9J715cuXXSyN7R9/nP6aOr1rTffBHnsnG/kFAApJsgCFJFmAQpIsQCFJFqDQwpS6U2X02bNnXezhw4fx+BRPx6cZA8vLy/GcKysrMQ5blcb7aDbM2tpaF/vhhx8mnTON99ZaW1pa6mKnT5/uYnNm3iwqT7IAhSRZgEKSLEAhSRag0EIXvlKr7N27d+PxN2/e7GIbGxtdLC3n9sEHH8RznjlzJsZhq6aO99Zau337dhdLxbDUljtqA79w4UIXS4UvPMkClJJkAQpJsgCFJFmAQgtd+EpdLTdu3IjHf/nll10sFb4OHz7cxY4fPx7POSqIwVal8b6+vh4/+9VXX3Wxb7/9dtI5jx49Gs85itPzJAtQSJIFKCTJAhSSZAEKSbIAhRZmdkFqCUytg6nS2lpr169f72LPnz/vYmkmQZrF0FpeM3MvraNJnTTe58wuSOsnp11tT5w4Ec/561//uosZ25knWYBCkixAIUkWoJAkC1Bo1xW+Uutfa/mlfSp8jTZSTMWrqS/yRxspHjp0qIvt3+//a2xdKnytrq7Gz965c6eLPX78eEvXT/dGGtuKYZ5kAUpJsgCFJFmAQpIsQKGFKXylQsDTp0+72LNnz+LxqXCWXuSn2GizOS/92Q5pzM/p+EpFrtTNmMb2gQMH4jmXlpa62Og+2Os8yQIUkmQBCkmyAIUkWYBCkixAoYUpB45mHfxcqsq2lmcXpHOmz6XY6PgUMwuBudKYSzMGWsszBNJ9kGYHpN2ZW8st42SeZAEKSbIAhSRZgEKSLEChhSl8bVUqGqQiVWrV3djYiOd88eLFpHMqfPE6U9tqR4WvNA5TLBmNTWN2Ok+yAIUkWYBCkixAIUkWoNCuK3yNXrhvde3XVFx48uRJF0tFrrQJY2t57dpUsLC5Itth1PU4tXMxGRXIUjyN7dF6tHuJuxugkCQLUEiSBSgkyQIUkmQBCu262QUjqUJ/8ODBLjaanZDaZR89ejTpnA8ePIjn3Nzc7GKpqmuXT+ZK43g0SyV9NrXgptkBaQy3lmfOpLFtdoEnWYBSkixAIUkWoJAkC1Bo11Vc5rTVppfuoxfx6UX+2trapOukz7WWW3BHGznCyNQiVyrKtpbHfBrv6TqjlvHUcp5abUffaS+tR+tJFqCQJAtQSJIFKCTJAhTadYWvOaauMdtaLgSsr693sbQ2Z/pca7loMHUdT3idOYWvVJBK3YypKHvo0KF4zocPH066Dp5kAUpJsgCFJFmAQpIsQKGFLnzNkZY6TAWtVBwYdXylrphU+BptgLeXumIYm9rxNVoyM8XTUoep+JvGcGu5qJvOaWx7kgUoJckCFJJkAQpJsgCFJFmAQgszuyBVK+dsNpdaAqeuBzuaXbC6utrFUgVXBZbtMBovKZ5mDaQZNqOxnWYXpOPxJAtQSpIFKCTJAhSSZAEKLUzhK0nra47Wx0ybzaUW2PRyf9R6mIoGc1oPoUoqXKVC79LSUjw+jfk5Rd29xJMsQCFJFqCQJAtQSJIFKLTQha9U5Dp27Fj87NGjR7vYqDvs51LBYBS3kSJvWio+pcJVKoaNCsVpreXNzc1J195rPMkCFJJkAQpJsgCFJFmAQpIsQKGFmV2Q1sw8fPhwF1teXo7Hnzx5soullsLUOpiqsq3lCmxqyx3NOEitvjBXmiWTZgKk8TraATe1jKf7YM7YXtT1kz3JAhSSZAEKSbIAhSRZgEILXfg6fvx4F7t06VI8/vz5813s7NmzXez+/ftdLBUMWpteHEibOLY2bmmENN7T+smt5eJVKkilou5oreQ05tPY1lbrSRaglCQLUEiSBSgkyQIUWujCV+rYWllZice/++67Xezjjz+edM5Tp07Fc6aullQIUBxgO6QOx9bymE1FsjReR12HqUiWimnGtidZgFKSLEAhSRagkCQLUEiSBSi0MLMLktROmFplW2vt888/72Jp7dcPP/ywi43WqH3//fe72JEjR7rYoq6jSZ2ps2layzsxT51xMNqxObWCpxkHZhd4kgUoJckCFJJkAQpJsgCFFqbwlQoBqfCVNkxsLbfQJvfu3etio3Vf33vvvS6WCg4KX8yVxkwqcLWWx3wqAD98+LCLjQpfaZ3Zx48fd7Hnz5/H4/fSfeBJFqCQJAtQSJIFKCTJAhRamMJXktbCHBUHLl++3MXSy/kPPvhg8vXTOrNpc8dRcQFGUpHo2LFj8bNpDeW0oeidO3cmX39jY6OLpY0UUxdYa3urE8zdDVBIkgUoJMkCFJJkAQpJsgCFFnp2QZLWzGwtrwmb1n599erV5Gul2Q3p+qPvBCNz1pO9ePFiF0uzab777rsultaNbS3P0knjfc79sqg8yQIUkmQBCkmyAIUkWYBCe67wlV7Oj+KjQgK8banwNSqgXrhwoYuljUPTusijttgzZ850sXPnznUxLeOeZAFKSbIAhSRZgEKSLEChPVf4gkUwdePQ1lo7ceJEF0sdXw8ePOhiT58+jedM3ZDp+jq+PMkClJJkAQpJsgCFJFmAQpIsQCGzC2BBjFpYU8t4aqFNbbkvX76M50yzG9IOtHtpV9oRT7IAhSRZgEKSLEAhSRag0D4vpgHqeJIFKCTJAhSSZAEKSbIAhSRZgEKSLECh/wGoTPupm7/fIQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#A \"reasonable\" composite augmentation: initially copy pasted BT. We run this cell a few times to check it makes sense\n",
        "#Also define encoder and model\n",
        "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
        "model = create_barlow_twins_model(fastai_encoder, hidden_size=10,projection_size=10)# projection_size=1024)\n",
        "#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n",
        "#values for these which is tantamount to doing nothing\n",
        "#So if we choose resize_scale=(1,1) then the images look the same.\n",
        "#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\n",
        "aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=False)\n",
        "#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
        "learn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
        "\n",
        "#dls.valid.bs = len(dls.valid_ds) #Set the validation dataloader batch size to be the length of the validation dataset\n",
        "\n",
        "b = dls.one_batch()\n",
        "learn._split(b)\n",
        "learn('before_batch')\n",
        "axes = learn.barlow_twins.show(n=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Kujpa-Lvag82"
      },
      "outputs": [],
      "source": [
        "#Simple linear classifier\n",
        "class LinearClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self,zdim):\n",
        "            \n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(zdim,10) #As 10 classes for mnist\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = cast(self.fc1(x),Tensor) #so we have to use cross entropy loss. cast is because using old version fastai \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "QJTzqSefag83"
      },
      "outputs": [],
      "source": [
        "#NB: Will give same random 20-tune set (for fixed random seed), only if the cell\n",
        "#\"#Get the dataloader and set batch size\" is the same. Perhaps later we can make this cell a function of that one. \n",
        "#Functions to train and evaluate head\n",
        "fastai_encoder.eval()\n",
        "\n",
        "def train_head(seed=10): #The seed choses a different (20) samples for training the head. 2 of each class\n",
        "\n",
        "    seed_everything(seed=seed)\n",
        "    dls_tune=tune_set(items0,tune_s=tune_s) #different random tune set each time (but random seed same for consistency)\n",
        "  \n",
        "    zdim=1024 #see above\n",
        "    head = LinearClassifier(zdim=zdim)\n",
        "    device='cuda'\n",
        "    head.to(device)\n",
        "    optimizer = torch.optim.Adam(head.parameters())\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    #EPOCHS=100\n",
        "\n",
        "    for epoch in range(200):\n",
        "\n",
        "        #for x,y in dls_tune.valid: #Slows massively on colab but not on kaggle. Weird. \n",
        "        x,y=dls_tune.valid.one_batch() #Same every time since dataset only has length=batch size = 20\n",
        "  \n",
        "        loss = criterion(head(fastai_encoder(x)),y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(loss)\n",
        "\n",
        "    return head\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_head(head):\n",
        "\n",
        "    N=len(dls_test.train)*test_bs #close to len(dls_test.train_ds) but not quite...\n",
        "\n",
        "    assert N == len(dls_test.train_ds)\n",
        "\n",
        "    num_correct=0\n",
        "\n",
        "    for x,y in dls_test.train:\n",
        "    #for i in range(3):\n",
        "\n",
        "        ypred = head(fastai_encoder(x))\n",
        "        correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n",
        "        num_correct += correct.sum()\n",
        "    \n",
        "    return num_correct/N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VULhbDWawO_J",
        "outputId": "d68da8a5-83e1-40e1-9dee-744e00758119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8312)\n",
            "CPU times: user 43 s, sys: 3.92 s, total: 46.9 s\n",
            "Wall time: 1min 29s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'seed_0': TensorCategory(0.8274),\n",
              " 'seed_1': TensorCategory(0.7652),\n",
              " 'seed_2': TensorCategory(0.8897),\n",
              " 'seed_3': TensorCategory(0.8537),\n",
              " 'seed_4': TensorCategory(0.8198)}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "%%time\n",
        "seed=10\n",
        "performance_dict={}\n",
        "for num in range(5):\n",
        "\n",
        "    head=train_head(seed=seed+num)\n",
        "    pct_correct = eval_head(head)\n",
        "    performance_dict[f'seed_{num}'] = pct_correct\n",
        "    \n",
        "print(torch.mean(tensor(list(performance_dict.values()))))\n",
        "performance_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpcqDLMJWpkB",
        "outputId": "e3c6e55a-ce21-42cd-eb58-f85751fcc491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8312)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'seed_0': TensorCategory(0.8274),\n",
              " 'seed_1': TensorCategory(0.7652),\n",
              " 'seed_2': TensorCategory(0.8897),\n",
              " 'seed_3': TensorCategory(0.8537),\n",
              " 'seed_4': TensorCategory(0.8198)}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "#Current: With Max_cor = (sigmoid,relu), and fc1=fc3, fc2=fc4\n",
        "\n",
        "print(torch.mean(tensor(list(performance_dict.values()))))\n",
        "performance_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of the below have sin and cos with constant coefficients. If we take `best so far` and give it random coefficients a and b with std=0.2 then get:\n",
        "\n",
        "With fc1,fc2,fc3,fc4 distinct. Indexmod=2, K=2 With Max_corr = (sigmoid,relu);a~b = 0.2 x N(0,1) **0.8390, 0.8553** Conclusion: We need to search over the a and b parameters (coefficients of sinusoids) when we do our big search. Or rather search over std the hps controlling how we sample a and b. "
      ],
      "metadata": {
        "id": "-Rmtuu4nxc13"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SYRjUytI8Fw"
      },
      "source": [
        "Results (continuing from prior commit):\n",
        "\n",
        "\n",
        "Note these are with 200 learn_epochs etc. Same random seed. See above for other details (and we mention when recording the results below that we varied)\n",
        "BT = 0.7581\n",
        "\n",
        "(These are with fc1,fc2,fc3,fc4 distinct). Indexmod=2, K=2 \n",
        "**With Max_corr = (sigmoid,relu): 0.8493,0.8332,0.8392. Best so far.**\n",
        "With Max_corr = (sigmoid,sigmoid): 0.3080,0.3219.   \n",
        "With Max_corr = (relu,relu): 0.8132,0.8142,0.8093.   \n",
        "\n",
        "(These are with fc1=fc3, fc2=fc4. i.e. just one NN applied)  \n",
        "With Max_corr = (sigmoid,relu): 0.8359,0.8258,0.8303\n",
        "\n",
        "Above are all with indexmod=2. Now we try removing the indexmod condition.\n",
        "Then get:\n",
        "Indexmod=0\n",
        "With Max_corr = (sigmoid,relu): 0.8264,0.8253 \n",
        "\n",
        "Try indexmod=4\n",
        "With Max_corr = (sigmoid,relu):0.8174\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snRrKfwCH6XD"
      },
      "source": [
        "Results on different MBT runs (see above for implementation): tensor(0.8493) (trying to reproduce now) (just changed y=self.sigmoid(self.fc3(y))\n",
        "from relu in MaxCorr). Performance went to tensor(0.3080)!!! Crazy. Let's change y back to relu and see what happens. result: tensor(0.8332)!! Wow. Similar\n",
        "to before (i.e. evidence in favour of reproducibility). All we changed was sigmoid to relu!\n",
        "\n",
        "To summarise: Max_Corr had (sigmoid,relu) and got great results (on two diff MBT runs 0.8493 and 0.8332. When we changed relu to sigmoid, got terrible results (0.3080). (As an aside the loss jumped around a lot)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPEDQE-rcKjL",
        "outputId": "8e127c85-873f-4a36-d76a-66a57c566f74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.8252)\n"
          ]
        }
      ],
      "source": [
        "#250 learn_epochs. To beat: (K=10,indexmod=4,std=0.1,convex=(0.2,0.8))\n",
        "tem={'seed_0': TensorCategory(0.8364),\n",
        " 'seed_1': TensorCategory(0.7424),\n",
        " 'seed_2': TensorCategory(0.8947),\n",
        " 'seed_3': TensorCategory(0.8392),\n",
        " 'seed_4': TensorCategory(0.8133)}\n",
        "print(torch.mean(tensor(list(tem.values())))) #tensor(0.8252)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZPO88U4XMgb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYI6BiCTXCmt",
        "outputId": "c99dc95d-0a71-4fc3-d791-16cee98bfa8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.8487)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "hw0VjYxRx1va",
        "outputId": "659f5266-600d-4b32-a834-a84fff7d18b3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c8c02caa2cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperformance_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'performance_dict' is not defined"
          ]
        }
      ],
      "source": [
        "performance_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COooHESjoNGb"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}