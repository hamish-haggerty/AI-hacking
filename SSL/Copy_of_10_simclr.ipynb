{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "q636zMoWIzzV"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq self-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "zkii11-pIzzZ"
   },
   "outputs": [],
   "source": [
    "#default_exp vision.simclr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pd3jLRd0Izza"
   },
   "source": [
    "# SimCLR\n",
    "\n",
    "> **SimCLR**: [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709.pdf)\n",
    "\n",
    "> **SimCLR V2**: [Big Self-Supervised Models are Strong Semi-Supervised Learners](https://arxiv.org/pdf/2006.10029.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kDckfJefIzzc"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHz6YbgcIzzd"
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHeMuzBeIzzd"
   },
   "source": [
    "#### SimCLR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4H1GovBgIzzd"
   },
   "source": [
    "![SimCLR Framework](https://github.com/KeremTurgutlu/self_supervised/blob/master/nbs/images/simclr.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRW8MG-ZIzze"
   },
   "source": [
    "SimCLR is a simple contrastive learning framework which uses 2 augmented views of the same image and InfoNCE loss for training. Different views of the same image are considered as positive examples whereas all the other images images in a batch are considered as negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjj1w1e_Izze"
   },
   "source": [
    "#### SimCLR V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwKBVeE5Izzf"
   },
   "source": [
    "![SimCLR V2 Framework](https://github.com/KeremTurgutlu/self_supervised/blob/master/nbs/images/simclr_v2.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWXnAbO1Izzf"
   },
   "source": [
    "SimCLR has a follow up paper with few minor changes and improvements. Code difference between `SimCLR` and `SimCLR V2` are minimal and there is good amount of overlap, that is why both versions are implemented here in the same module. Also, SimCLR V2 is more about the added step of knowledge distillation rather than the contrastive learning itself.\n",
    "\n",
    " - One difference in SimCLR V2 is that `MLP` module has 3 layers instead of 2.\n",
    "\n",
    " - Another difference is using a larger model for the pretraining/self supervised learning task. It is mentioned in the original paper that scaling up the model from ResNet-50 to ResNet-152 (3×+SK) gave 29% relative gain in top-1 accuracy when fine tuning with only 1% labeled data.\n",
    "\n",
    "- Also, a few addition to data augmentation pipeline happenned, such as adding gaussian blur.\n",
    "\n",
    "*Note that `self_supervised.augmentations` module is highly flexible, supporting all the augmentations from the popular self supervised learning algorithms by default, allowing to pass any custom augmentations and more. It should always be adjusted based on the data and problem at hand for best performance.*\n",
    "\n",
    "\n",
    "> **Qote from SimCLR V2 paper:** In our experiments, we set the width of projection head’s middle layers to that of its input, so it is also adjusted by the width multiplier. However, a wider projection head improves performance even when the base network remains narrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZeOLeW_Izzh"
   },
   "source": [
    "SimCLR model consists of an `encoder` and a `projector (MLP)` layer. The definition of this module is fairly simple as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oB3h6Ax1Izzi"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class SimCLRModel(Module):\n",
    "    \"Compute predictions of concatenated xi and xj\" \n",
    "    def __init__(self,encoder,projector): self.encoder,self.projector = encoder,projector\n",
    "    def forward(self,x): return self.projector(self.encoder(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoYPGqqfIzzi"
   },
   "source": [
    "Instead of directly using `SimCLRModel` by passing both an `encoder` and a `projector`, `create_simclr_model` function can be used by minimally passing a predefined `encoder` and the expected input channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n5S4x5q1Izzi"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def create_simclr_model(encoder, hidden_size=256, projection_size=128, bn=False, nlayers=2):\n",
    "    \"Create SimCLR model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    return SimCLRModel(encoder, projector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLQeI3KzIzzj"
   },
   "source": [
    "You can use `self_supervised.layers` module to create an encoder. It supports all **timm** and **fastai** models available out of the box.\n",
    "\n",
    "We define number of input channels with `n_in`, projector/mlp's hidden size with `hidden_size`,  projector/mlp's final projection size with `projection_size` and projector/mlp's number of layers with `nlayers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VBjZTigIzzj",
    "outputId": "73082ad7-4f89-4adc-f023-4a3aeee53dd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = create_encoder(\"tf_efficientnet_b0_ns\", n_in=3, pretrained=False, pool_type=PoolingType.CatAvgMax)\n",
    "model = create_simclr_model(encoder, hidden_size=2048, projection_size=128, nlayers=2)\n",
    "out = model(torch.randn((2,3,224,224))); out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JC9oLblhIzzk"
   },
   "source": [
    "## SimCLR Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AieTbaHxIzzk"
   },
   "source": [
    "The following parameters can be passed;\n",
    "\n",
    "- **aug_pipelines** list of augmentation pipelines List[Pipeline] created using functions from `self_supervised.augmentations` module. Each `Pipeline` should be set to `split_idx=0`. You can simply use `get_simclr_aug_pipelines` utility to get aug_pipelines.\n",
    "- **temp** temperature scaling for cross entropy loss (defaults to paper's best value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awCJ-RTmIzzl"
   },
   "source": [
    "SimCLR algorithm uses 2 views of a given image, and `SimCLR` callback expects a list of 2 augmentation pipelines in `aug_pipelines`.\n",
    "\n",
    "You can simply use helper function `get_simclr_aug_pipelines()` which will allow augmentation related arguments such as size, rotate, jitter...and will return a list of 2 pipelines, which we can be passed to the callback. This function uses `get_multi_aug_pipelines` which then `get_batch_augs`. For more information you may refer to `self_supervised.augmentations` module.\n",
    "\n",
    "Also, you may choose to pass your own list of aug_pipelines which needs to be List[Pipeline, Pipeline] where Pipeline(..., split_idx=0). Here, `split_idx=0` forces augmentations to be applied in training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BOWHL6e9Izzl"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_simclr_aug_pipelines(size, **kwargs): return get_multi_aug_pipelines(n=2, size=size, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2lL2l1RIzzm",
    "outputId": "a31c78fa-cfbc-4eda-a8b1-bc8890d472e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline: RandomResizedCrop -> RandomHorizontalFlip,\n",
       " Pipeline: RandomResizedCrop -> RandomHorizontalFlip]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_pipelines = get_simclr_aug_pipelines(size=28, rotate=False, jitter=False, bw=False, blur=False, stats=None, cuda=False)\n",
    "aug_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0xikxojJIzzm"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class SimCLR(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines, temp=0.07, print_augs=False):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('temp')\n",
    "        \n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "                    \n",
    "            \n",
    "    def before_batch(self):\n",
    "        xi,xj = self.aug1(self.x), self.aug2(self.x)\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "        bs = self.learn.xb[0].shape[0]\n",
    "        self.learn.yb = (torch.arange(bs, device=self.dls.device).roll(bs//2),)\n",
    "    \n",
    "    \n",
    "    def _remove_diag(self, x):\n",
    "        bs = x.shape[0]\n",
    "        return x[~torch.eye(bs).bool()].reshape(bs,bs-1)    \n",
    "    \n",
    "    \n",
    "    def lf(self, pred, *yb):\n",
    "        pred, targ = F.normalize(pred, dim=1), yb[0]\n",
    "        sim = self._remove_diag(pred @ pred.T) / self.temp\n",
    "        targ = self._remove_diag(torch.eye(targ.shape[0], device=self.dls.device)[targ]).nonzero()[:,-1]\n",
    "        return F.cross_entropy(sim, targ)\n",
    "    \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1):\n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:] \n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]] \n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbnXGrSoIzzn"
   },
   "source": [
    "## Distributed SimCRL Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nblBeIKIzzn"
   },
   "source": [
    "`DistributedSimCLR` is a distributed implementation of InfoNCE Loss. It effectively increases the number of negative samples to all available samples across all GPUs during loss calculation. For example, if you use batch size of 16 per GPU and 8 GPUs, then the loss will be calculated using a similarity matrix with size of 16x8 x 16x8 = 1024x1024. In literature/experiments it's mentioned that more negatives help training.\n",
    "\n",
    "Following callback should be used together with `DistributedDataParallel` and inside a python script which will be executed in launch mode, such as:\n",
    "\n",
    "> **python -m fastai.launch script.py --FOLD 4 --size 640 --bs 12 --epochs 10 --lr 1e-3 --arch_name tf_efficientnet_b7_ns**\n",
    "\n",
    "For more details about distributed operations like `all gather`, see https://pytorch.org/tutorials/intermediate/dist_tuto.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tr_xGdXIzzn"
   },
   "source": [
    "> **Training Tip:** You can maximize your effective batchsize by using gradient checkpointing (see **self_supervised.layers** module), fp16 (**Learner.to_fp16()** in fastai) and distributed callback. Don't worry if you don't have access to multiple GPUs, usually just using gradient checkpointing and fp16 is enough to increase your batch size to 256 and beyond. Which is enough to train highly competitive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QYvDD6UYIzzn"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from self_supervised.dist import GatherLayer\n",
    "\n",
    "class DistributedSimCLR(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines=[], temp=0.07, print_augs=False):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('temp')\n",
    "            \n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "                    \n",
    "            \n",
    "    def before_batch(self):\n",
    "        xi,xj = self.aug1(self.x), self.aug2(self.x)\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "        bs = self.learn.xb[0].shape[0]\n",
    "        self.learn.yb = (torch.arange(bs, device=self.dls.device).roll(bs//2),)\n",
    "    \n",
    "    \n",
    "    def _remove_diag(self, x):\n",
    "        bs = x.shape[0]\n",
    "        return x[~torch.eye(bs).bool()].reshape(bs,bs-1)    \n",
    "    \n",
    "    \n",
    "    def lf(self, pred, *yb):\n",
    "        # gather and reorder\n",
    "        all_preds = list(GatherLayer.apply(pred)); all_preds.pop(rank_distrib())\n",
    "        all_preds = torch.cat([pred]+all_preds)\n",
    "        \n",
    "        pred, all_preds, targ = F.normalize(pred, dim=1), F.normalize(all_preds, dim=1), yb[0]\n",
    "        sim = self._remove_diag(pred @ all_preds.T) / self.temp\n",
    "        targ = self._remove_diag(torch.eye(targ.shape[0], device=self.dls.device)[targ]).nonzero()[:,-1]\n",
    "        return F.cross_entropy(sim, targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlWtawKIIzzn"
   },
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "KyjPVa9wIzzo",
    "outputId": "9737b147-3cc1-4e33-c079-fe076ee6613b"
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)\n",
    "tds = Datasets(items, [PILImageBW.create, [parent_label, Categorize()]], splits=GrandparentSplitter()(items))\n",
    "dls = tds.dataloaders(bs=5, after_item=[ToTensor(), IntToFloatTensor()], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oIHP5w4eIzzo",
    "outputId": "4d6277a2-7a06-405d-8cf6-6022a0ee9e06"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'named_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fastai_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxresnet18\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m create_simclr_model(fastai_encoder, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m, projection_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      3\u001b[0m aug_pipelines \u001b[38;5;241m=\u001b[39m get_simclr_aug_pipelines(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m, rotate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, jitter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, bw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, blur\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SSL/lib/python3.9/site-packages/self_supervised/layers.py:36\u001b[0m, in \u001b[0;36mcreate_encoder\u001b[0;34m(arch, pretrained, n_in, pool_type)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_encoder\u001b[39m(arch:\u001b[38;5;28mstr\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, pool_type\u001b[38;5;241m=\u001b[39mPoolingType\u001b[38;5;241m.\u001b[39mCatAvgMax):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA utility for creating encoder without specifying the package\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m(): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_fastai_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43march\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:                 \u001b[38;5;28;01mreturn\u001b[39;00m create_timm_encoder(arch, pretrained, n_in, pool_type)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SSL/lib/python3.9/site-packages/self_supervised/layers.py:22\u001b[0m, in \u001b[0;36mcreate_fastai_encoder\u001b[0;34m(arch, pretrained, n_in, pool_type)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_fastai_encoder\u001b[39m(arch:\u001b[38;5;28mstr\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, pool_type\u001b[38;5;241m=\u001b[39mPoolingType\u001b[38;5;241m.\u001b[39mCatAvgMax):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate timm encoder from a given arch backbone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 22\u001b[0m     encoder \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     pool \u001b[38;5;241m=\u001b[39m AdaptiveConcatPool2d() \u001b[38;5;28;01mif\u001b[39;00m pool_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcatavgmax\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mAdaptiveAvgPool2d(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39mencoder, pool, Flatten())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SSL/lib/python3.9/site-packages/fastai/vision/learner.py:81\u001b[0m, in \u001b[0;36mcreate_body\u001b[0;34m(model, n_in, pretrained, cut)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_body\u001b[39m(model, n_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cut\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCut off the body of a typically pretrained `arch` as determined by `cut`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 81\u001b[0m     \u001b[43m_update_first_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cut \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m         ll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(model\u001b[38;5;241m.\u001b[39mchildren()))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SSL/lib/python3.9/site-packages/fastai/vision/learner.py:60\u001b[0m, in \u001b[0;36m_update_first_layer\u001b[0;34m(model, n_in, pretrained)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChange first layer based on number of input channels\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_in \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m first_layer, parent, name \u001b[38;5;241m=\u001b[39m \u001b[43m_get_first_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_layer, nn\u001b[38;5;241m.\u001b[39mConv2d), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChange of input channels only supported with Conv2d, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(first_layer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_channels\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected number of input channels, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(first_layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_channels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m while expecting 3\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SSL/lib/python3.9/site-packages/fastai/vision/learner.py:37\u001b[0m, in \u001b[0;36m_get_first_layer\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess first layer of a model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m c,p,n \u001b[38;5;241m=\u001b[39m m,\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# child, parent, name\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_parameters\u001b[49m())[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     38\u001b[0m     p,c\u001b[38;5;241m=\u001b[39mc,\u001b[38;5;28mgetattr\u001b[39m(c,n)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c,p,n\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'named_parameters'"
     ]
    }
   ],
   "source": [
    "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
    "model = create_simclr_model(fastai_encoder, hidden_size=2048, projection_size=128)\n",
    "aug_pipelines = get_simclr_aug_pipelines(size=28, rotate=False, jitter=False, bw=False, blur=False, stats=None, cuda=False)\n",
    "learn = Learner(dls, model, cbs=[SimCLR(aug_pipelines, temp=0.07, print_augs=True),ShortEpochCallback(0.001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlLAv5wAIzzo"
   },
   "source": [
    "Also, with `show_one()` method you can inspect data augmentations as a sanity check. You can use existing augmentation functions from `augmentations` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "id": "wXWzozNqIzzo",
    "outputId": "39232fc4-c938-4f8c-9c18-5264dae20a48"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_FakeLoader' object has no attribute '_get_shared_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mdls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/fastai/data/load.py:177\u001b[0m, in \u001b[0;36mDataLoader.one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis DataLoader does not contain any batches\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfake_l\u001b[38;5;241m.\u001b[39mno_multiproc(): res \u001b[38;5;241m=\u001b[39m \u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mit\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mdelattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/fastcore/basics.py:626\u001b[0m, in \u001b[0;36mfirst\u001b[0;34m(x, f, negate, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(x)\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f: x \u001b[38;5;241m=\u001b[39m filter_ex(x, f\u001b[38;5;241m=\u001b[39mf, negate\u001b[38;5;241m=\u001b[39mnegate, gen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 626\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/fastai/data/load.py:132\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_iter()\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idxs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_idxs() \u001b[38;5;66;03m# called in context of main process (not workers/subprocesses)\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_l\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# pin_memory causes tuples to be converted to lists, so convert them back to tuples\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpin_memory \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(b) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m: b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(b)\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: b \u001b[38;5;241m=\u001b[39m to_device(b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, loader):\n\u001b[0;32m--> 683\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_SingleProcessDataLoaderIter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:594\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, loader: DataLoader) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mdataset\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shared_seed \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_shared_seed\u001b[49m()\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset, IterDataPipe):\n\u001b[1;32m    596\u001b[0m         shared_rng \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mGenerator()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_FakeLoader' object has no attribute '_get_shared_seed'"
     ]
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "# learn._split(b)\n",
    "# learn('before_batch')\n",
    "# axes = learn.sim_clr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SimCLR.show of SimCLR>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.sim_clr.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SimCLR.show of SimCLR>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#My stuff\n",
    "\n",
    "learn.sim_clr.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0SPNiGCJIzzo",
    "outputId": "9d55f39d-f951-48f8-847c-c2b19535282b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qFjJ7T68Izzp",
    "outputId": "53c604b0-be67-4c35-c7e2-444bd6b291c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorBase(2.6874)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.recorder.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1uql4tQIzzp"
   },
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFqMM5a5Izzp",
    "outputId": "b3d9bb89-5b65-4e03-9345-2770bdf5fe5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01 - augmentations.ipynb.\n",
      "Converted 02 - layers.ipynb.\n",
      "Converted 03 - distributed.ipynb.\n",
      "Converted 10 - simclr.ipynb.\n",
      "Converted 11 - moco.ipynb.\n",
      "Converted 12 - byol.ipynb.\n",
      "Converted 13 - swav.ipynb.\n",
      "Converted 20 - clip.ipynb.\n",
      "Converted 21 - clip-moco.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4aTaXb1YIzzq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqkKgKOIIzzq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of 10 - simclr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
