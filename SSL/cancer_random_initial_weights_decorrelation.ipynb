{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamish-haggerty/AI-hacking/blob/master/SSL/cancer_random_initial_weights_decorrelation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92vWYgIFXYbh"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamish-haggerty/AI-hacking/blob/master/SSL/cancer_validation_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bJO1nXHXYbj"
      },
      "source": [
        "# cancer_random_initial_weights_decorrelation\n",
        "\n",
        "> Purpose of this notebook is to implement our ensemble decorrelation idea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0PuDo3faXYbk"
      },
      "outputs": [],
      "source": [
        "#| default_exp cancer_random_initial_weights_decorrelation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyg-iyahXYbl"
      },
      "source": [
        "Setup: Surely there is a way to get rid of having to put this cell everywhere. hmmm.\n",
        "\n",
        "Or we can just copy paste / delete this in and out when needed. Either way, getting close to a decent workable workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAFkssKBXYbl",
        "outputId": "9b6bd75b-e84f-45da-ef47-440da48ead01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#| hide\n",
        "# import os\n",
        "# from google.colab import drive\n",
        "\n",
        "def colab_is_true():\n",
        "\n",
        "    try: \n",
        "        from google.colab import drive\n",
        "\n",
        "        return True \n",
        "    except ModuleNotFoundError:\n",
        "        return False\n",
        "\n",
        "def setup_colab():\n",
        "    from google.colab import drive\n",
        "    import os\n",
        "    drive.mount('/content/drive',force_remount=True)\n",
        "    #os.system('unzip -q \"/content/drive/My Drive/archive (1).zip\"')\n",
        "    os.system('git clone https://github.com/hamish-haggerty/cancer-proj.git')\n",
        "\n",
        "    os.chdir('cancer-proj')\n",
        "    \n",
        "    os.system('pip install .')\n",
        "    os.system('pip install -qU nbdev')\n",
        "    os.system('nbdev_install_quarto')\n",
        "\n",
        "    os.system('unzip -q \"/content/drive/My Drive/archive (1).zip\"') #does this work?\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    on_colab = colab_is_true()\n",
        "    if on_colab:\n",
        "        setup_colab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mEZyj1ycXYbm"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "from nbdev.showdoc import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6WBHcYiGXYbn"
      },
      "outputs": [],
      "source": [
        "#| export\n",
        "from fastai.vision.all import *\n",
        "from base_rbt.all import *\n",
        "from cancer_proj.cancer_dataloading import *\n",
        "from cancer_proj.cancer_metrics import *\n",
        "from cancer_proj.cancer_maintrain import *\n",
        "from self_supervised.augmentations import assert_aug_pipelines\n",
        "from self_supervised.layers import create_mlp_module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DvdPk2nXYbn"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nc37xCQwXYbn"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "#Since we have cloned repository and cd'd into it (and the data itself is not stored in the\n",
        "#repo) we need cd out of it, get the data, then cd back into the repo `cancer-proj`.\n",
        "#This is a bit annoying, can maybe remove this later\n",
        "if on_colab:\n",
        "    #os.chdir('..') #assumes we are currently in cancer-proj directory\n",
        "    train_dir = colab_train_dir\n",
        "    test_dir = colab_test_dir\n",
        "else:\n",
        "    train_dir = local_train_dir\n",
        "    test_dir = local_test_dir\n",
        "\n",
        "#define general hps\n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#bs=256\n",
        "#bs=698\n",
        "bs=256\n",
        "bs_tune=256\n",
        "size=128\n",
        "bs_val=174\n",
        "\n",
        "#get the data dictionary\n",
        "data_dict = get_fnames_dls_dict(train_dir=train_dir,test_dir=test_dir,\n",
        "                    device=device,bs_val=bs_val,bs=bs,bs_tune=bs_tune,size=size,n_in=3)\n",
        "\n",
        "#get the dataloaders\n",
        "dls_train,dls_tune,dls_valid = data_dict['dls_train'],data_dict['dls_tune'],data_dict['dls_valid']\n",
        "x,y = data_dict['x'],data_dict['y']\n",
        "xval,yval = data_dict['xval'],data_dict['yval']\n",
        "xtune,ytune = data_dict['xtune'],data_dict['ytune']\n",
        "vocab = data_dict['vocab']\n",
        "\n",
        "#If we want to write some tests (make sure the data is same every time etc):\n",
        "fnames,fnames_train,fnames_tune,fnames_valid,fnames_test = data_dict['fnames'],data_dict['fnames_train'],data_dict['fnames_tune'],data_dict['fnames_valid'],data_dict['fnames_test']\n",
        "\n",
        "test_eq(x.shape,xtune.shape)\n",
        "\n",
        "# if on_colab:\n",
        "#     os.chdir('cancer-proj')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOEtOKl9XYbo"
      },
      "source": [
        "## Load aug pipelines here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bLXKHGceXYbp"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "aug_dict = create_aug_pipelines(size=size,device=device,Augs=BYOL_Augs,TUNE_Augs=TUNE_Augs,Val_Augs=Val_Augs)\n",
        "aug_pipelines = aug_dict['aug_pipelines']\n",
        "aug_pipelines_tune = aug_dict['aug_pipelines_tune']\n",
        "aug_pipelines_test = aug_dict['aug_pipelines_test'] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NzY_8WjXYbp"
      },
      "source": [
        "## Optionally, display:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7GEptps-XYbp"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "#show_bt_batch(dls=dls_train,aug=aug_pipelines,n_in=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CNoEpeqzXYbq"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "#show_linear_batch(dls=dls_tune,n_in=3,aug=aug_pipelines_tune,n=2,print_augs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5SpFbkPAXYbq"
      },
      "outputs": [],
      "source": [
        "#| export\n",
        "\n",
        "@patch\n",
        "def lf(self:BarlowTwins, pred,*yb): return lf_bt(pred,I=self.I,lmb=self.lmb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY1LQWTTXYbq"
      },
      "source": [
        "## New API for ensemble decorrelation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eXbDh_xuXYbr"
      },
      "outputs": [],
      "source": [
        "#| export\n",
        "\n",
        "class P4BarlowTwinsModel(Module):\n",
        "\n",
        "    def __init__(self,model,encoder2,projector2):\n",
        "        self.model = model #frozen model\n",
        "        self.encoder2 = encoder2\n",
        "        self.projector2 = projector2\n",
        "\n",
        "        #put on GPU\n",
        "        if torch.cuda.is_available(): self.to(torch.device('cuda'))\n",
        "\n",
        "\n",
        "        \n",
        "    def forward(self,x,y):\n",
        "        \n",
        "        return self.model(x),self.projector2(self.encoder2(x))\n",
        "\n",
        "def create_p4barlow_twins_model(model,encoder2, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
        "    \"Create Barlow Twins model\"\n",
        "    n_in  = in_channels(encoder2)\n",
        "    with torch.no_grad(): \n",
        "        model.cpu()\n",
        "        encoder2.cpu()\n",
        "        \n",
        "        representation = encoder2(torch.randn((2,n_in,128,128)))\n",
        "\n",
        "    model.cpu()\n",
        "    encoder2.cpu()\n",
        "\n",
        "    projector2 = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
        "    apply_init(projector2)\n",
        "\n",
        "    return P4BarlowTwinsModel(model=model,encoder2=encoder2,projector2=projector2)\n",
        "\n",
        "\n",
        "class BarlowTwinsEns(Callback):\n",
        "    order,run_valid = 9,True\n",
        "    def __init__(self, aug_pipelines,n_in,t=0.1,s=0.1,lmb=5e-3, print_augs=False):\n",
        "        assert_aug_pipelines(aug_pipelines)\n",
        "        self.aug1, self.aug2 = aug_pipelines\n",
        "        if print_augs: print(self.aug1), print(self.aug2)\n",
        "        store_attr('lmb')\n",
        "        self.n_in=n_in\n",
        "        self.t=t\n",
        "        self.s=s\n",
        "        \n",
        "    def before_fit(self): \n",
        "        self.learn.loss_func = self.lf\n",
        "        nf = self.learn.model.projector2[-1].out_features\n",
        "        self.I = torch.eye(nf).to(self.dls.device)\n",
        "\n",
        "    def before_batch(self):\n",
        "        \n",
        "        #TODO: Make this nicer (possibly can load in data as TensorImage(BW) or something?)\n",
        "        #This is a bit of a hack. Can make this more elegant later. But in new version of FastAI\n",
        "        #seems we need to compute TensorImage(BW) here, and depends on whether color or not, i.e. n_in.\n",
        "        if self.n_in == 1:\n",
        "            \n",
        "            assert False\n",
        "\n",
        "            #Two distorted views according to first augmentation distribution\n",
        "            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug1(TensorImageBW(self.x))\n",
        "          \n",
        "            #Two distorted views according to second augmentation distribution\n",
        "            #xi_2,xj_2 = self.aug2(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
        "\n",
        "\n",
        "        elif self.n_in == 3:\n",
        "            \n",
        "            \n",
        "            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
        "            \n",
        "        \n",
        "        self.learn.xb = (torch.cat([xi, xj]),torch.cat([xi, xj]))\n",
        "\n",
        "\n",
        "    def before_epoch(self):\n",
        "        \n",
        "        ##########\"Best\" annealing schedule found so far\n",
        "        if self.epoch < 5:\n",
        "            self.t=0.5\n",
        "            self.s=0.5\n",
        "            \n",
        "        if self.epoch == 10:\n",
        "            self.t=0.25\n",
        "            self.s=0.25\n",
        "            \n",
        "        if self.epoch == 15:\n",
        "            self.t=0.125\n",
        "            self.s=0.125\n",
        "            \n",
        "        if self.epoch == 20:\n",
        "            self.t=0.05\n",
        "            self.s=0.05\n",
        "            \n",
        "        if self.epoch == 25:\n",
        "            self.t=0.025\n",
        "            self.s=0.025\n",
        "        ##########\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def show(self, n=1):\n",
        "        \n",
        "        x=self.learn.x[0]\n",
        "        y=self.learn.x[1]\n",
        "        \n",
        "        bs = x.size(0)//2\n",
        "        x1,x2  = x[:bs], x[bs:]\n",
        "        y1,y2  = y[:bs], y[bs:]\n",
        "        \n",
        "        idxs = np.random.choice(range(bs),n,False)\n",
        "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
        "        x2 = self.aug1.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
        "        \n",
        "        y1 = self.aug1.decode(y1[idxs].to('cpu').clone()).clamp(0,1)\n",
        "        y2 = self.aug1.decode(y2[idxs].to('cpu').clone()).clamp(0,1)\n",
        "        \n",
        "        images = []\n",
        "        for i in range(n): images += [x1[i],x2[i],y1[i],y2[i]]\n",
        "        show_batch(x1[0], None, images, max_n=len(images), nrows=n)\n",
        "\n",
        "        return\n",
        "    \n",
        "def show_btens_batch(dls,n_in,aug,n=2,print_augs=True):\n",
        "    \"Given a linear learner, show a batch\"\n",
        "        \n",
        "    learn = Learner(dls,model=None, cbs=[BarlowTwinsEns(aug,n_in=n_in,print_augs=print_augs)])\n",
        "    b = dls.one_batch()\n",
        "    learn._split(b)\n",
        "    learn('before_batch')\n",
        "    axes = learn.barlow_twins_ens.show(n=n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "m5QZhpbVXYbs",
        "outputId": "7b807424-5a9c-4e4f-d6a5-a0db5cd36772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> ColorJitter -> RandomGrayscale -> RandomGaussianNoise -> RandomGaussianBlur -- {'p': 1.0, 'prob': 1.0, 's': 13, 'sig': None, 'blur_r': (0.1, 2), 'same_on_batch': False} -> RandomSolarize -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n",
            "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> ColorJitter -> RandomGrayscale -> RandomGaussianNoise -> RandomGaussianBlur -- {'p': 1.0, 'prob': 0.1, 's': 13, 'sig': None, 'blur_r': (0.1, 2), 'same_on_batch': False} -> RandomSolarize -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#| hide\n",
        "show_btens_batch(dls_train,3,aug_pipelines,n=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zURWOipXXYbt"
      },
      "source": [
        "Next thing, is need to patch in the new loss function!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vJpY0W8YXYbt"
      },
      "outputs": [],
      "source": [
        "#| export\n",
        "\n",
        "class AttributeDict(dict):\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "    \n",
        "def lf_rbt_ens(pred,I,lmb,\n",
        "               t,\n",
        "               s,\n",
        "               ):\n",
        "\n",
        "    \n",
        "    pred1 = pred[0] #frozen\n",
        "    pred2 = pred[1] #has gradients\n",
        "    \n",
        "    \n",
        "    bs,nf = pred1.size(0)//2,pred1.size(1)\n",
        "\n",
        "    #All standard, from BT\n",
        "    z1, z2 = pred1[:bs],pred1[bs:] #so z1 is bs*projection_size, likewise for z2\n",
        "    z1norm = (z1 - z1.mean(0)) / (z1.std(0, unbiased=False) + 1e-7)\n",
        "    z2norm = (z2 - z2.mean(0)) / (z2.std(0, unbiased=False) + 1e-7)\n",
        "    \n",
        "    z1_2, z2_2 = pred2[:bs],pred2[bs:] #so z1 is bs*projection_size, likewise for z2\n",
        "    z1norm_2 = (z1_2 - z1_2.mean(0)) / (z1_2.std(0, unbiased=False) + 1e-7)\n",
        "    z2norm_2 = (z2_2 - z2_2.mean(0)) / (z2_2.std(0, unbiased=False) + 1e-7)\n",
        "    \n",
        "    #Make sure gradients are turned off / turned on appropriately\n",
        "    test_eq(pred1.requires_grad,False)\n",
        "    test_eq(pred2.requires_grad,True)\n",
        "\n",
        "    #Within frozen model \n",
        "    C = (z1norm.T @ z2norm) / bs \n",
        "    cdiff = (C - I)**2\n",
        "    \n",
        "    #Within model_2 (unfrozen)\n",
        "    C2 = (z1norm_2.T @ z2norm_2) / bs \n",
        "    cdiff_2 = (C2 - I)**2\n",
        "\n",
        "\n",
        "    #Between model term 2\n",
        "    C = (z1norm * z1norm_2) \n",
        "    cdiff_3 = (1/bs)*(C)**2\n",
        "    \n",
        "    C = (z2norm * z2norm_2) \n",
        "    cdiff_4 = (1/bs)*(C)**2\n",
        "    \n",
        "    cdiff_between = 0.5*cdiff_3 + 0.5*cdiff_4\n",
        "    \n",
        "    bt_loss = (cdiff_2*I).sum() + lmb*(cdiff_2*(1-I)).sum()\n",
        "\n",
        "    print(bt_loss)\n",
        "    print(cdiff_between/sum())\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    return bt_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MnUWZVUkXYbu"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "@patch\n",
        "def lf(self:BarlowTwinsEns, pred,*yb): return lf_rbt_ens(pred,I=self.I,lmb=self.lmb,t=self.t,s=self.s) #pass them to loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9THOzI2bXYbu",
        "outputId": "697b3373-97e4-461f-e662-7d0ddab7d278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train this guy the usual way\n",
            "then turn off gradients etc\n"
          ]
        }
      ],
      "source": [
        "#| export\n",
        "\n",
        "model,encoder = create_model('no_pretrain',device,ps=8192,n_in=3)\n",
        "\n",
        "print('train this guy the usual way')\n",
        "\n",
        "model.eval()\n",
        "model = grad_on(model,on=False)\n",
        "\n",
        "print('then turn off gradients etc')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(encoder.parameters()).device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTR-u3MXdBne",
        "outputId": "2bee83c8-b4f4-4bb6-a9e7-8a9379f05403"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_model??"
      ],
      "metadata": {
        "id": "A114Q7iPiq2W"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-H_unb1uXYbv"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "ps=8192\n",
        "_,encoder2 = create_model('no_pretrain',device,ps=ps,n_in=3)\n",
        "\n",
        "model2 = create_p4barlow_twins_model(model,encoder2,hidden_size=ps,projection_size=ps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ens_model(model,device,ps=8192,n_in=3):\n",
        "    \"Input a barlow twins model (encoder and projector) that has already been trained\"\n",
        "\n",
        "    #Put into eval mode and turn off gradient\n",
        "    model.eval()\n",
        "    model = grad_on(model,on=False)\n",
        "\n",
        "    _,encoder2 = create_model('no_pretrain',device,ps=ps,n_in=3)\n",
        "    model2 = create_p4barlow_twins_model(model,encoder2,hidden_size=ps,projection_size=ps)\n",
        "\n",
        "    encoder2 = model2.encoder2\n",
        "    if device == 'cuda':\n",
        "        model2.cuda()\n",
        "        encoder2.cuda()\n",
        "\n",
        "\n",
        "    return model2,encoder2\n"
      ],
      "metadata": {
        "id": "Ja-71R6Gk6sc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t2skhfXXYbv"
      },
      "source": [
        "No splitter needed at the moment since we are just using it on random initial weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-Kto4mcNXYbv"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "learn = Learner(dls_train,model2,cbs=[BarlowTwinsEns(aug_pipelines,n_in=3,lmb=1/8192,print_augs=False)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "L1Wa-u3TXYbv"
      },
      "outputs": [],
      "source": [
        "#learn.fit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1) Train several BT models (say for 100 epochs)\n",
        "\n",
        "## Step 2) Train several BT models, decorrelating from models in 1 (pairwise)\n",
        "\n",
        "## Step 3) Fine tune models in 1) and in 2)\n",
        "\n",
        "## Compare pairwise performance in 1) and in 2)"
      ],
      "metadata": {
        "id": "KgfrjNEj-TfP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-MCqGLoXYbw"
      },
      "source": [
        "## Note: using this default encoder, for random weights, doesn't seem to work real well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJMYVahcXYbw"
      },
      "source": [
        "## Note: we don't actually want to freeze the resnet when pretraining in this notebook, since the initial weights are random. So we just need to make sure encoder_fine_tune isn't doing that"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OWaZA2GXYbx"
      },
      "source": [
        "## Test: make sure that it freezes the appropriate part of model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qHR9zg9XYbx"
      },
      "source": [
        "Make sure resnet frozen, linear head unfrozen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9eaf101c0fdd45879814734484f14066",
            "d58165f9bd8647e488fc6166fc97e082",
            "44d29d1abfb6478791f33df288f95fa2",
            "07457b1065d34300800dc583057b4ace",
            "3f36256847c94420b5e8037c036cb72b",
            "e03315ea5e9f4e47aa4ab7fb366612e3",
            "782c74ebdda449c3a11c7ff80df03f8b",
            "6d882a52f2094b3187afebcdba009aa7",
            "b3d7e97865a54779954d556996958295",
            "592913c511b14d54b5c6d4dce76a0048",
            "d2aa7410ad53455ead6159b5280a407e"
          ]
        },
        "id": "Nt36oEd1XYbx",
        "outputId": "010fce7f-855d-4426-c2d2-f2994d4f97ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/barlowtwins/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/barlowtwins/ep1000_bs2048_lrw0.2_lrb0.0048_lambd0.0051/resnet50.pth\" to /root/.cache/torch/hub/checkpoints/resnet50.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/90.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9eaf101c0fdd45879814734484f14066"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "body should be frozen, (sans batchnorm) linear head unfrozen\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LM (Input shape: 256 x 3 x 128 x 128)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     256 x 64 x 64 x 64  \n",
              "Conv2d                                    9408       False     \n",
              "BatchNorm2d                               128        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "MaxPool2d                                                      \n",
              "Conv2d                                    4096       False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 32 x 32 \n",
              "Conv2d                                    32768      False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 16 x 16 \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 8 x 8   \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    2097152    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 1 x 1  \n",
              "AdaptiveAvgPool2d                                              \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048          \n",
              "Flatten                                                        \n",
              "____________________________________________________________________________\n",
              "                     256 x 9             \n",
              "Linear                                    18441      True      \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 23,526,473\n",
              "Total trainable params: 71,561\n",
              "Total non-trainable params: 23,454,912\n",
              "\n",
              "Optimizer used: <function Adam at 0x7fe1807630d0>\n",
              "Loss function: <bound method LinearBt.lf of LinearBt>\n",
              "\n",
              "Model frozen up to parameter group #1\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - CastToTensor\n",
              "  - LinearBt\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "bt_model,encoder = create_model(which_model='bt_pretrain',ps=8192,device=device)\n",
        "model = LM(encoder)\n",
        "test_eq(len(my_splitter(model)),2)\n",
        "test_eq(len(my_splitter_bt(bt_model)),2)\n",
        "\n",
        "learn = Learner(dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=aug_pipelines_tune,n_in=3)],wd=0.0)\n",
        "learn.freeze()\n",
        "print('body should be frozen, (sans batchnorm) linear head unfrozen')\n",
        "learn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goLaekflXYbx"
      },
      "source": [
        "## We can use this to check the  bt-model is of the appropriate type: resnet + projector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hDNBT6nUXYbx",
        "outputId": "a981d51a-1e72-46d7-8ba6-63223273b94e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "body should be frozen, (sans batchnorm) projector unfrozen\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BarlowTwinsModel (Input shape: 256 x 3 x 128 x 128)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     256 x 64 x 64 x 64  \n",
              "Conv2d                                    9408       False     \n",
              "BatchNorm2d                               128        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "MaxPool2d                                                      \n",
              "Conv2d                                    4096       False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 32 x 32 \n",
              "Conv2d                                    32768      False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 16 x 16 \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 8 x 8   \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    2097152    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 1 x 1  \n",
              "AdaptiveAvgPool2d                                              \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048          \n",
              "Flatten                                                        \n",
              "____________________________________________________________________________\n",
              "                     256 x 8192          \n",
              "Linear                                    16785408   True      \n",
              "BatchNorm1d                               16384      True      \n",
              "ReLU                                                           \n",
              "Linear                                    67117056   True      \n",
              "BatchNorm1d                               16384      True      \n",
              "ReLU                                                           \n",
              "Linear                                    67117056   True      \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 174,560,320\n",
              "Total trainable params: 151,105,408\n",
              "Total non-trainable params: 23,454,912\n",
              "\n",
              "Optimizer used: <function Adam at 0x7fe1807630d0>\n",
              "Loss function: <bound method BarlowTwins.lf of BarlowTwins>\n",
              "\n",
              "Model frozen up to parameter group #1\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - CastToTensor\n",
              "  - BarlowTwins\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "#| hide\n",
        "\n",
        "#test : manual. BT\n",
        "\n",
        "learn = Learner(dls_train,bt_model,splitter=my_splitter_bt,cbs=[BarlowTwins(aug_pipelines,n_in=3,lmb=1/8192,print_augs=False)])\n",
        "learn.freeze()\n",
        "print('body should be frozen, (sans batchnorm) projector unfrozen')\n",
        "learn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBu4-OGwXYby"
      },
      "source": [
        "## Ok, so `fit_one_cycle` works the best! So let's patch it back in. Also, just need to add `pretrain` argument to `fine_tune`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7rrD4oPxXYby"
      },
      "outputs": [],
      "source": [
        "@patch_to(main_train)\n",
        "def fit(learn,fit_type,epochs,freeze_epochs,initial_weights,pretrain):\n",
        "    \"\"\"We can patch in a modification, e.g. if we want subtype of fine_tune:supervised_pretrain to be different\n",
        "    to fine_tune:bt_pretrain\"\"\"\n",
        "\n",
        "    if fit_type == 'encoder_fine_tune': #i.e. barlow twins\n",
        "\n",
        "        #learn.encoder_fine_tune(epochs,freeze_epochs=freeze_epochs)\n",
        "        lr_max=0.0030199517495930195\n",
        "        print(f'lr_max={lr_max}')\n",
        "        learn.fit_one_cycle(epochs,lr_max= lr_max)\n",
        "\n",
        "    elif fit_type == 'fine_tune':\n",
        "\n",
        "        if pretrain == False:\n",
        "            print('pretrain was False, and about to fit_one_cycle')\n",
        "            learn.fit_one_cycle(epochs,lr_max=0.00027542) \n",
        "\n",
        "        elif pretrain == True:\n",
        "            print('pretrain was True, and about to linear_fine_tune')\n",
        "            learn.linear_fine_tune(epochs,freeze_epochs=freeze_epochs) #This gave very similar performance, when pretrain=False (see above / earlier commit)\n",
        "\n",
        "        #learn.no_freeze_linear_fine_tune(epochs,freeze_epochs=freeze_epochs) \n",
        "\n",
        "    else: raise Exception('Fit policy not of expected form')\n",
        "\n",
        "\n",
        "@patch\n",
        "def fine_tune(self:main_train):\n",
        "    \"fine tune in supervised fashion, according to tune_fit_policy, and get metrics\"\n",
        "\n",
        "    #encoder = pickle.loads(pickle.dumps(self.encoder)) #We might want to pretrain once and fine tune several times (varying e.g. tune augs)\n",
        "\n",
        "    try: \n",
        "        encoder = self.encoder\n",
        "    \n",
        "    except AttributeError:\n",
        "        _,self.encoder = create_model(which_model=self.initial_weights,ps=self.ps,device=self.device)\n",
        "\n",
        "    model = LM(self.encoder)\n",
        "    learn = Learner(self.dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "    #debugging\n",
        "    #learn = Learner(self.dls_tune,model,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "    main_train.fit(learn,fit_type='fine_tune',\n",
        "                    epochs=self.numfit,freeze_epochs=self.freeze_numfit,\n",
        "                    initial_weights=self.initial_weights,\n",
        "                    pretrain=self.pretrain\n",
        "                    ) #fine tuning (don't confuse this with fit policy!)\n",
        "    scores,preds, acc = predict_model(self.xval,self.yval,model=model,aug_pipelines_test=self.aug_pipelines_test,numavg=3)\n",
        "    #metrics dict will have f1 score, auc etc etc\n",
        "    metrics = classification_report_wrapper(preds, self.yval, self.vocab, print_report=self.print_report)\n",
        "    auc_dict = plot_roc(self.yval,preds,self.vocab,print_plot=self.print_plot)\n",
        "    metrics['acc'],metrics['auc_dict'],metrics['scores'],metrics['preds'],metrics['xval'],metrics['yval'] = acc,auc_dict,scores,preds,self.xval,self.yval\n",
        "\n",
        "    #torch.save(model.state_dict(), self.tuned_model_path)\n",
        "    return metrics #\n",
        "\n",
        "@patch\n",
        "def train_encoder(self:main_train):\n",
        "    \"create encoder and (optionally, if pretrain=True) train with BT algorithm, according to fit_policy\"\n",
        "\n",
        "    try: #get existing encoder and plonk on new projector\n",
        "        encoder = self.encoder\n",
        "        encoder.cpu()\n",
        "        bt_model = create_barlow_twins_model(encoder, hidden_size=self.ps,projection_size=self.ps,nlayers=3)\n",
        "        bt_model.cuda()\n",
        "\n",
        "    except AttributeError: #otherwise, create\n",
        "        bt_model,encoder = create_model(which_model=self.initial_weights,ps=self.ps,device=self.device)\n",
        "\n",
        "    if self.pretrain: #train encoder according to fit policy\n",
        "\n",
        "        #lmb=0.005 #this guy doesn't seem to work\n",
        "        lmb=1/8192\n",
        "        print(f'lmb={lmb}')\n",
        "        learn = Learner(self.dls_train,bt_model,cbs=[BarlowTwins(self.aug_pipelines,n_in=self.n_in,lmb=lmb,print_augs=False)])\n",
        "        main_train.fit(learn,fit_type='encoder_fine_tune',\n",
        "                        epochs=self.num_epochs,freeze_epochs=self.freeze_num_epochs,\n",
        "                        initial_weights=self.initial_weights,\n",
        "                        pretrain=self.pretrain\n",
        "                        )\n",
        "        \n",
        "    self.encoder = bt_model.encoder\n",
        "    self.bt_model=bt_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comments: `train_encoder` has a few differences. `fine_tune` basically the same except a different encoder... "
      ],
      "metadata": {
        "id": "apyeyOaPEeb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class main_train_ensemble(main_train):\n",
        "\n",
        "    def __init__(self,\n",
        "                 dls_train, #used for training BT (if pretrain=True)\n",
        "                 dls_tune , #used for tuning\n",
        "                 dls_valid, #used to compute metrics / evaluate results. \n",
        "                 xval, #currently `predict_model` below assumes this is entire validation / test data\n",
        "                 yval,\n",
        "                 aug_pipelines, #the aug pipeline for self-supervised learning\n",
        "                 aug_pipelines_tune, #the aug pipeline for supervised learning\n",
        "                 aug_pipelines_test, #test (or valid) time augmentations \n",
        "                 initial_weights, #Which initial weights to use\n",
        "                 pretrain, #Whether to fit BT\n",
        "                 num_epochs, #number of BT fit epochs\n",
        "                 numfit, #number of tune_fit epochs\n",
        "                 freeze_num_epochs, #How many epochs to freeze body for when training BT\n",
        "                 freeze_numfit, #How many epochs to freeze body for when fine tuning\n",
        "                 ps=8192, #projection size\n",
        "                 n_in=3, #color channels\n",
        "                 indim=2048, #dimension output of encoder (2048 for resnet50)\n",
        "                 outdim=9, #number of classes\n",
        "                 print_report=False, #F1 metrics etc\n",
        "                 print_plot=False, #ROC curve\n",
        "                 tune_model_path=None, #save models after fine tuning\n",
        "                 model=None, #BT model that has already been trained; i.e. what we are pushing rep away from...\n",
        "                 ):\n",
        "        store_attr()\n",
        "        self.vocab = self.dls_valid.vocab\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    def train_encoder(self):\n",
        "        \"create encoder and (optionally, if pretrain=True) train with BT algorithm, according to fit_policy\"\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            bt_model2,encoder2 = create_ens_model(model=self.model,ps=self.ps,device=self.device)\n",
        "\n",
        "        if self.pretrain: #train encoder according to fit policy\n",
        "\n",
        "            #lmb=0.005 #this guy doesn't seem to work\n",
        "            lmb=1/8192\n",
        "            print(f'lmb={lmb}')\n",
        "            learn = Learner(self.dls_train,bt_model2,cbs=[BarlowTwinsEns(self.aug_pipelines,n_in=self.n_in,lmb=lmb,print_augs=False)])\n",
        "            main_train_ensemble.fit(learn,fit_type='encoder_fine_tune',\n",
        "                            epochs=self.num_epochs,freeze_epochs=self.freeze_num_epochs,\n",
        "                            initial_weights=self.initial_weights,\n",
        "                            pretrain=self.pretrain\n",
        "                            )\n",
        "            \n",
        "        self.encoder2 = bt_model2.encoder2\n",
        "        self.bt_model2=bt_model2\n",
        "\n",
        "\n",
        "    def fine_tune(self):\n",
        "        \"fine tune in supervised fashion, according to tune_fit_policy, and get metrics\"\n",
        "\n",
        "        #encoder = pickle.loads(pickle.dumps(self.encoder)) #We might want to pretrain once and fine tune several times (varying e.g. tune augs)\n",
        "\n",
        "\n",
        "        model = LM(self.encoder2)\n",
        "        learn = Learner(self.dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "        #debugging\n",
        "        #learn = Learner(self.dls_tune,model,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "        main_train_ensemble.fit(learn,fit_type='fine_tune',\n",
        "                    epochs=self.numfit,freeze_epochs=self.freeze_numfit,\n",
        "                    initial_weights=self.initial_weights,\n",
        "                    pretrain=self.pretrain\n",
        "                    ) #fine tuning (don't confuse this with fit policy!)\n",
        "        \n",
        "        scores,preds, acc = predict_model(self.xval,self.yval,model=model,aug_pipelines_test=self.aug_pipelines_test,numavg=3)\n",
        "        #metrics dict will have f1 score, auc etc etc\n",
        "        metrics = classification_report_wrapper(preds, self.yval, self.vocab, print_report=self.print_report)\n",
        "        auc_dict = plot_roc(self.yval,preds,self.vocab,print_plot=self.print_plot)\n",
        "        metrics['acc'],metrics['auc_dict'],metrics['scores'],metrics['preds'],metrics['xval'],metrics['yval'] = acc,auc_dict,scores,preds,self.xval,self.yval\n",
        "\n",
        "        #torch.save(model.state_dict(), self.tuned_model_path)\n",
        "        return metrics #\n"
      ],
      "metadata": {
        "id": "rHp_Z0cL_t1u"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some tests:"
      ],
      "metadata": {
        "id": "O7DjYTLYJv7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that training the second encoder doesn't change the weights of the first encoder (i.e. that it is really frozen)"
      ],
      "metadata": {
        "id": "C3G1q2z2Jyqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "class AttributeDict(dict):\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "    \n",
        "def lf_rbt_ens(pred,I,lmb,\n",
        "               t,\n",
        "               s,\n",
        "               ):\n",
        "\n",
        "    \n",
        "    pred1 = pred[0] #frozen\n",
        "    pred2 = pred[1] #has gradients\n",
        "    \n",
        "    \n",
        "    bs,nf = pred1.size(0)//2,pred1.size(1)\n",
        "\n",
        "    #All standard, from BT\n",
        "    z1, z2 = pred1[:bs],pred1[bs:] #so z1 is bs*projection_size, likewise for z2\n",
        "    z1norm = (z1 - z1.mean(0)) / (z1.std(0, unbiased=False) + 1e-7)\n",
        "    z2norm = (z2 - z2.mean(0)) / (z2.std(0, unbiased=False) + 1e-7)\n",
        "    \n",
        "    z1_2, z2_2 = pred2[:bs],pred2[bs:] #so z1 is bs*projection_size, likewise for z2\n",
        "    z1norm_2 = (z1_2 - z1_2.mean(0)) / (z1_2.std(0, unbiased=False) + 1e-7)\n",
        "    z2norm_2 = (z2_2 - z2_2.mean(0)) / (z2_2.std(0, unbiased=False) + 1e-7)\n",
        "    \n",
        "    #Make sure gradients are turned off / turned on appropriately\n",
        "    test_eq(pred1.requires_grad,False)\n",
        "    test_eq(pred2.requires_grad,True)\n",
        "\n",
        "    #Within frozen model \n",
        "    C = (z1norm.T @ z2norm) / bs \n",
        "    cdiff = (C - I)**2\n",
        "    \n",
        "    #Within model_2 (unfrozen)\n",
        "    C2 = (z1norm_2.T @ z2norm_2) / bs \n",
        "    cdiff_2 = (C2 - I)**2\n",
        "\n",
        "\n",
        "    #Between model term 2\n",
        "    C = (z1norm * z1norm_2) \n",
        "    cdiff_3 = (1/bs)*(C)**2\n",
        "    \n",
        "    C = (z2norm * z2norm_2) \n",
        "    cdiff_4 = (1/bs)*(C)**2\n",
        "    \n",
        "    cdiff_between = 0.5*cdiff_3 + 0.5*cdiff_4\n",
        "    \n",
        "    bt_loss = (cdiff_2*I).sum() + lmb*(cdiff_2*(1-I)).sum()\n",
        "\n",
        "    loss = bt_loss + t*cdiff_between.sum()\n",
        "\n",
        "    print(f'bt loss: {bt_loss} ')\n",
        "    print(f'Scaled between loss: {t*cdiff_between.sum()} ')\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "iA05BesZC6B6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfybvxyRIhVU",
        "outputId": "96d60c5e-ec64-45a5-c59c-30e74c4b8ffc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16177"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=1\n",
        "freeze_num_epochs=1\n",
        "freeze_numfit=1\n",
        "numfit=1\n",
        "\n",
        "main = main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "        aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "        initial_weights='no_pretrain',pretrain=True,\n",
        "        num_epochs=1,numfit=1,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "        print_report=True,\n",
        "                )\n",
        "        \n",
        "main.train_encoder()\n",
        "\n",
        "print('trained first encoder')\n",
        "\n",
        "s=0\n",
        "for p in main.bt_model.parameters():\n",
        "    s+=p.sum().item()\n",
        "print(f'sum of first models parameters is: {s} ')\n",
        "\n",
        "\n",
        "main_ens = main_train_ensemble(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "        aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "        initial_weights='no_pretrain',pretrain=True,\n",
        "        num_epochs=1,numfit=1,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "        print_report=True,model=main.bt_model\n",
        "                )\n",
        "\n",
        "main_ens.train_encoder()\n",
        "\n",
        "print('trained second encoder (decorrelated)')\n",
        "\n",
        "s2=0\n",
        "for p in main.bt_model.parameters():\n",
        "    s2+=p.sum().item()\n",
        "print(f'sum of first models parameters is: {s2} ')\n",
        "\n",
        "test_eq(s,s2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "NssXMG5wGEmS",
        "outputId": "07c45c09-6b19-4118-c042-0cef7cd4dc9d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lmb=0.0001220703125\n",
            "lr_max=0.0030199517495930195\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6645.418457</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trained first encoder\n",
            "sum of first models parameters is: 37929.50347258191 \n",
            "lmb=0.0001220703125\n",
            "lr_max=0.0030199517495930195\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>26878.902344</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bt loss: 7529.03466796875 \n",
            "Scaled between loss: 18174.791015625 \n",
            "bt loss: 6822.9716796875 \n",
            "Scaled between loss: 21207.5546875 \n",
            "trained second encoder (decorrelated)\n",
            "sum of first models parameters is: 37929.50347258191 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_9VAsBvD9LR",
        "outputId": "32a7e66e-443c-42d3-fd0a-e4af3e0a38c8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "582"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test that fine tuning works (i.e. runs) and weights don't change when they shouldnt "
      ],
      "metadata": {
        "id": "SF64g5UPPGn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics1 = main.fine_tune()\n",
        "s=0\n",
        "for p in main.bt_model.parameters():\n",
        "    s+=p.sum().item()\n",
        "print(f'sum of first models parameters is: {s} ')\n",
        "\n",
        "metrics2 = main_ens.fine_tune()\n",
        "\n",
        "s2=0\n",
        "for p in main.bt_model.parameters():\n",
        "    s2+=p.sum().item()\n",
        "print(f'sum of first models parameters is: {s} ')\n",
        "test_eq(s,s2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lyRv4_UIFX6w",
        "outputId": "9cb530c4-9c5e-4970-9b12-d5b781e0b2c4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pretrain was True, and about to linear_fine_tune\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.396944</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.294426</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.00      0.00      0.00        20\n",
            "      basal cell carcinoma       0.00      0.00      0.00        20\n",
            "            dermatofibroma       0.00      0.00      0.00        19\n",
            "                  melanoma       0.00      0.00      0.00        20\n",
            "                     nevus       0.00      0.00      0.00        20\n",
            "pigmented benign keratosis       0.00      0.00      0.00        20\n",
            "      seborrheic keratosis       0.00      0.00      0.00        15\n",
            "   squamous cell carcinoma       0.11      0.80      0.19        20\n",
            "           vascular lesion       0.00      0.00      0.00        20\n",
            "\n",
            "                  accuracy                           0.09       174\n",
            "                 macro avg       0.01      0.09      0.02       174\n",
            "              weighted avg       0.01      0.09      0.02       174\n",
            "\n",
            "sum of first models parameters is: 38060.014380230044 \n",
            "pretrain was True, and about to linear_fine_tune\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.310013</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.439386</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.11      1.00      0.21        20\n",
            "      basal cell carcinoma       0.00      0.00      0.00        20\n",
            "            dermatofibroma       0.00      0.00      0.00        19\n",
            "                  melanoma       0.00      0.00      0.00        20\n",
            "                     nevus       0.00      0.00      0.00        20\n",
            "pigmented benign keratosis       0.00      0.00      0.00        20\n",
            "      seborrheic keratosis       0.00      0.00      0.00        15\n",
            "   squamous cell carcinoma       0.00      0.00      0.00        20\n",
            "           vascular lesion       0.00      0.00      0.00        20\n",
            "\n",
            "                  accuracy                           0.11       174\n",
            "                 macro avg       0.01      0.11      0.02       174\n",
            "              weighted avg       0.01      0.11      0.02       174\n",
            "\n",
            "sum of first models parameters is: 38060.014380230044 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial experiment: Train several BT models (standard way) and several decorrelated nets. Compare ensemble performance within standard way, and between"
      ],
      "metadata": {
        "id": "z6Uw1i9nPaQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@patch\n",
        "def before_epoch(self:BarlowTwinsEns):\n",
        "    \n",
        "    ##########\"Best\" annealing schedule found so far\n",
        "    print('patched in new annealing schedule')\n",
        "    self.s='foo'\n",
        "        \n",
        "    if self.epoch <10:\n",
        "        self.t=0.1\n",
        "\n",
        "    if self.epoch == 20:\n",
        "        self.t=0.01\n",
        "\n",
        "    if self.epoch == 30:\n",
        "        self.t=0.001\n",
        "\n",
        "    if self.epoch == 40:\n",
        "        self.t=0.0\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "3m4xNYDPHS9t"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_epochs=1\n",
        "freeze_num_epochs=1\n",
        "freeze_numfit=1\n",
        "numfit=1\n",
        "\n",
        "\n",
        "main = main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "    aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "    initial_weights='no_pretrain',pretrain=True,\n",
        "    num_epochs=num_epochs,numfit=numfit,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "    print_report=True,\n",
        "            )\n",
        "\n",
        "main.train_encoder()\n",
        "print('trained first encoder')\n",
        "\n",
        "main_ens = main_train_ensemble(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "        aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "        initial_weights='no_pretrain',pretrain=True,\n",
        "        num_epochs=num_epochs,numfit=numfit,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "        print_report=True,model=main.bt_model\n",
        "                )\n",
        "\n",
        "main_ens.train_encoder()\n",
        "\n",
        "metrics = main.fine_tune()\n",
        "print('fine tuned number 1')\n",
        "metrics_ens = main_ens.fine_tune()\n",
        "print('fine tuned number 2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wqdrurlzHiiA",
        "outputId": "5951e0aa-0d92-4466-a3e2-3ed43b1a053d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lmb=0.0001220703125\n",
            "lr_max=0.0030199517495930195\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6569.790527</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trained first encoder\n",
            "lmb=0.0001220703125\n",
            "lr_max=0.0030199517495930195\n",
            "patched in new annealing schedule\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>8495.072266</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bt loss: 7876.923828125 \n",
            "Scaled between loss: 863.212158203125 \n",
            "bt loss: 7375.45556640625 \n",
            "Scaled between loss: 879.4693603515625 \n",
            "pretrain was True, and about to linear_fine_tune\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.423330</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.480873</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.11      1.00      0.21        20\n",
            "      basal cell carcinoma       0.00      0.00      0.00        20\n",
            "            dermatofibroma       0.00      0.00      0.00        19\n",
            "                  melanoma       0.00      0.00      0.00        20\n",
            "                     nevus       0.00      0.00      0.00        20\n",
            "pigmented benign keratosis       0.00      0.00      0.00        20\n",
            "      seborrheic keratosis       0.00      0.00      0.00        15\n",
            "   squamous cell carcinoma       0.00      0.00      0.00        20\n",
            "           vascular lesion       0.00      0.00      0.00        20\n",
            "\n",
            "                  accuracy                           0.11       174\n",
            "                 macro avg       0.01      0.11      0.02       174\n",
            "              weighted avg       0.01      0.11      0.02       174\n",
            "\n",
            "fine tuned number 1\n",
            "pretrain was True, and about to linear_fine_tune\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.437115</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.417465</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.00      0.00      0.00        20\n",
            "      basal cell carcinoma       0.11      1.00      0.21        20\n",
            "            dermatofibroma       0.00      0.00      0.00        19\n",
            "                  melanoma       0.00      0.00      0.00        20\n",
            "                     nevus       0.00      0.00      0.00        20\n",
            "pigmented benign keratosis       0.00      0.00      0.00        20\n",
            "      seborrheic keratosis       0.00      0.00      0.00        15\n",
            "   squamous cell carcinoma       0.00      0.00      0.00        20\n",
            "           vascular lesion       0.00      0.00      0.00        20\n",
            "\n",
            "                  accuracy                           0.11       174\n",
            "                 macro avg       0.01      0.11      0.02       174\n",
            "              weighted avg       0.01      0.11      0.02       174\n",
            "\n",
            "fine tuned number 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kAw-q2rH4N_",
        "outputId": "6945d5c7-429a-4a49-c0d7-874d5d19d300"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=50\n",
        "freeze_num_epochs=1\n",
        "freeze_numfit=6\n",
        "numfit=75\n",
        "\n",
        "main_dict_1 = {}\n",
        "main_dict_2 = {}\n",
        "\n",
        "for i in range(2):\n",
        "\n",
        "    if i == 1:\n",
        "\n",
        "        main = main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "            aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "            initial_weights='no_pretrain',pretrain=True,\n",
        "            num_epochs=num_epochs,numfit=numfit,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "            print_report=True,\n",
        "                    )\n",
        "        \n",
        "        main.train_encoder()\n",
        "        print('trained first encoder')\n",
        "\n",
        "    main_ens = main_train_ensemble(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "            aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "            initial_weights='no_pretrain',pretrain=True,\n",
        "            num_epochs=num_epochs,numfit=numfit,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "            print_report=True,model=main.bt_model\n",
        "                    )\n",
        "    \n",
        "    main_ens.train_encoder()\n",
        "    print('trained second encoder')\n",
        "\n",
        "    metrics = main.fine_tune()\n",
        "    print('fine tuned number 1')\n",
        "    metrics_ens = main_ens.fine_tune()\n",
        "    print('fine tuned number 2')\n",
        "\n",
        "    main_dict_1[i] = metrics\n",
        "    main_dict_2[i] = metrics_ens\n",
        "\n",
        "    print('please see loss function: only have rr term')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z3FmuzdxPpOr",
        "outputId": "6419e72f-c41c-45d0-f2a4-ebaa6d086351"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lmb=0.0001220703125\n",
            "lr_max=0.0030199517495930195\n",
            "patched in new annealing schedule\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>7497.475586</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>7261.932129</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6834.811523</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>6407.141602</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>6125.150391</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>5863.493164</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>5714.076660</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>5530.636230</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>5431.887695</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>5237.257324</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>5125.163086</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>4975.333984</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>4927.444824</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>4826.731934</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>4737.802734</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>4647.958008</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>4551.780762</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>4468.363770</td>\n",
              "      <td>None</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>4389.476562</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>4335.590332</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>4247.301270</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>4174.767578</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>4103.652832</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>4053.295654</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>3984.383301</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>3925.427490</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>3866.244629</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>3811.235352</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>3752.901123</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>3701.820068</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3653.953369</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>3603.919434</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>3556.514648</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>3514.094727</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>3472.495850</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>3432.535645</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>3394.412354</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>3356.678467</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>3320.022461</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>3286.001953</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3251.404053</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>3220.023193</td>\n",
              "      <td>None</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>3188.775391</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>3157.816650</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>3128.880615</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>3108.500977</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>3081.117676</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>3056.851807</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>3033.344238</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>3009.123047</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bt loss: 6550.9404296875 \n",
            "Scaled between loss: 1390.3265380859375 \n",
            "bt loss: 5142.33837890625 \n",
            "Scaled between loss: 1920.2353515625 \n",
            "patched in new annealing schedule\n",
            "bt loss: 6818.78759765625 \n",
            "Scaled between loss: 1476.4964599609375 \n",
            "bt loss: 4489.8583984375 \n",
            "Scaled between loss: 1311.4942626953125 \n",
            "patched in new annealing schedule\n",
            "bt loss: 4909.29638671875 \n",
            "Scaled between loss: 1393.8944091796875 \n",
            "bt loss: 4078.51806640625 \n",
            "Scaled between loss: 1685.0364990234375 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3963.10302734375 \n",
            "Scaled between loss: 1102.897705078125 \n",
            "bt loss: 4479.2265625 \n",
            "Scaled between loss: 897.8204956054688 \n",
            "patched in new annealing schedule\n",
            "bt loss: 4335.26318359375 \n",
            "Scaled between loss: 841.4434814453125 \n",
            "bt loss: 4190.5791015625 \n",
            "Scaled between loss: 843.2084350585938 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3841.802490234375 \n",
            "Scaled between loss: 896.5877075195312 \n",
            "bt loss: 3872.615234375 \n",
            "Scaled between loss: 795.0454711914062 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3672.8154296875 \n",
            "Scaled between loss: 674.7743530273438 \n",
            "bt loss: 4791.58740234375 \n",
            "Scaled between loss: 716.9990234375 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3428.3994140625 \n",
            "Scaled between loss: 858.5938720703125 \n",
            "bt loss: 3706.931396484375 \n",
            "Scaled between loss: 872.3624877929688 \n",
            "patched in new annealing schedule\n",
            "bt loss: 4242.5712890625 \n",
            "Scaled between loss: 833.5072631835938 \n",
            "bt loss: 3842.708984375 \n",
            "Scaled between loss: 628.15966796875 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3312.294921875 \n",
            "Scaled between loss: 564.01025390625 \n",
            "bt loss: 3113.03857421875 \n",
            "Scaled between loss: 608.6456298828125 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3352.097900390625 \n",
            "Scaled between loss: 656.0189819335938 \n",
            "bt loss: 3850.09765625 \n",
            "Scaled between loss: 580.580322265625 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3150.800048828125 \n",
            "Scaled between loss: 529.7779541015625 \n",
            "bt loss: 3218.13037109375 \n",
            "Scaled between loss: 444.3758850097656 \n",
            "patched in new annealing schedule\n",
            "bt loss: 4013.2900390625 \n",
            "Scaled between loss: 474.058837890625 \n",
            "bt loss: 3892.80419921875 \n",
            "Scaled between loss: 582.3660278320312 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3232.341064453125 \n",
            "Scaled between loss: 678.2111206054688 \n",
            "bt loss: 3026.64599609375 \n",
            "Scaled between loss: 721.8460083007812 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2964.52587890625 \n",
            "Scaled between loss: 636.859619140625 \n",
            "bt loss: 3511.53515625 \n",
            "Scaled between loss: 495.0433654785156 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3106.4384765625 \n",
            "Scaled between loss: 630.4396362304688 \n",
            "bt loss: 3034.858642578125 \n",
            "Scaled between loss: 545.0263061523438 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2871.13037109375 \n",
            "Scaled between loss: 515.6228637695312 \n",
            "bt loss: 3025.480224609375 \n",
            "Scaled between loss: 469.1087951660156 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2799.24462890625 \n",
            "Scaled between loss: 465.0423889160156 \n",
            "bt loss: 3197.90185546875 \n",
            "Scaled between loss: 460.1949157714844 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3159.25146484375 \n",
            "Scaled between loss: 396.3368225097656 \n",
            "bt loss: 2803.032470703125 \n",
            "Scaled between loss: 445.9861755371094 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3360.18359375 \n",
            "Scaled between loss: 462.9384765625 \n",
            "bt loss: 2954.76123046875 \n",
            "Scaled between loss: 496.301025390625 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2977.26708984375 \n",
            "Scaled between loss: 52.805233001708984 \n",
            "bt loss: 3037.468505859375 \n",
            "Scaled between loss: 52.67009735107422 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3238.931884765625 \n",
            "Scaled between loss: 54.26167297363281 \n",
            "bt loss: 2981.22314453125 \n",
            "Scaled between loss: 65.3565673828125 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3087.417724609375 \n",
            "Scaled between loss: 65.42701721191406 \n",
            "bt loss: 2943.28125 \n",
            "Scaled between loss: 81.10978698730469 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3678.131591796875 \n",
            "Scaled between loss: 75.10428619384766 \n",
            "bt loss: 2824.63916015625 \n",
            "Scaled between loss: 59.30428695678711 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2859.72412109375 \n",
            "Scaled between loss: 55.42349624633789 \n",
            "bt loss: 2924.0107421875 \n",
            "Scaled between loss: 53.85332489013672 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3077.302734375 \n",
            "Scaled between loss: 51.01618194580078 \n",
            "bt loss: 2848.8193359375 \n",
            "Scaled between loss: 57.707523345947266 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2769.05810546875 \n",
            "Scaled between loss: 61.02787780761719 \n",
            "bt loss: 2962.735107421875 \n",
            "Scaled between loss: 70.95636749267578 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2804.27685546875 \n",
            "Scaled between loss: 61.87498092651367 \n",
            "bt loss: 2924.515869140625 \n",
            "Scaled between loss: 58.657020568847656 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2759.131591796875 \n",
            "Scaled between loss: 51.37611389160156 \n",
            "bt loss: 2729.66650390625 \n",
            "Scaled between loss: 49.22380828857422 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2716.9287109375 \n",
            "Scaled between loss: 49.14575958251953 \n",
            "bt loss: 2875.268310546875 \n",
            "Scaled between loss: 50.64641571044922 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2838.72705078125 \n",
            "Scaled between loss: 5.07804012298584 \n",
            "bt loss: 2828.4951171875 \n",
            "Scaled between loss: 4.785872459411621 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2741.71826171875 \n",
            "Scaled between loss: 4.7939300537109375 \n",
            "bt loss: 2723.28271484375 \n",
            "Scaled between loss: 4.882109642028809 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2704.215576171875 \n",
            "Scaled between loss: 5.4057297706604 \n",
            "bt loss: 2728.213623046875 \n",
            "Scaled between loss: 6.637808799743652 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2821.7666015625 \n",
            "Scaled between loss: 5.3921403884887695 \n",
            "bt loss: 2681.653076171875 \n",
            "Scaled between loss: 5.560046672821045 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2741.974609375 \n",
            "Scaled between loss: 6.06723165512085 \n",
            "bt loss: 2685.27392578125 \n",
            "Scaled between loss: 5.283322811126709 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2691.76220703125 \n",
            "Scaled between loss: 6.319936752319336 \n",
            "bt loss: 2694.194091796875 \n",
            "Scaled between loss: 5.745548248291016 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2714.17626953125 \n",
            "Scaled between loss: 5.791382312774658 \n",
            "bt loss: 2645.83642578125 \n",
            "Scaled between loss: 6.306403160095215 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2630.0341796875 \n",
            "Scaled between loss: 5.509828567504883 \n",
            "bt loss: 2651.609375 \n",
            "Scaled between loss: 6.128234386444092 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2614.824951171875 \n",
            "Scaled between loss: 5.751590728759766 \n",
            "bt loss: 2617.669189453125 \n",
            "Scaled between loss: 6.688962459564209 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2628.52978515625 \n",
            "Scaled between loss: 6.2611002922058105 \n",
            "bt loss: 2621.87744140625 \n",
            "Scaled between loss: 6.556965351104736 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2622.77490234375 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2536.099853515625 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2652.780517578125 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2556.5048828125 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2547.02099609375 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2592.115478515625 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2576.542724609375 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2502.43359375 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2540.33154296875 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2550.963623046875 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2732.4716796875 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2657.22998046875 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2549.297119140625 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2492.33984375 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2535.062744140625 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2577.40478515625 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2561.41259765625 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2529.3095703125 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2503.42626953125 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2502.2109375 \n",
            "Scaled between loss: 0.0 \n",
            "trained second encoder\n",
            "pretrain was True, and about to linear_fine_tune\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.233054</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.209057</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.180998</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.159505</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.162368</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.169364</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.112534</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.050880</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.972680</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.914114</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.861008</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.804592</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.759710</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.716066</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.680828</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.657094</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.628642</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.600815</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.575720</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.551131</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.535751</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.514607</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.495853</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.477793</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.460247</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.442374</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.431830</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.418091</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.408740</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.400067</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.388899</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.372600</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.357502</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.345602</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.331530</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.314579</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.302942</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.283536</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.266476</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.247466</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.228131</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.211364</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.194308</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.176569</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.160291</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.140808</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.124107</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.105558</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.086843</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.066839</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.047383</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.026404</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.008348</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.987903</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.966669</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.944100</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.933353</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.915483</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.895515</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.874983</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.855573</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.834564</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.814143</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.799018</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.780642</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.761982</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.743428</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.725895</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.706737</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.689675</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.670982</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.655231</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.638332</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.621715</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.604680</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.587560</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.573370</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.558538</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.545831</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.531730</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.520614</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.40      0.50      0.44        20\n",
            "      basal cell carcinoma       0.47      0.40      0.43        20\n",
            "            dermatofibroma       0.47      0.47      0.47        19\n",
            "                  melanoma       0.33      0.30      0.32        20\n",
            "                     nevus       0.92      0.60      0.73        20\n",
            "pigmented benign keratosis       0.47      0.40      0.43        20\n",
            "      seborrheic keratosis       0.33      0.40      0.36        15\n",
            "   squamous cell carcinoma       0.24      0.30      0.27        20\n",
            "           vascular lesion       0.86      0.95      0.90        20\n",
            "\n",
            "                  accuracy                           0.48       174\n",
            "                 macro avg       0.50      0.48      0.48       174\n",
            "              weighted avg       0.51      0.48      0.49       174\n",
            "\n",
            "fine tuned number 1\n",
            "pretrain was True, and about to linear_fine_tune\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.249571</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.206061</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.208757</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.211008</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.223877</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.232399</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.201360</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.150708</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.076428</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.024338</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.965629</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.909124</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.859381</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.817627</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.780673</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.747267</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.715729</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.679534</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.652452</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.624845</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.600680</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.582474</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.568580</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.563347</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.551025</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.535532</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.520056</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.505399</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.498846</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.484103</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.474107</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.459440</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.440381</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.424111</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.403650</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.386746</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.367123</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.350437</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.333741</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.316930</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.298870</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.278278</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.260515</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.243209</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.223554</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.209326</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.192896</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.175184</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.158660</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.139197</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.121008</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.099232</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.077798</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.056608</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.036592</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.017885</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.996293</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.976211</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.955788</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.934069</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.913119</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.890057</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.872230</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.849778</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.832845</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.812198</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.793497</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.774414</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.757840</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.739228</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.719566</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.705068</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.687832</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.672524</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.657784</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.639329</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.623894</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.608597</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.595223</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.581593</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.570382</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.39      0.35      0.37        20\n",
            "      basal cell carcinoma       0.44      0.60      0.51        20\n",
            "            dermatofibroma       0.57      0.63      0.60        19\n",
            "                  melanoma       0.27      0.20      0.23        20\n",
            "                     nevus       0.71      0.60      0.65        20\n",
            "pigmented benign keratosis       0.67      0.60      0.63        20\n",
            "      seborrheic keratosis       0.29      0.33      0.31        15\n",
            "   squamous cell carcinoma       0.38      0.45      0.41        20\n",
            "           vascular lesion       1.00      0.85      0.92        20\n",
            "\n",
            "                  accuracy                           0.52       174\n",
            "                 macro avg       0.52      0.51      0.51       174\n",
            "              weighted avg       0.53      0.52      0.52       174\n",
            "\n",
            "fine tuned number 2\n",
            "please see loss function: only have rr term\n",
            "lmb=0.0001220703125\n",
            "lr_max=0.0030199517495930195\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6674.175293</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5953.060059</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5648.758789</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5278.581055</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5033.379883</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4882.217773</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4753.944336</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4583.965332</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4533.456543</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4414.129883</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>4291.884277</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>4273.856934</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>4175.719238</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>4078.703613</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>4059.222412</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>3994.641602</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>3979.452881</td>\n",
              "      <td>None</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>3936.054932</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>3876.651855</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>3828.266113</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3772.126953</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>3725.027100</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>3676.990967</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>3631.176270</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>3582.331299</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>3533.066162</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>3493.346680</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>3451.911377</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>3412.998779</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>3377.549805</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3344.161133</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>3312.687988</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>3282.472168</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>3253.248047</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>3227.393799</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>3204.802734</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>3179.989014</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>3156.357422</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>3136.744141</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>3115.231445</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3094.644043</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>3074.686035</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>3054.839844</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>3033.185547</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>3016.105713</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>2996.644531</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>2978.710938</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>2961.109131</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>2945.037842</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>2929.697266</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trained first encoder\n",
            "lmb=0.0001220703125\n",
            "lr_max=0.0030199517495930195\n",
            "patched in new annealing schedule\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>8258.833984</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>7325.978516</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6741.622559</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>6395.390137</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>6064.157715</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>5809.712402</td>\n",
              "      <td>None</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>5628.584473</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>5389.722656</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>5225.115234</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>5186.124023</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>5281.857422</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>5226.334473</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>5131.314453</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>5021.206543</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>4937.917480</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>4834.477539</td>\n",
              "      <td>None</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>4731.729980</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>4651.130371</td>\n",
              "      <td>None</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>4580.922363</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>4505.473633</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>4395.215820</td>\n",
              "      <td>None</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>4298.778320</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>4207.860840</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>4122.265137</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>4044.913330</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>3975.128418</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>3909.771973</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>3848.435303</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>3795.606201</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>3742.607666</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3693.758057</td>\n",
              "      <td>None</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>3646.044922</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>3606.890869</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>3565.163086</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>3527.323486</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>3491.125732</td>\n",
              "      <td>None</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>3457.001953</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>3421.760986</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>3390.953857</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>3360.551025</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3330.723389</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>3302.023193</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>3277.218018</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>3253.186035</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>3229.231934</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>3206.362549</td>\n",
              "      <td>None</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>3185.687988</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>3166.040039</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>3147.620361</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>3130.203369</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bt loss: 7743.9208984375 \n",
            "Scaled between loss: 1310.9991455078125 \n",
            "bt loss: 6208.841796875 \n",
            "Scaled between loss: 1269.8431396484375 \n",
            "patched in new annealing schedule\n",
            "bt loss: 5333.748046875 \n",
            "Scaled between loss: 1296.0386962890625 \n",
            "bt loss: 4697.01953125 \n",
            "Scaled between loss: 1537.3275146484375 \n",
            "patched in new annealing schedule\n",
            "bt loss: 4304.236328125 \n",
            "Scaled between loss: 1346.0013427734375 \n",
            "bt loss: 4485.810546875 \n",
            "Scaled between loss: 1146.96875 \n",
            "patched in new annealing schedule\n",
            "bt loss: 4033.1015625 \n",
            "Scaled between loss: 1147.765869140625 \n",
            "bt loss: 4783.4970703125 \n",
            "Scaled between loss: 904.1435546875 \n",
            "patched in new annealing schedule\n",
            "bt loss: 4023.03759765625 \n",
            "Scaled between loss: 989.552734375 \n",
            "bt loss: 3810.302001953125 \n",
            "Scaled between loss: 910.6622314453125 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3797.052978515625 \n",
            "Scaled between loss: 881.8477783203125 \n",
            "bt loss: 3804.913330078125 \n",
            "Scaled between loss: 877.9138793945312 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3915.13671875 \n",
            "Scaled between loss: 965.7233276367188 \n",
            "bt loss: 3575.302978515625 \n",
            "Scaled between loss: 913.5790405273438 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3247.69482421875 \n",
            "Scaled between loss: 768.5219116210938 \n",
            "bt loss: 3232.56103515625 \n",
            "Scaled between loss: 677.44482421875 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3007.007080078125 \n",
            "Scaled between loss: 792.7128295898438 \n",
            "bt loss: 3224.684326171875 \n",
            "Scaled between loss: 1214.0911865234375 \n",
            "patched in new annealing schedule\n",
            "bt loss: 4821.16748046875 \n",
            "Scaled between loss: 993.6982421875 \n",
            "bt loss: 3375.26416015625 \n",
            "Scaled between loss: 623.8797607421875 \n",
            "patched in new annealing schedule\n",
            "bt loss: 5498.3251953125 \n",
            "Scaled between loss: 708.36962890625 \n",
            "bt loss: 5235.44921875 \n",
            "Scaled between loss: 668.1185913085938 \n",
            "patched in new annealing schedule\n",
            "bt loss: 4597.13037109375 \n",
            "Scaled between loss: 594.58740234375 \n",
            "bt loss: 3705.395751953125 \n",
            "Scaled between loss: 598.1612548828125 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3584.5849609375 \n",
            "Scaled between loss: 605.0048217773438 \n",
            "bt loss: 3609.993896484375 \n",
            "Scaled between loss: 691.05859375 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3369.33154296875 \n",
            "Scaled between loss: 612.236328125 \n",
            "bt loss: 3282.294677734375 \n",
            "Scaled between loss: 597.3153686523438 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3608.331787109375 \n",
            "Scaled between loss: 648.9278564453125 \n",
            "bt loss: 3311.90966796875 \n",
            "Scaled between loss: 565.1615600585938 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3100.275390625 \n",
            "Scaled between loss: 580.1604614257812 \n",
            "bt loss: 3123.87744140625 \n",
            "Scaled between loss: 583.9137573242188 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2886.82958984375 \n",
            "Scaled between loss: 560.6188354492188 \n",
            "bt loss: 3063.723876953125 \n",
            "Scaled between loss: 577.4730834960938 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3290.668701171875 \n",
            "Scaled between loss: 646.8585205078125 \n",
            "bt loss: 2808.41162109375 \n",
            "Scaled between loss: 618.9954223632812 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3276.94580078125 \n",
            "Scaled between loss: 594.6144409179688 \n",
            "bt loss: 2900.610595703125 \n",
            "Scaled between loss: 633.2020874023438 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3103.701171875 \n",
            "Scaled between loss: 551.1184692382812 \n",
            "bt loss: 2803.01953125 \n",
            "Scaled between loss: 594.4212036132812 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2933.68115234375 \n",
            "Scaled between loss: 53.03882598876953 \n",
            "bt loss: 2792.3701171875 \n",
            "Scaled between loss: 48.37728500366211 \n",
            "patched in new annealing schedule\n",
            "bt loss: 3010.34423828125 \n",
            "Scaled between loss: 53.488037109375 \n",
            "bt loss: 2807.85986328125 \n",
            "Scaled between loss: 52.526283264160156 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2896.65576171875 \n",
            "Scaled between loss: 49.1416015625 \n",
            "bt loss: 2815.535888671875 \n",
            "Scaled between loss: 58.090457916259766 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2823.38916015625 \n",
            "Scaled between loss: 50.768611907958984 \n",
            "bt loss: 2800.0751953125 \n",
            "Scaled between loss: 57.846248626708984 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2765.9775390625 \n",
            "Scaled between loss: 55.05469512939453 \n",
            "bt loss: 2883.6259765625 \n",
            "Scaled between loss: 54.739070892333984 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2894.150634765625 \n",
            "Scaled between loss: 61.77925491333008 \n",
            "bt loss: 2783.145751953125 \n",
            "Scaled between loss: 60.08731460571289 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2820.53125 \n",
            "Scaled between loss: 59.11605453491211 \n",
            "bt loss: 2819.562744140625 \n",
            "Scaled between loss: 58.96729278564453 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2761.035400390625 \n",
            "Scaled between loss: 59.954647064208984 \n",
            "bt loss: 2836.62939453125 \n",
            "Scaled between loss: 62.672908782958984 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2974.41748046875 \n",
            "Scaled between loss: 59.36137390136719 \n",
            "bt loss: 2762.28857421875 \n",
            "Scaled between loss: 61.444549560546875 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2817.63916015625 \n",
            "Scaled between loss: 63.94704055786133 \n",
            "bt loss: 2766.501220703125 \n",
            "Scaled between loss: 63.42161560058594 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2828.80615234375 \n",
            "Scaled between loss: 7.404026031494141 \n",
            "bt loss: 2879.8759765625 \n",
            "Scaled between loss: 6.501431465148926 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2802.455078125 \n",
            "Scaled between loss: 7.393941879272461 \n",
            "bt loss: 2822.37939453125 \n",
            "Scaled between loss: 6.70740270614624 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2750.015625 \n",
            "Scaled between loss: 6.749866962432861 \n",
            "bt loss: 3069.26171875 \n",
            "Scaled between loss: 6.585978031158447 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2776.54541015625 \n",
            "Scaled between loss: 6.26348876953125 \n",
            "bt loss: 2849.94775390625 \n",
            "Scaled between loss: 6.332901477813721 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2802.047119140625 \n",
            "Scaled between loss: 5.963656902313232 \n",
            "bt loss: 2868.78466796875 \n",
            "Scaled between loss: 6.380950927734375 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2873.735595703125 \n",
            "Scaled between loss: 6.2459917068481445 \n",
            "bt loss: 2767.92041015625 \n",
            "Scaled between loss: 6.514759540557861 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2809.8603515625 \n",
            "Scaled between loss: 6.828242301940918 \n",
            "bt loss: 2822.00146484375 \n",
            "Scaled between loss: 6.500980377197266 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2739.3681640625 \n",
            "Scaled between loss: 6.772955417633057 \n",
            "bt loss: 2763.8134765625 \n",
            "Scaled between loss: 7.277889728546143 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2857.85546875 \n",
            "Scaled between loss: 7.167891025543213 \n",
            "bt loss: 2739.108642578125 \n",
            "Scaled between loss: 6.504693508148193 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2800.98193359375 \n",
            "Scaled between loss: 6.915966987609863 \n",
            "bt loss: 2737.22509765625 \n",
            "Scaled between loss: 6.953197956085205 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2758.066650390625 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2744.1259765625 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2740.970703125 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2736.6123046875 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2757.4853515625 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2813.65869140625 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2799.34912109375 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2747.017578125 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2737.39208984375 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2755.33349609375 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2745.4404296875 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2738.138427734375 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2753.52880859375 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2771.16748046875 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2768.08447265625 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2753.78662109375 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2763.06640625 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2767.1474609375 \n",
            "Scaled between loss: 0.0 \n",
            "patched in new annealing schedule\n",
            "bt loss: 2793.6142578125 \n",
            "Scaled between loss: 0.0 \n",
            "bt loss: 2739.1796875 \n",
            "Scaled between loss: 0.0 \n",
            "trained second encoder\n",
            "pretrain was True, and about to linear_fine_tune\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.370738</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.299842</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.259085</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.247237</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.228407</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.216200</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.159156</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.078339</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.019427</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.967580</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.907056</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.867402</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.831077</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.805153</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.775430</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.752224</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.726728</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.698699</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.674299</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.652225</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.627486</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.604326</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.588126</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.570551</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.556617</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.540187</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.522218</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.507556</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.498747</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.484152</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.471475</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.457699</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.439441</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.418483</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.401707</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.385426</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.369960</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.350414</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.333831</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.314720</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.297949</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.279815</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.259283</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.237774</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.216576</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.193572</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.172523</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.155349</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.132496</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.112903</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.091386</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.072627</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.054134</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.035312</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.015968</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.995222</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.978212</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.962924</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.942740</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.922169</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.900409</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.881625</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.860995</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.842860</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.821488</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.800882</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.781360</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.763542</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.746066</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.726952</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.709272</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.693915</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.676179</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.659076</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.643279</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.625257</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.610433</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.595255</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.581333</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.567823</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.555583</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.43      0.45      0.44        20\n",
            "      basal cell carcinoma       0.53      0.50      0.51        20\n",
            "            dermatofibroma       0.39      0.47      0.43        19\n",
            "                  melanoma       0.33      0.30      0.32        20\n",
            "                     nevus       0.65      0.55      0.59        20\n",
            "pigmented benign keratosis       0.58      0.55      0.56        20\n",
            "      seborrheic keratosis       0.38      0.40      0.39        15\n",
            "   squamous cell carcinoma       0.43      0.50      0.47        20\n",
            "           vascular lesion       0.94      0.85      0.89        20\n",
            "\n",
            "                  accuracy                           0.51       174\n",
            "                 macro avg       0.52      0.51      0.51       174\n",
            "              weighted avg       0.52      0.51      0.52       174\n",
            "\n",
            "fine tuned number 1\n",
            "pretrain was True, and about to linear_fine_tune\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.264899</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.221472</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.215962</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.215153</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.210472</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.207644</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.172088</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.133194</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.111952</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.070238</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.038964</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.003049</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.967076</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.933220</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.892982</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.854430</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.816900</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.788183</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.759078</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.727809</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.694843</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.673438</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.647027</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.628778</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.615860</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.600915</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.581631</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.560289</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.539656</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.525922</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.509127</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.494207</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.482777</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.465642</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.447207</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.431680</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.409650</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.396873</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.377218</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.355507</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.334253</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.313290</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.297637</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.274735</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.259580</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.239805</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.222565</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.207852</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.188343</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.166990</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.149269</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.128861</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.107446</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.091658</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.073161</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.053888</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.033871</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.016110</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.997187</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.979666</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.960106</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.944032</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.921229</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.902681</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.881069</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.859325</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.839495</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.821539</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.806964</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.789204</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.771878</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.752886</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.736240</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.719373</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.705665</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.689252</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.672463</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.655531</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.640319</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.627295</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.612230</td>\n",
              "      <td>None</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.42      0.50      0.45        20\n",
            "      basal cell carcinoma       0.48      0.65      0.55        20\n",
            "            dermatofibroma       0.50      0.37      0.42        19\n",
            "                  melanoma       0.40      0.30      0.34        20\n",
            "                     nevus       0.83      0.50      0.62        20\n",
            "pigmented benign keratosis       0.50      0.65      0.57        20\n",
            "      seborrheic keratosis       0.42      0.53      0.47        15\n",
            "   squamous cell carcinoma       0.26      0.25      0.26        20\n",
            "           vascular lesion       0.94      0.85      0.89        20\n",
            "\n",
            "                  accuracy                           0.51       174\n",
            "                 macro avg       0.53      0.51      0.51       174\n",
            "              weighted avg       0.53      0.51      0.51       174\n",
            "\n",
            "fine tuned number 2\n",
            "please see loss function: only have rr term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert False"
      ],
      "metadata": {
        "id": "Z3zsxWVFVth_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_ZOT9RwXYbz"
      },
      "source": [
        "## Experiment: with random initial weights, we run several times with pretrain=True and pretrain=False, and record results to ensemble as well. The hope is that pretraining helps, and that ensembling also helps. If so, we can potentially implement our ensemble decorrelation idea as well"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "Jin2NWLPuJSo",
        "outputId": "c48317a0-43c4-4a23-dd8f-49e6eb94eed2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-100f62972f2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKLE8S7_XYbz"
      },
      "outputs": [],
      "source": [
        "def run_main_train(pretrain,initial_weights='no_pretrain',num_epochs=300,freeze_num_epochs=1,freeze_numfit=6,numfit=75,num=5):\n",
        "    \"run main_train num times.\"\n",
        "\n",
        "    main_dict = {}\n",
        "    for i in range(num):\n",
        "\n",
        "        main = main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "                aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "                initial_weights=initial_weights,pretrain=pretrain,\n",
        "                num_epochs=num_epochs,numfit=numfit,freeze_num_epochs=freeze_num_epochs,freeze_numfit=freeze_numfit,\n",
        "                print_report=True,\n",
        "                        )\n",
        "        \n",
        "        metrics = main()\n",
        "        main_dict[i] = metrics\n",
        "\n",
        "    return main_dict\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTsjiQcLXYb0"
      },
      "outputs": [],
      "source": [
        "lst = [False,True] #pretrain or not\n",
        "results={False:None,True:None} \n",
        "\n",
        "for pretrain in lst:\n",
        "    main_dict = run_main_train(pretrain=pretrain,num=5)\n",
        "    results[pretrain] = main_dict #main_dict has result of running main num=3 times.\n",
        "\n",
        "save_dict_to_gdrive(results,'random_weights_baseline')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QmNoFUvXYb0"
      },
      "source": [
        "#Print out result of each run and save: "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_dict_1.keys()\n",
        "\n",
        "from statistics import mean,stdev\n",
        "print('First nets trained have acc: ')\n",
        "lst_1 = [main_dict_1[i]['acc'] for i in range(len(main_dict_1.keys()))]\n",
        "print(lst_1)\n",
        "print(f'And the mean for first nets is: {mean(lst_1)}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ8ZZr6uuP8t",
        "outputId": "4a94e73f-9749-4dd1-e302-b5085a909584"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First nets trained have acc: \n",
            "[0.48275861144065857, 0.5114942789077759]\n",
            "And the mean for first nets is: 0.4971264451742172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean,stdev\n",
        "print('Second nets trained have acc: ')\n",
        "lst_2 = [main_dict_2[i]['acc'] for i in range(len(main_dict_2.keys()))]\n",
        "print(lst_2)\n",
        "print(f'And the mean for second nets is: {mean(lst_2)}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRRkrRoLu_WZ",
        "outputId": "39dde8d1-cc04-4c85-a274-26896b460b9b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second nets trained have acc: \n",
            "[0.517241358757019, 0.5114942789077759]\n",
            "And the mean for second nets is: 0.5143678188323975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {'net_1':main_dict_1,'net_2':main_dict_2}"
      ],
      "metadata": {
        "id": "2u2wYisYvVBv"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nBpdaePXYb0",
        "outputId": "81f6fc86-27e5-49ec-d9b4-f8e3f2478046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensembling within type of initial weights\n"
          ]
        }
      ],
      "source": [
        "from itertools import combinations\n",
        "\n",
        "print('Ensembling within type of initial weights')\n",
        "\n",
        "def within_ensemble_results(results,key,param='pretrain'):\n",
        "\n",
        "    print(f'Results for {key}')\n",
        "\n",
        "    _results = list(results[key].values())\n",
        "    _results = list(combinations(_results,2)) #all pairs of results. So for num=3, will be 3\n",
        "    for v in _results:\n",
        "\n",
        "        print(f\"\\nAcc of first guy in ensemble is: {v[0]['acc']}\")\n",
        "        print(f\"Acc of second guy in ensemble is: {v[1]['acc']}\")\n",
        "        _,acc = predict_ensemble(yval=yval,scores1=v[0]['scores'],scores2=v[1]['scores'])\n",
        "        print(f'Acc of ensemble is:{acc}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc63zb3FXYb1",
        "outputId": "e8bc9dfa-237f-4599-8037-fab832d7616d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for net_1\n",
            "\n",
            "Acc of first guy in ensemble is: 0.48275861144065857\n",
            "Acc of second guy in ensemble is: 0.5114942789077759\n",
            "Acc of ensemble is:0.5114942789077759\n",
            "\n"
          ]
        }
      ],
      "source": [
        "within_ensemble_results(results,key='net_1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TodlO2FzXYb1"
      },
      "outputs": [],
      "source": [
        "#within_ensemble_results(results,key=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7bIWxEDXYb1",
        "outputId": "75a89f5b-8d9d-4fb8-de13-a48586cb8874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensembling between\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "print('Ensembling between')\n",
        "\n",
        "def between_ensemble_results(results,key1,key2,param='pretrain'):\n",
        "\n",
        "\n",
        "    _results = list(zip(results[key1].values(), results[key2].values()))\n",
        "\n",
        "\n",
        "    for v in _results:\n",
        "\n",
        "        print(f\"\\nAcc of first guy in ensemble ({key1}) is: {v[0]['acc']}\")\n",
        "        print(f\"Acc of second guy in ensemble ({key2}) is: {v[1]['acc']}\")\n",
        "        _,acc = predict_ensemble(yval=yval,scores1=v[0]['scores'],scores2=v[1]['scores'])\n",
        "        print(f'Acc of ensemble is:{acc}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IeX5NmpXYb2",
        "outputId": "b1df7589-1033-4969-aa38-8617b0ff6dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Acc of first guy in ensemble (net_1) is: 0.48275861144065857\n",
            "Acc of second guy in ensemble (net_2) is: 0.517241358757019\n",
            "Acc of ensemble is:0.545976996421814\n",
            "\n",
            "\n",
            "Acc of first guy in ensemble (net_1) is: 0.5114942789077759\n",
            "Acc of second guy in ensemble (net_2) is: 0.5114942789077759\n",
            "Acc of ensemble is:0.540229856967926\n",
            "\n"
          ]
        }
      ],
      "source": [
        "between_ensemble_results(results,key1='net_1',key2='net_2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQbino69XYb2"
      },
      "source": [
        "## Ok, plan of attack now:\n",
        "\n",
        "- Does ensembling naively, with random initial weights, give performance gains? We hypothesise that YES.\n",
        "- Depending a bit on the results of this run, which we will have in 2-3 hours, we can implement ensemble decorrelation idea. (Counteract representation collapse).\n",
        "- Otherwise we have: compare supervised initial weights, self-supervised initial weights, random initial weights (with pretraining for last guy).\n",
        "- Show (hopefully) that ensembling supervised initial weights with self supervised initial weights gives performance gains beyond ensembling within type of initial weights (i.e. between ensembling better than within)\n",
        "- So we can compare the three schemes.\n",
        "\n",
        "- What else?\n",
        "\n",
        "- Another thing to consider is performance conditional on a specific condition (e.g. motivated by skin cancer). e.g. consider just predicting squamous cell carcinoma vs a few other conditions. We could try pretraining Barlow Twins "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5W-LMLQXYb2"
      },
      "source": [
        "- Ok, from a methodological point of view, are there any tweaks to the basic BT scheme, that are likely to work for our current setup. The tweaks must be: reasonably welll principled... and easy to implement, given the time constraints. We currently have:\n",
        "\n",
        "    - Small amounts of data\n",
        "    - The data itself is fairly high dimensional\n",
        "    - Somewhat high (?) between group overlap. i.e. the classes have high overlap and are hard to distingush.\n",
        "    - A very naive approach: add some more data, e.g. include some TinyImageNet data when BT pretraining. This might be a bit annoying to do. We really want algorithmic style modifications, if we can think of them.\n",
        "    - Add a simple equivariant term to Barlow Twins loss: \n",
        "        - e.g. a flag saying whether certain transformation has been applied or not {0,1}.\n",
        "        - But not the BYOL_Augs: we want EITHER sensitivity or insensitivty to a given aug (not both).\n",
        "        - I recall before that noise harmed performance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fha3mw18XYb2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-veJBC6ZXYb2"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "# #old supervised baseline (with fine tune)\n",
        "\n",
        "# tem = {0: 0.6724137663841248,\n",
        "#  1: 0.7126436829566956,\n",
        "#  2: 0.6724137663841248,\n",
        "#  3: 0.6321839094161987,\n",
        "#  4: 0.6896551847457886}\n",
        "\n",
        "# from statistics import mean\n",
        "# mean(list(tem.values()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9eaf101c0fdd45879814734484f14066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d58165f9bd8647e488fc6166fc97e082",
              "IPY_MODEL_44d29d1abfb6478791f33df288f95fa2",
              "IPY_MODEL_07457b1065d34300800dc583057b4ace"
            ],
            "layout": "IPY_MODEL_3f36256847c94420b5e8037c036cb72b"
          }
        },
        "d58165f9bd8647e488fc6166fc97e082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e03315ea5e9f4e47aa4ab7fb366612e3",
            "placeholder": "​",
            "style": "IPY_MODEL_782c74ebdda449c3a11c7ff80df03f8b",
            "value": "100%"
          }
        },
        "44d29d1abfb6478791f33df288f95fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d882a52f2094b3187afebcdba009aa7",
            "max": 94355933,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3d7e97865a54779954d556996958295",
            "value": 94355933
          }
        },
        "07457b1065d34300800dc583057b4ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_592913c511b14d54b5c6d4dce76a0048",
            "placeholder": "​",
            "style": "IPY_MODEL_d2aa7410ad53455ead6159b5280a407e",
            "value": " 90.0M/90.0M [00:01&lt;00:00, 56.9MB/s]"
          }
        },
        "3f36256847c94420b5e8037c036cb72b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e03315ea5e9f4e47aa4ab7fb366612e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "782c74ebdda449c3a11c7ff80df03f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d882a52f2094b3187afebcdba009aa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3d7e97865a54779954d556996958295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "592913c511b14d54b5c6d4dce76a0048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2aa7410ad53455ead6159b5280a407e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}