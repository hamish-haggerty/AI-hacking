{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[],"include_colab_link":true},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/hamish-haggerty/AI-hacking/blob/master/SSL/BT_MNIST_new3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"# !pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0\n# !pip install fastai==2.6.3 --no-deps\n!pip install self_supervised\n\n!pip install pytest\n!pip install ipytest","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"X8jFsEXz_61O","outputId":"5ab690f3-0404-43c3-96e6-b0a30743c8ac","execution":{"iopub.status.busy":"2022-10-13T04:36:49.790812Z","iopub.execute_input":"2022-10-13T04:36:49.791166Z","iopub.status.idle":"2022-10-13T04:37:17.940530Z","shell.execute_reply.started":"2022-10-13T04:36:49.791128Z","shell.execute_reply":"2022-10-13T04:37:17.939375Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: self_supervised in /opt/conda/lib/python3.7/site-packages (1.0.4)\nRequirement already satisfied: kornia>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from self_supervised) (0.5.8)\nRequirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from self_supervised) (22.1.2)\nRequirement already satisfied: timm>=0.4.5 in /opt/conda/lib/python3.7/site-packages (from self_supervised) (0.6.11)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from self_supervised) (21.3)\nRequirement already satisfied: fastai>=2.2.7 in /opt/conda/lib/python3.7/site-packages (from self_supervised) (2.7.9)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (6.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.7.3)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (0.0.7)\nRequirement already satisfied: fastcore<1.6,>=1.4.5 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.5.26)\nRequirement already satisfied: torch<1.14,>=1.7 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.11.0)\nRequirement already satisfied: pillow>6.0.0 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (9.1.1)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (3.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (2.28.1)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.0.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (3.5.3)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (0.12.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.7->self_supervised) (1.3.5)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm>=0.4.5->self_supervised) (0.8.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->self_supervised) (3.0.9)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.4.2)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.8.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.3.0)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.1.2)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.0.7)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.0.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.0.8)\nRequirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (4.1.1)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.0.6)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.10.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (59.8.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (4.64.0)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.6.2)\nRequirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (8.0.17)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (0.7.8)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (3.0.10)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (1.21.6)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.7->self_supervised) (2.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.7->self_supervised) (2022.6.15.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm>=0.4.5->self_supervised) (4.12.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm>=0.4.5->self_supervised) (3.7.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (1.4.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.7->self_supervised) (4.33.3)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fastai>=2.2.7->self_supervised) (2022.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai>=2.2.7->self_supervised) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai>=2.2.7->self_supervised) (1.0.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<4->fastai>=2.2.7->self_supervised) (3.8.0)\nRequirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<4->fastai>=2.2.7->self_supervised) (5.2.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->fastai>=2.2.7->self_supervised) (1.15.0)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai>=2.2.7->self_supervised) (8.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<4->fastai>=2.2.7->self_supervised) (2.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (7.1.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest) (21.3)\nRequirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from pytest) (1.11.0)\nRequirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest) (4.12.0)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest) (21.4.0)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest) (2.0.1)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest) (1.1.1)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest) (1.0.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest) (3.8.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pytest) (3.0.9)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: ipytest in /opt/conda/lib/python3.7/site-packages (0.12.0)\nRequirement already satisfied: pytest>=5.4 in /opt/conda/lib/python3.7/site-packages (from ipytest) (7.1.3)\nRequirement already satisfied: ipython in /opt/conda/lib/python3.7/site-packages (from ipytest) (7.33.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from ipytest) (21.3)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.4->ipytest) (21.4.0)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.4->ipytest) (1.0.0)\nRequirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.4->ipytest) (1.11.0)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest>=5.4->ipytest) (1.1.1)\nRequirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.4->ipytest) (4.12.0)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.4->ipytest) (2.0.1)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython->ipytest) (5.3.0)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython->ipytest) (0.18.1)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython->ipytest) (2.12.0)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython->ipytest) (0.1.3)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython->ipytest) (59.8.0)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython->ipytest) (0.7.5)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython->ipytest) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython->ipytest) (4.8.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython->ipytest) (5.1.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython->ipytest) (3.0.30)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->ipytest) (3.0.9)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (3.8.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython->ipytest) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython->ipytest) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipytest) (0.2.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"%%javascript\nfunction ClickConnect(){\nconsole.log(\"Working\");\ndocument.querySelector(\"colab-toolbar-button#connect\").click()\n}setInterval(ClickConnect,60000)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"BOv4kkJDag8r","outputId":"49fee111-45ba-4c1c-898f-c4a940fae234","execution":{"iopub.status.busy":"2022-10-12T01:08:52.753713Z","iopub.execute_input":"2022-10-12T01:08:52.756581Z","iopub.status.idle":"2022-10-12T01:08:52.774039Z","shell.execute_reply.started":"2022-10-12T01:08:52.756535Z","shell.execute_reply":"2022-10-12T01:08:52.773142Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"function ClickConnect(){\nconsole.log(\"Working\");\ndocument.querySelector(\"colab-toolbar-button#connect\").click()\n}setInterval(ClickConnect,60000)\n"},"metadata":{}}]},{"cell_type":"code","source":"import fastai\nimport self_supervised\nimport torch\nif torch.cuda.is_available():device='cuda'\nelse:device='cpu'\n#assert(fastai.__version__ == '2.6.3') #Check that version is 2.6.3","metadata":{"id":"Pk01WY_Dag8s","execution":{"iopub.status.busy":"2022-10-13T04:37:30.281562Z","iopub.execute_input":"2022-10-13T04:37:30.282060Z","iopub.status.idle":"2022-10-13T04:37:32.506957Z","shell.execute_reply.started":"2022-10-13T04:37:30.282011Z","shell.execute_reply":"2022-10-13T04:37:32.505926Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.all import *\nfrom self_supervised.augmentations import *\nfrom self_supervised.layers import *\nfrom torchvision import transforms\nimport inspect\nimport warnings\nimport random\nimport math\nwarnings.filterwarnings(\"ignore\")\nimport ipytest\nipytest.autoconfig()\nimport pytest","metadata":{"id":"AOjr_YCLag8t","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7019d8a5-9001-4424-aa35-b9501f91d059","execution":{"iopub.status.busy":"2022-10-13T04:37:35.255608Z","iopub.execute_input":"2022-10-13T04:37:35.256505Z","iopub.status.idle":"2022-10-13T04:37:37.491974Z","shell.execute_reply.started":"2022-10-13T04:37:35.256452Z","shell.execute_reply":"2022-10-13T04:37:37.490893Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Like most other SSL algorithms BT's model consists of an encoder and projector (MLP) layer.\n#Definition is straightforward:\n#https://colab.research.google.com/github/KeremTurgutlu/self_supervised/blob/master/nbs/14%20-%20barlow_twins.ipynb#scrollTo=1M6QcUChcvpz\nclass BarlowTwinsModel(Module):\n    \"\"\"An encoder followed by a projector\n    \"\"\"\n    def __init__(self,encoder,projector):self.encoder,self.projector = encoder,projector\n        \n    def forward(self,x): return self.projector(self.encoder(x))","metadata":{"id":"XTSdKC6bag8t","execution":{"iopub.status.busy":"2022-10-13T04:37:41.783481Z","iopub.execute_input":"2022-10-13T04:37:41.784036Z","iopub.status.idle":"2022-10-13T04:37:41.798362Z","shell.execute_reply.started":"2022-10-13T04:37:41.783980Z","shell.execute_reply":"2022-10-13T04:37:41.797141Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#HOWEVER instead of directly using the above, by passing both an encoder and a projector, create_barlow_twins_model\n#function can be used by minimally passing a predefined encoder and the expected input channels.\n\n#In the paper it's mentioned that MLP layer consists of 3 layers... following function will create a 3 layer\n#MLP projector with batchnorm and ReLU by default. Alternatively, you can change bn and nlayers. \n\n#Questions: Why torch.no_grad() when doing this?\ndef create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n    \"Create Barlow Twins model\"\n    n_in  = in_channels(encoder)\n    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n    apply_init(projector)\n    return BarlowTwinsModel(encoder, projector)\n\n#Similar to above. Simple API to make the BT model:","metadata":{"id":"ZL3EE07Pag8u","execution":{"iopub.status.busy":"2022-10-13T04:37:44.329009Z","iopub.execute_input":"2022-10-13T04:37:44.329470Z","iopub.status.idle":"2022-10-13T04:37:44.340295Z","shell.execute_reply.started":"2022-10-13T04:37:44.329431Z","shell.execute_reply":"2022-10-13T04:37:44.339208Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#BarlowTwins Callback\n#The following parameters can be passed:\n# - aug_pipelines\n# Imb lambda is the weight for redundancy reduction term in the loss function\n\n@delegates(get_multi_aug_pipelines)\ndef get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(n=2,size=size,**kwargs)","metadata":{"id":"DFjGL-COag8v","execution":{"iopub.status.busy":"2022-10-13T04:37:50.760921Z","iopub.execute_input":"2022-10-13T04:37:50.761477Z","iopub.status.idle":"2022-10-13T04:37:50.769314Z","shell.execute_reply.started":"2022-10-13T04:37:50.761431Z","shell.execute_reply":"2022-10-13T04:37:50.768154Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Uniform random number between a and b\ndef Unif(a,b):\n    return (b-a)*torch.rand(1).item()+a","metadata":{"id":"xx4KsywAag8v","execution":{"iopub.status.busy":"2022-10-11T12:39:03.961155Z","iopub.execute_input":"2022-10-11T12:39:03.961709Z","iopub.status.idle":"2022-10-11T12:39:03.968681Z","shell.execute_reply.started":"2022-10-11T12:39:03.961668Z","shell.execute_reply":"2022-10-11T12:39:03.967474Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def random_sinusoid(x,std=0.1,seed=0):\n    \n    seed_everything(seed=seed)    \n    t=(std) * torch.randn(1,500).to(device)\n    s=(std) * torch.randn(1,500).to(device)\n    \n    u=torch.randn(1,500).to(device)\n    v=torch.randn(1,500).to(device)\n\n    a=(0.2) * torch.randn(1,500).to(device)\n    b=(0.2) * torch.randn(1,500).to(device)\n    # N = torch.abs(a) + torch.abs(b)\n    # a = a/N\n    # b = b/N\n\n    return a*torch.sin(t*x[:,]*math.pi+u) + b*torch.cos(s*x[:,]*math.pi+v)\n\n\n    \n    #return torch.sin(t*math.pi*x+u) + torch.cos(s*math.pi*x + v)","metadata":{"id":"zU4GwLruU5AD","execution":{"iopub.status.busy":"2022-10-13T04:37:53.901579Z","iopub.execute_input":"2022-10-13T04:37:53.902041Z","iopub.status.idle":"2022-10-13T04:37:53.916715Z","shell.execute_reply.started":"2022-10-13T04:37:53.902002Z","shell.execute_reply":"2022-10-13T04:37:53.915622Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#New stuff\nclass Cdiff_Rand:\n    \n    def __init__(self,seed,bs,std=0.1,K=2):\n        self.seed=seed\n        self.std=std\n        self.K=2\n        self.bs=bs\n\n    def __call__(self,z1norm,z2norm):\n        \n        cdiff_rand=0\n        for i in range(self.K):\n\n            z1norm_2,z2norm_2 = random_sinusoid(z1norm,std=self.std,seed=self.seed+i), random_sinusoid(z2norm,std=self.std,seed=2*self.seed+i)\n            cdiff_rand = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,bs=bs)\n\n        cdiff_rand=(1/self.K)*cdiff_rand\n    \n        return cdiff_rand\n  ","metadata":{"id":"Xej8_KxJ71Sl","execution":{"iopub.status.busy":"2022-10-13T07:23:37.999959Z","iopub.execute_input":"2022-10-13T07:23:38.000668Z","iopub.status.idle":"2022-10-13T07:23:38.010623Z","shell.execute_reply.started":"2022-10-13T07:23:38.000630Z","shell.execute_reply":"2022-10-13T07:23:38.007494Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"#New stuff\ndef C_z1z2(z1norm,z1norm_2,z2norm,z2norm_2,bs):\n    \n    Ctem1 =  (z1norm.T @ z2norm_2) / bs\n    Ctem2 = (z1norm_2.T @ z2norm) / bs\n    cdiff_2 = (0.5*Ctem1.pow(2) + 0.5*Ctem2.pow(2))\n\n    return cdiff_2\n\nclass Max_Corr(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(ps,ps)\n        self.fc2 = nn.Linear(ps,ps)\n\n        self.fc3 = nn.Linear(ps,ps)\n        self.fc4 = nn.Linear(ps,ps)\n\n        self.sigmoid = nn.Sigmoid()\n\n        self.relu = nn.ReLU()\n    def forward(self,x,y):\n\n        x=self.sigmoid(self.fc1(x)) #when (sigmoid,relu) GREAT results, with (sigmoid,sigmoid) TERRIBLE. Currently testing (relu,relu)\n        x=self.fc2(x)\n       \n        y=self.relu(self.fc3(y)) #originally had relu and got really good results. If we can't reproduce those results, possible reasons:\n                                    #results were due to chance; or having relu on one branch (and sigmoid on the other) helps via breaking\n                                      #the symmetry! Other idea: set fc1=fc3, fc2=fc4. \n        y=self.fc4(y)\n\n        return x,y\n\nclass Cdiff_Sup:\n    \n    def __init__(self,I,inner_steps,bs):\n        \n        self.I=I\n        self.inner_steps=inner_steps\n        self.bs=bs\n        self.max_corr = Max_Corr()\n        if device == 'cuda':\n            self.max_corr.cuda()\n        \n    def inner_step(self,z1norm,z2norm):\n    \n        max_corr=self.max_corr\n        I=self.I\n        bs=self.bs\n        inner_steps=self.inner_steps\n\n        z1norm=z1norm.detach()\n        z2norm=z2norm.detach()\n\n        # z1norm=z1norm[:,0]\n        # z2norm=z2norm[:,0]\n\n        max_corr = Max_Corr()\n        max_corr.cuda()\n    \n        # for p in max_corr.parameters():\n        #     p.requires_grad=True]\n\n        optimizer = torch.optim.Adam(list(max_corr.parameters()),lr=0.001)\n        for i in range(inner_steps):\n            z1norm_2,z2norm_2=max_corr(z1norm,z2norm)\n            #z1norm_2 = (z1norm_2 - z1norm_2.mean(0)) / z1norm_2.std(0, unbiased=False)\n        \n            assert (z1norm_2.shape,z2norm_2.shape) == (z1norm.shape,z2norm.shape)\n\n            # Ctem1 =  (z1norm.T @ z2norm_2) / bs\n            # Ctem2 = (z1norm_2.T @ z2norm) / bs\n            # cdiff_2 = (0.5*Ctem1.pow(2) + 0.5*Ctem2.pow(2))\n\n            cdiff_2 = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,bs=bs)\n            #cdiff_2=Ctem.pow(2)\n\n            inner_loss=-1*(cdiff_2*(1-I)).mean()\n\n            optimizer.zero_grad()\n            inner_loss.backward()\n            optimizer.step()\n        \n        for p in max_corr.parameters():\n            p.requires_grad=False\n            \n        return max_corr\n    \n    def __call__(self,z1norm,z2norm):\n        \n            max_corr =  self.inner_step(z1norm,z2norm)\n            z1norm_2,z2norm_2 = max_corr(z1norm,z2norm)\n      \n            cdiff_sup = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,bs=bs)\n    \n            return cdiff_sup\n","metadata":{"id":"XsNBXcIjyjD2","execution":{"iopub.status.busy":"2022-10-13T04:38:08.345517Z","iopub.execute_input":"2022-10-13T04:38:08.345977Z","iopub.status.idle":"2022-10-13T04:38:08.375742Z","shell.execute_reply.started":"2022-10-13T04:38:08.345938Z","shell.execute_reply":"2022-10-13T04:38:08.374802Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Like most other SSL algorithms BT's model consists of an encoder and projector (MLP) layer.\n#Definition is straightforward:\n#https://colab.research.google.com/github/KeremTurgutlu/self_supervised/blob/master/nbs/14%20-%20barlow_twins.ipynb#scrollTo=1M6QcUChcvpz\nclass BarlowTwinsModel(Module):\n    \"\"\"An encoder followed by a projector\n    \"\"\"\n    def __init__(self,encoder,projector,projector2):self.encoder,self.projector,self.projector2 = encoder,projector,projector2\n        \n    def forward(self,x): \n        # print('BarlowTwinsModel...')\n        # print(x.shape)\n        # print('shape of x')\n        # input()\n\n        # print(self.encoder(x).shape)\n        # print('shape of encoder(x)')\n        # input()\n        # print(self.projector(self.encoder(x)).shape)\n        \n        # input('shape of z')\n        tem = self.encoder(x)\n        \n        return self.projector(tem),self.projector2(tem)\n    \n    \n#HOWEVER instead of directly using the above, by passing both an encoder and a projector, create_barlow_twins_model\n#function can be used by minimally passing a predefined encoder and the expected input channels.\n\n#In the paper it's mentioned that MLP layer consists of 3 layers... following function will create a 3 layer\n#MLP projector with batchnorm and ReLU by default. Alternatively, you can change bn and nlayers. \n\n#Questions: Why torch.no_grad() when doing this?\ndef create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n    \"Create Barlow Twins model\"\n    n_in  = in_channels(encoder)\n    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n    apply_init(projector)\n    \n    projector2 = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n    apply_init(projector2)\n    \n    return BarlowTwinsModel(encoder, projector,projector2)\n\n#Similar to above. Simple API to make the BT model:","metadata":{"execution":{"iopub.status.busy":"2022-10-13T04:38:16.040063Z","iopub.execute_input":"2022-10-13T04:38:16.040530Z","iopub.status.idle":"2022-10-13T04:38:16.058439Z","shell.execute_reply.started":"2022-10-13T04:38:16.040490Z","shell.execute_reply":"2022-10-13T04:38:16.057365Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#export\nclass BarlowTwins(Callback):\n    order,run_valid = 9,True\n    def __init__(self, aug_pipelines, lmb=5e-3, print_augs=False):\n        assert_aug_pipelines(aug_pipelines)\n        self.aug1, self.aug2 = aug_pipelines\n        if print_augs: print(self.aug1), print(self.aug2)\n        store_attr('lmb')\n        self.index=-1\n\n        self.inner_steps=4\n        \n    def before_fit(self): \n        self.learn.loss_func = self.lf\n        nf = self.learn.model.projector[-1].out_features\n        self.I = torch.eye(nf).to(self.dls.device)\n\n    def update_seed(self):\n        \n        indexmod=2\n        if self.index%indexmod == 0: #every `indexmod` index update the seed (best we have found so far)\n            self.seed = np.random.randint(0,10000)\n\n    def before_epoch(self):\n        self.index=-1\n\n        if self.epoch%10==0:\n            self.inner_steps += 1\n            \n    def before_batch(self):\n    \n        xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n        self.learn.xb = (torch.cat([xi, xj]),)\n\n        self.index=self.index+1\n        self.update_seed()\n\n\n\n        #Uncomment to run standard BT\n    def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n        #bs,nf = pred.size(0)//2,pred.size(1)\n        bs,nf = pred[0].size(0)//2,pred[0].size(1)\n        \n        pred1=pred[0]\n        pred2=pred[0]\n                \n        z1, z2 = pred1[:bs],pred1[bs:] #so z1 is bs*projection_size, likewise for z2\n\n        #Used to encode invariance\n        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n        \n        seed=self.seed\n        #Used to encode redundancy-reduction\n        z1_two,z2_two = pred2[:bs],pred2[bs:]\n        z1norm_two = (z1_two - z1_two.mean(0)) / z1_two.std(0, unbiased=False)\n        z2norm_two = (z2_two - z2_two.mean(0)) / z2_two.std(0, unbiased=False)\n        \n        #C = (z1norm.T @ z2norm) / bs\n        #C_two = (z1norm.T @ z2norm) / bs\n        Invar = (z1norm-z2norm).pow(2)\n        \n        #z1norm_two_a = random_sinusoid(z1norm_two,seed=seed+0)\n        #z2norm_two_a = random_sinusoid(z2norm_two,seed=seed+10)\n        \n        z1norm_two_a = z1norm_two\n        z2norm_two_a = z2norm_two\n        #C_two = (z1norm_two.T @ z2norm_two) / bs\n        #cdiff = C_two.pow(2)\n        \n        CdiffRand = Cdiff_Rand(seed=self.seed,bs=bs,std=0.2,K=2)\n        cdiff = CdiffRand(z1norm_two,z2norm_two)\n        \n        #cdiff=C_z1z2(z1norm_two_a,z2norm_two,z1norm_two_a,z2norm_two,bs)\n        redun_reduc = self.lmb*cdiff\n        \n        #Other stuff - i.e. we want the two representations to be different\n        #C1 = (z1norm.T @ z1norm_two) / bs\n        #C2 = (z2norm.T @ z2norm_two) / bs\n        \n        CdiffRand = Cdiff_Rand(seed=self.seed,bs=bs,std=0.2,K=2)\n        cdiff1 = CdiffRand(z1norm,z1norm_two)\n        \n        CdiffRand = Cdiff_Rand(seed=self.seed,bs=bs,std=0.2,K=2)\n        cdiff2 = CdiffRand(z2norm,z2norm_two)\n        \n#         z1norm_sin = random_sinusoid(z1norm,seed=seed+20)\n#         z1norm_two_sin = random_sinusoid(z1norm_two,seed=seed+40)\n#         z2norm_sin = random_sinusoid(z2norm,seed=seed+100)\n#         z2norm_two_sin = random_sinusoid(z2norm_two,seed=seed+350)\n#         cdiff = self.lmb*C_z1z2(z1norm_sin,z1norm_two,z2norm,z2norm_two_sin,bs)\n        #cdiff = self.lmb*C_z1z2(z1norm,z1norm_2,z2norm,z2norm_2,bs)\n        #cdiff1 = self.lmb*C1.pow(2)\n        #cdiff2 = self.lmb*C2.pow(2)\n        \n        cdiff = self.lmb*(cdiff1+cdiff2)\n        #cdiff = self.lmb*C1.pow(2) +  self.lmb*C2.pow(2)\n        \n        #No collapse\n        relu = nn.ReLU()\n        eps=1e-7\n        #C = (z1norm.T @ z1norm) / bs\n        \n        cdiffa=relu(1-(z1.var(0,unbiased=False)+eps).pow(0.5))\n        cdiffb=relu(1-(z1_two.var(0,unbiased=False)+eps).pow(0.5))\n        \n        loss = (1/nf)*Invar.sum() + 0.5*(cdiffa + cdiffb).sum()+ (redun_reduc + cdiff).sum()\n        \n#         C = (z1norm.T @ z2norm) / bs \n#         cdiff = (C - self.I)**2\n#         loss = (cdiff*self.I + cdiff*(1-self.I)*self.lmb).sum() \n        return loss\n\n\n    # def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n        \n    #     bs,nf = pred.size(0)//2,pred.size(1)\n\n    #     #All standard, from BT\n    #     z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n    #     z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n    #     z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n        \n    #     C = (z1norm.T @ z2norm) / bs \n    #     cdiff = (C - self.I)**2\n\n\n\n    #     # #Let's change this block to rewritten (should do same thing)\n    #     # max_corr = inner_step(z1norm,z2norm,I=self.I,inner_steps=5)#,inner_steps=self.inner_steps)\n    #     # z1norm_2,z2norm_2 = max_corr(z1norm,z2norm)\n    #     # Ctem1 =  (z1norm.T @ z2norm_2) / bs\n    #     # Ctem2 = (z1norm_2.T @ z2norm) / bs\n    #     # #Ctem = (z1norm_2.T @ z2norm_2) / bs\n    #     # #cdiff_2 = Ctem.pow(2)\n    #     # cdiff_2 = (0.5*Ctem1.pow(2) + 0.5*Ctem2.pow(2)) #+ 0.1*Ctem.pow(2)\n\n\n    #     CdiffSup = Cdiff_Sup(I=self.I,inner_steps=5,bs=bs)\n    #     cdiff_2 = CdiffSup(z1norm,z2norm)\n\n    #     CdiffRand = Cdiff_Rand(seed=self.seed,bs=bs,std=0.2,K=2)\n    #     cdiff_2_2 = CdiffRand(z1norm,z2norm)\n\n    #     cdiff_2 = 0.5*cdiff_2_2 + 0.5*cdiff_2\n            \n    #     l2 = cdiff_2*(1-self.I)*self.lmb #Is either the standard term - or not.\n\n    #     loss = (cdiff*self.I + l2).sum()\n    #     torch.cuda.empty_cache()\n    #     return loss\n\n    @torch.no_grad()\n    def show(self, n=1):\n \n        bs = self.learn.x.size(0)//2\n        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]\n        #x1 = TensorImageBW(x1)\n        #x2 = TensorImageBW(x2)\n        idxs = np.random.choice(range(bs),n,False)\n        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n        images = []\n        for i in range(n): images += [x1[i],x2[i]]\n        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)","metadata":{"id":"a2Exs2s3ag8z","execution":{"iopub.status.busy":"2022-10-13T07:23:55.991468Z","iopub.execute_input":"2022-10-13T07:23:55.993423Z","iopub.status.idle":"2022-10-13T07:23:56.017052Z","shell.execute_reply.started":"2022-10-13T07:23:55.993375Z","shell.execute_reply":"2022-10-13T07:23:56.016134Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"#Debugging cell - delete later (similar to cell below)\nps=500\nhs=500\n#So I think I just just replace this line:\n#fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n#with this one:\nfastai_encoder = create_fastai_encoder(xresnet18(),pretrained=False,n_in=1)\n\n#fastai_encoder = create_body(xresnet18(n_out=512),n_in=1,pretrained=False)\n\nmodel = create_barlow_twins_model(fastai_encoder, hidden_size=hs,projection_size=ps)# projection_size=1024)\n\n#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n#values for these which is tantamount to doing nothing\n#So if we choose resize_scale=(1,1) then the images look the same.\n#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\naug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=True)\n\n#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwRMSProp(model.parameters(),lr=0.1, mom=0.9)ins(aug_pipelines, print_augs=True)])\nopt = torch.optim.RMSprop\n#partial(OptimWrapper, opt=opt)\nlearn = Learner(dls,model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n#learn = Learner(dls, model,opt_func=opt_func, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n\nlearn.fit(100) #300                            ","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vbS1WtLiag80","outputId":"8a0b4cd1-5225-4a82-a901-61ab409cb819","execution":{"iopub.status.busy":"2022-10-13T07:24:05.408619Z","iopub.execute_input":"2022-10-13T07:24:05.409020Z","iopub.status.idle":"2022-10-13T08:04:42.059462Z","shell.execute_reply.started":"2022-10-13T07:24:05.408982Z","shell.execute_reply":"2022-10-13T08:04:42.054982Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\nPipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>519.296631</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>398.268585</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>322.588989</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>275.377899</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>258.288696</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>223.454178</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>199.597305</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>182.524490</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>166.419586</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>150.632614</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>159.312302</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>148.844360</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>134.423416</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>133.101532</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>130.029968</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>121.332062</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>120.089935</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>117.264572</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>106.882759</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>108.793533</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>116.439636</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>109.505165</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>106.069618</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>106.599800</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>97.869545</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>94.675415</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>94.802193</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>89.613358</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>88.185287</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>95.548882</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>95.100090</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>87.896309</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>87.163345</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>83.966820</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>80.831856</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>82.095863</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>81.085732</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>78.465553</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>80.458008</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>79.502213</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>77.320236</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>77.197105</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>77.883881</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>73.267044</td>\n      <td>None</td>\n      <td>00:25</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>71.334175</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>74.193130</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>70.423164</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>69.993057</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>70.809761</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>71.916145</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>71.644211</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>72.078697</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>67.932274</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>65.870651</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>68.138489</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>67.071457</td>\n      <td>None</td>\n      <td>00:25</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>65.678192</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>66.918861</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>71.182663</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>67.482918</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>66.219917</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>65.145012</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>62.678413</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>60.998238</td>\n      <td>None</td>\n      <td>00:23</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>61.355968</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>58.405960</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>59.311714</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>64.681335</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>62.120361</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>62.602562</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>63.407581</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>59.943497</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>57.867306</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>58.939964</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>57.991505</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>57.099792</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>58.200138</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>61.434494</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>59.282063</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>58.800930</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>57.555176</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>54.848541</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>54.504063</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>53.936390</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>51.884354</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>55.129536</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>58.997204</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>56.169548</td>\n      <td>None</td>\n      <td>00:25</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>55.577015</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>56.489307</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>53.088341</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>52.475178</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>56.006092</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>53.671986</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>51.225319</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>53.411430</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>54.131569</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>50.977230</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>52.188469</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>50.919617</td>\n      <td>None</td>\n      <td>00:24</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"#new\ndef seed_everything(seed=42):\n    \"\"\"\"\n    Seed everything.\n    \"\"\"   \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\ndef tune_set(items0,seed=None,bs_tune=20):\n    \n    seed_everything(seed=seed)\n    \n    items0=items0.shuffle()\n    d = {'0':0,'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0,'8':0,'9':0}\n    ITEMS=[]\n    for i in items0:\n        s=str(i).split('/training/')[1][0]\n        if d[s] is 0 or d[s] is 1:\n            ITEMS.append(i)\n            d[s]+=1\n    #items0=ITEMS\n\n    for i in items0:\n        if i not in ITEMS:\n            ITEMS.append(i)\n            \n    split = IndexSplitter(list(range(bs_tune)))\n\n    tds_tune = Datasets(ITEMS, [PILImageBW.create, [parent_label, Categorize()]], splits=split(ITEMS)) #Or do we want this?\n    dls_tune = tds_tune.dataloaders(bs=bs_tune,num_workers=0, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n    \n    return dls_tune\n","metadata":{"id":"Fdbbd-uV8Ltr","execution":{"iopub.status.busy":"2022-10-13T04:41:32.155234Z","iopub.execute_input":"2022-10-13T04:41:32.155681Z","iopub.status.idle":"2022-10-13T04:41:32.173585Z","shell.execute_reply.started":"2022-10-13T04:41:32.155642Z","shell.execute_reply":"2022-10-13T04:41:32.172331Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def shuffle_items(items,seed):\n    \"\"\"Helper function to sort a list according to given random seed\n    \"\"\"\n    items.sort()\n    \n    if seed !=None:\n        seed_everything(seed=seed)\n        items=items.shuffle()\n    \n    return items\n\nclass BT_Data:\n    \n    def __init__(self,items,seed=42,ts=16384,bs=512,tune_s=2000,bs_tune=20,bs_test=578):\n        \n        self.ts=ts\n        self.bs=bs\n        self.tune_s=tune_s\n        self.bs_tune=bs_tune\n        self.bs_test=bs_test\n        \n        self._seed=seed\n        self.seed=seed\n        items=shuffle_items(items,seed)\n        self.items=items\n\n    @property\n    def seed(self):\n        return self._seed\n    \n    @seed.setter #When we update the seed, we update the datasets (so items and dls objects) accordingly\n    def seed(self,val):\n        self._seed=val\n        self.items = shuffle_items(items,val)\n        self.build_items_i()\n        self.build_dls()\n        \n    def build_items_i(self):\n        self.items1 = self.items[0:ts] #train BT on these guys\n        self.items0 = self.items[self.ts:self.ts+self.tune_s] #for fine tuning - just choose 2000 guys to extract 20 for fine tuning \n        self.items2 = self.items[self.ts+self.tune_s:] #test on remainder\n        \n    def build_dls(self):\n        \n        split = RandomSplitter(valid_pct=0.0)\n        tds = Datasets(self.items1, [PILImageBW.create, [parent_label, Categorize()]], splits=split(self.items1))\n        self.dls = tds.dataloaders(bs=self.bs,num_workers=0, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n\n        #Evaluate linear classifier on this guy\n        split = RandomSplitter(valid_pct=0.0) #randomly split training set into training and validation\n        tds_test = Datasets(self.items2, [PILImageBW.create, [parent_label, Categorize()]], splits=split(self.items2)) #Or do we want this?\n        self.dls_test = tds_test.dataloaders(bs=self.bs_test,num_workers=0, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n\n\ndef build_BT_Data(items,seed,tune_seed):\n    ts=16384\n    bs=512\n    tune_s=2000\n    bs_tune=20\n    bs_test=578\n    \n    k=dict(seed=seed,ts=ts,bs=bs,tune_s=tune_s,bs_tune=bs_tune,bs_test=bs_test)\n    bt_dataset = BT_Data(items=items,**k)\n\n    items = bt_dataset.items\n    items1 = bt_dataset.items1\n    items0 = bt_dataset.items0\n    items2 = bt_dataset.items2\n\n    dls = bt_dataset.dls\n    dls_test = bt_dataset.dls_test\n\n    dls_tune=tune_set(items0=items0,seed=seed,bs_tune=bs_tune)\n    \n    return dict(seed=seed,tune_seed=tune_seed,items=items,items1=items1,items0=items0,items2=items2,dls=dls,dls_test=dls_test,dls_tune=dls_tune)\n\n\n","metadata":{"id":"89bdbbno8TNf","execution":{"iopub.status.busy":"2022-10-13T04:41:35.037666Z","iopub.execute_input":"2022-10-13T04:41:35.038153Z","iopub.status.idle":"2022-10-13T04:41:35.061067Z","shell.execute_reply.started":"2022-10-13T04:41:35.038074Z","shell.execute_reply":"2022-10-13T04:41:35.060060Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#new\n\npath = untar_data(URLs.MNIST)\nitems = get_image_files(path/'training') #i.e. NOT testing!!!\nitems.sort()\n\nseed=420\ntune_seed=100\nts=16384\nbs=512\ntune_s=2000\nbs_tune=20\nbs_test=578\n\nbt_data = BT_Data(items=items,seed=seed,ts=ts,bs=bs,tune_s=tune_s,bs_tune=bs_tune,bs_test=bs_test)\n\nitems1=bt_data.items1\nitems0=bt_data.items0\nitems2=bt_data.items2\n\ndls=bt_data.dls\ndls_test=bt_data.dls_test\n\n","metadata":{"id":"7gKpW58J8oiU","execution":{"iopub.status.busy":"2022-10-13T04:42:19.127499Z","iopub.execute_input":"2022-10-13T04:42:19.129809Z","iopub.status.idle":"2022-10-13T04:42:29.222668Z","shell.execute_reply.started":"2022-10-13T04:42:19.129770Z","shell.execute_reply":"2022-10-13T04:42:29.221574Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"%%ipytest -qq\n#TODO: Rewrite so works for both (seed,tune_seed) = (42,10) and (420,100). At the moment \n\nlabeller = using_attr(RegexLabeller(pat = r'(\\d+).png$'), 'name')\nconvert_tensor = transforms.ToTensor()\nExpected_first_item = {42:{'items1':'19825','items0':'40684','items2':'43064'},420:{'items1':'44942','items0':'23821','items2':'908'}}\nExpected_first_dls = {42:{'dls':0.085169,'dls_test':0.099924},420:{'dls':0.183678,'dls_test':0.162825}}\nExpected_first_dls_tune = {(42,55):0.093707,(420,55):0.1513355}\n\nbt_data_42 = build_BT_Data(items=items,seed=42,tune_seed=10)\nbt_data_420 = build_BT_Data(items=items,seed=420,tune_seed=100)\n\ndef verify_DatasetShape(dls_obj,batch_size,ds_settype='train'):\n    \"\"\"\"Helper function to verify shape of a dls object given the batch size; ds_settype is either `train` or \n        `valid`. The idea is we want the batch_size to divide the length of the dlsobj.\n    \"\"\"\n    \n    tem = len(getattr(dls_obj,ds_settype)) #length of dlsobj.train or dlsobj.valid depending on settpe\n    return tem*batch_size == len(getattr(dls_obj,ds_settype+'_ds'))\n\ndef verify_first_item(items,expected):\n    \"\"\"Helper function to verify first element of items is as expected, given random seed of 42\n    \"\"\"\n        \n    return labeller(items[0]) == expected\n        \ndef verify_first_dls(dls_obj,expected,ds_settype='train'):\n    \"\"\"Helper function to verify first element of the given dls object is as expected, given random seed of 42.\n        Note that ds_settype is either `train` or `valid\n    \"\"\"\n    \n    #All we are doing here is getting the first tensor in, for example e.g. dls_obj.train_ds and computing\n    #the mean of all the elements. If random seed is same, then it should give the same results\n    z=convert_tensor(next(iter(getattr(dls_obj,ds_settype+'_ds')))[0]).mean().item()\n    \n    #logging.debug(f'with {ds_settype} has: {z}')\n    assert z-expected < 0.0001\n\n    \n@pytest.mark.parametrize('bt_dataset',[bt_data_42,bt_data_420])\nclass Test_shapes:\n    \n    def test_shape_dlsobjects(self,bt_dataset):\n        \"\"\"\"Test the shape of each dlsobj\n        \"\"\"\n    \n        assert verify_DatasetShape(bt_dataset['dls'],batch_size=bs,ds_settype='train')\n\n        assert verify_DatasetShape(bt_dataset['dls_tune'],batch_size=bs_tune,ds_settype='valid')\n\n        assert verify_DatasetShape(bt_dataset['dls_test'],batch_size=bs_test,ds_settype='train')\n    \n    def test_length_dlsobjects(self,bt_dataset):\n        \"\"\"\"Test the length of each dlsobj that we use\n        \"\"\"\n        assert len(bt_dataset['dls'].train_ds) == ts and len(bt_dataset['dls_tune'].valid_ds) == bs_tune and len(bt_dataset['dls_test'].train_ds)==41616\n    \n    \n@pytest.mark.parametrize('bt_dataset',[bt_data_42,bt_data_420])   \nclass Test_first:\n    \n    def test_first_item(self,bt_dataset):\n        \"\"\"\"Verify that the first item of each items is as expected\n        \"\"\"\n\n        seed = bt_dataset['seed']\n\n        assert verify_first_item(bt_dataset['items1'],Expected_first_item[seed]['items1'])\n\n        assert verify_first_item(bt_dataset['items0'],Expected_first_item[seed]['items0'])\n\n        assert verify_first_item(bt_dataset['items2'],Expected_first_item[seed]['items2'])\n\n    def test_first_dlsobj(self,bt_dataset):\n        \"\"\"Verify that the first item of each dlsobj is as expected\n        \"\"\"\n        seed = bt_dataset['seed']\n        dls = bt_dataset['dls']\n        dls_test = bt_dataset['dls_test']\n        items0 = bt_dataset['items0']\n\n        verify_first_dls(dls,ds_settype='train',expected=Expected_first_dls[seed]['dls'])\n        verify_first_dls(dls_test,ds_settype='train',expected=Expected_first_dls[seed]['dls_test'])\n\n        tune_seed=55\n        dls_tune=tune_set(items0,seed=tune_seed,bs_tune=bs_tune)\n\n        verify_first_dls(dls_tune,ds_settype='valid',expected=Expected_first_dls_tune[(seed,tune_seed)])\n\n\n@pytest.mark.parametrize('bt_dataset',[bt_data_42,bt_data_420])\ndef test1_tune_set(bt_dataset):\n    \"\"\"Check whether the function `tune_set` gives us the expected values\"\"\"\n    \n\n    seed=bt_dataset['seed']\n    tune_seed=bt_dataset['tune_seed']\n    items0 = bt_dataset['items0']\n    \n    if tune_seed==10 and seed==42:\n        expected = {10:0.12255,11:0.153564,12:0.12781,13:0.129523,14:0.13019}\n    \n    elif tune_seed==100 and seed==420:\n        expected={100:0.136104,101:0.120989,102:0.1381390,103:0.1380412,104:0.14285138}\n        \n    for i in range(5):\n        #seed_everything(seed=seed)\n        dls_tune=tune_set(items0,seed=tune_seed+i,bs_tune=20)\n        x_mean=0\n        for x,y in dls_tune.valid:\n            x_mean += x.mean()\n\n        assert abs(x_mean-expected[tune_seed+i])<0.0001\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1z3pyrAB8rpN","outputId":"cd025c63-661c-491b-c55c-5f2ef538225e","execution":{"iopub.status.busy":"2022-10-13T04:42:29.228356Z","iopub.execute_input":"2022-10-13T04:42:29.230678Z","iopub.status.idle":"2022-10-13T04:43:11.812416Z","shell.execute_reply.started":"2022-10-13T04:42:29.230638Z","shell.execute_reply":"2022-10-13T04:43:11.811435Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                   [100%]\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"#A \"reasonable\" composite augmentation: initially copy pasted BT. We run this cell a few times to check it makes sense\n#Also define encoder and model\nfastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\nmodel = create_barlow_twins_model(fastai_encoder, hidden_size=10,projection_size=10)# projection_size=1024)\n#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n#values for these which is tantamount to doing nothing\n#So if we choose resize_scale=(1,1) then the images look the same.\n#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\naug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=False)\n#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\nlearn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n\n#dls.valid.bs = len(dls.valid_ds) #Set the validation dataloader batch size to be the length of the validation dataset\n\nb = dls.one_batch()\nlearn._split(b)\nlearn('before_batch')\naxes = learn.barlow_twins.show(n=2)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":413},"id":"AKbw2pxMag82","outputId":"ad338376-6361-44a8-afcd-4c1cbc00eb5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n\nPipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n"},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x432 with 4 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#Simple linear classifier\nclass LinearClassifier(nn.Module):\n    \n    def __init__(self,zdim):\n            \n        super().__init__()\n        self.fc1 = nn.Linear(zdim,10) #As 10 classes for mnist\n        \n    def forward(self,x):\n        x = cast(self.fc1(x),Tensor) #so we have to use cross entropy loss. cast is because using old version fastai \n        return x\n\ndef turnoffgrad_model(fastai_encoder):\n    for p in fastai_encoder.parameters():\n        p.requires_grad=False\n        \n    return fastai_encoder\n\n#NB: Will give same random 20-tune set (for fixed random seed), only if the cell\n#\"#Get the dataloader and set batch size\" is the same. Perhaps later we can make this cell a function of that one. \n#Functions to train and evaluate head\nfastai_encoder.eval()\nencoder_nograd = turnoffgrad_model(fastai_encoder) \ndef train_head(encoder_nograd,tune_seed=10,bs_tune=20): #The seed choses a different (20) samples for training the head. 2 of each class\n    \"\"\"Train head on a tune_set, chosen through given tune_seed for reproducibility if needed\n    \"\"\"\n                                    # of the tune_seed)\n    \n    dls_tune=tune_set(items0,seed=tune_seed,bs_tune=bs_tune) #different random tune set each time (but as a function of tune_seed)\n \n    N=len(dls_tune.valid)*bs_tune \n    assert N == len(dls_tune.valid_ds) #Check that the tune set (valid) is divided by the batch size\n    assert len(dls_tune.valid_ds) == bs_tune\n\n    zdim=1024 #see above\n    head = LinearClassifier(zdim=zdim)\n    head.to(device)\n    optimizer = torch.optim.Adam(head.parameters())\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(200):\n        #for x,y in dls_tune.valid: #Slows massively on colab but not on kaggle. Weird. \n        x,y=dls_tune.valid.one_batch() #Same every time since dataset only has length=batch size = 20.\n                                        #Will need to fix this for CIFAR10 etc\n\n        loss = criterion(head(encoder_nograd(x)),y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    return head\n\n@torch.no_grad()\ndef eval_head(head):\n    \"\"\"Evaluate the (typically trained) head on on the test set\n    \"\"\"\n    N=len(dls_test.train)*bs_test\n    assert N == len(dls_test.train_ds)\n\n    num_correct=0\n    for x,y in dls_test.train:\n\n        ypred = head(encoder_nograd(x))\n        correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n        num_correct += correct.sum()\n    \n    return num_correct/N\n\ndef eval_encoder(encoder_nograd,tune_seed=10):\n    \"\"\"\"Evaluate the encoder, which means to train and evaluate the head - basically wrap functions train_head\n        and eval_head\n    \"\"\"\n    head=train_head(encoder_nograd,tune_seed=tune_seed)\n    pct_correct = eval_head(head)\n    return pct_correct\n    ","metadata":{"id":"IXTxgA9-Mhih","execution":{"iopub.status.busy":"2022-10-13T08:05:48.591167Z","iopub.execute_input":"2022-10-13T08:05:48.591534Z","iopub.status.idle":"2022-10-13T08:05:48.612258Z","shell.execute_reply.started":"2022-10-13T08:05:48.591502Z","shell.execute_reply":"2022-10-13T08:05:48.611327Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"%%time\nassert tune_seed==100\nassert seed == 420\nperformance_dict={}\nfor num in range(5):\n    \n    pct_correct = eval_encoder(encoder_nograd,tune_seed=tune_seed+num)\n    performance_dict[f'seed_{num}'] = pct_correct \n\nprint(torch.mean(tensor(list(performance_dict.values()))))\nperformance_dict","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKgPajGBMpSn","outputId":"2d8a7c13-2d7e-49c8-f5bc-a5914fa58983","execution":{"iopub.status.busy":"2022-10-13T08:05:53.518952Z","iopub.execute_input":"2022-10-13T08:05:53.519533Z","iopub.status.idle":"2022-10-13T08:11:05.725947Z","shell.execute_reply.started":"2022-10-13T08:05:53.519495Z","shell.execute_reply":"2022-10-13T08:11:05.724799Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"tensor(0.8390)\nCPU times: user 5min, sys: 10.1 s, total: 5min 10s\nWall time: 5min 12s\n","output_type":"stream"},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"{'seed_0': TensorCategory(0.8005),\n 'seed_1': TensorCategory(0.8192),\n 'seed_2': TensorCategory(0.8788),\n 'seed_3': TensorCategory(0.8619),\n 'seed_4': TensorCategory(0.8347)}"},"metadata":{}}]},{"cell_type":"code","source":"#test: 0.1361,0.1210\n#BT baseline, new random seeds, 0.7693\n\nprint(torch.mean(tensor(list(performance_dict.values()))))\nperformance_dict","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NpcqDLMJWpkB","outputId":"f8f4b517-a880-48a9-908c-3c16d3d82137","execution":{"iopub.status.busy":"2022-10-13T05:56:08.398637Z","iopub.execute_input":"2022-10-13T05:56:08.399161Z","iopub.status.idle":"2022-10-13T05:56:08.419394Z","shell.execute_reply.started":"2022-10-13T05:56:08.399118Z","shell.execute_reply":"2022-10-13T05:56:08.418364Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"tensor(0.8227)\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"{'seed_0': TensorCategory(0.8151),\n 'seed_1': TensorCategory(0.7934),\n 'seed_2': TensorCategory(0.8422),\n 'seed_3': TensorCategory(0.8464),\n 'seed_4': TensorCategory(0.8165)}"},"metadata":{}}]},{"cell_type":"code","source":"\n\nnew_420_100={'seed_0': TensorCategory(0.7952),\n 'seed_1': TensorCategory(0.7952),\n 'seed_2': TensorCategory(0.8647),\n 'seed_3': TensorCategory(0.8407),\n 'seed_4': TensorCategory(0.8118)}\n\nprint(torch.mean(tensor(list(new_420_100.values()))))#tensor(0.8215)\n\n\nnew_420_100_reg = {'seed_0': TensorCategory(0.8005),\n 'seed_1': TensorCategory(0.8192),\n 'seed_2': TensorCategory(0.8788),\n 'seed_3': TensorCategory(0.8619),\n 'seed_4': TensorCategory(0.8347)} #tensor(0.8227)\nprint(torch.mean(tensor(list(new_420_100_reg.values())))) #tensor(0.8390)\n\n","metadata":{"id":"G1gszrPuMuzW","execution":{"iopub.status.busy":"2022-10-13T09:13:25.524752Z","iopub.execute_input":"2022-10-13T09:13:25.525147Z","iopub.status.idle":"2022-10-13T09:13:25.537991Z","shell.execute_reply.started":"2022-10-13T09:13:25.525107Z","shell.execute_reply":"2022-10-13T09:13:25.536837Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"tensor(0.8215)\ntensor(0.8390)\n","output_type":"stream"}]},{"cell_type":"code","source":"#200 learn epochs\nBT_42_10_run1={'seed_0': TensorCategory(0.7667),\n 'seed_1': TensorCategory(0.6843),\n 'seed_2': TensorCategory(0.8468),\n 'seed_3': TensorCategory(0.7687),\n 'seed_4': TensorCategory(0.7288)}\nprint(torch.mean(tensor(list(BT_42_10_run1.values()))))#tensor(0.7591)\n\nMBT_42_10_run1 = {'seed_0': TensorCategory(0.8238),\n 'seed_1': TensorCategory(0.7834),\n 'seed_2': TensorCategory(0.8999),\n 'seed_3': TensorCategory(0.8601),\n 'seed_4': TensorCategory(0.8221)}\n\nprint(torch.mean(tensor(list(MBT_42_10_run1.values()))))#tensor(0.8379)\n\nBT_420_100_run1 = {'seed_0': TensorCategory(0.7532),\n 'seed_1': TensorCategory(0.7501),\n 'seed_2': TensorCategory(0.7808),\n 'seed_3': TensorCategory(0.7804),\n 'seed_4': TensorCategory(0.7461)}\n\nprint(torch.mean(tensor(list(BT_420_100_run1.values()))))#tensor(0.7621)\n\nMBT_420_100_run1={'seed_0': TensorCategory(0.8016),\n 'seed_1': TensorCategory(0.7849),\n 'seed_2': TensorCategory(0.8416),\n 'seed_3': TensorCategory(0.8364),\n 'seed_4': TensorCategory(0.7986)}\n\nprint(torch.mean(tensor(list(MBT_420_100_run1.values())))) #tensor(0.8126)\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3KMNc94mz5CJ","outputId":"8b0b52ab-d817-4c04-b99c-8374c0d1e4a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor(0.7591)\n\ntensor(0.8379)\n\ntensor(0.7621)\n\ntensor(0.8126)\n"}]},{"cell_type":"code","source":"#100 learn_epochs, 420 and 100 random seeds used instead of 42 and 10.\nBT_1={'seed_0': TensorCategory(0.7614),\n 'seed_1': TensorCategory(0.7328),\n 'seed_2': TensorCategory(0.7640),\n 'seed_3': TensorCategory(0.8039),\n 'seed_4': TensorCategory(0.7309)}\nprint(torch.mean(tensor(list(BT.values())))) #tensor(0.7586)\n\nBT_2={'seed_0': TensorCategory(0.7413),\n 'seed_1': TensorCategory(0.7645),\n 'seed_2': TensorCategory(0.7981),\n 'seed_3': TensorCategory(0.8010),\n 'seed_4': TensorCategory(0.7355)}\nprint(torch.mean(tensor(list(BT_2.values())))) #tensor(0.7681)\n\nMBT_1 = {'seed_0': TensorCategory(0.7721),\n 'seed_1': TensorCategory(0.7693),\n 'seed_2': TensorCategory(0.8398),\n 'seed_3': TensorCategory(0.8129),\n 'seed_4': TensorCategory(0.7908)}\nprint(torch.mean(tensor(list(MBT_1.values())))) #tensor(0.7970)\n\nMBT_2 = {'seed_0': TensorCategory(0.8126),\n 'seed_1': TensorCategory(0.7781),\n 'seed_2': TensorCategory(0.8234),\n 'seed_3': TensorCategory(0.8280),\n 'seed_4': TensorCategory(0.8084)}\nprint(torch.mean(tensor(list(MBT_2.values())))) #tensor(0.8101)\n\n\n","metadata":{"id":"yUHZSinCsrt4","outputId":"9c8ed2a0-eb46-423f-a0a0-c6dbeee1d333","colab":{"base_uri":"https://localhost:8080/","height":240}},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-0f6bbb4458fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m  \u001b[0;34m'seed_3'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorCategory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8039\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m  'seed_4': TensorCategory(0.7309)}\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#tensor(0.7586)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m BT_2={'seed_0': TensorCategory(0.7413),\n","\u001b[0;31mNameError\u001b[0m: name 'BT' is not defined"]}]},{"cell_type":"markdown","source":"Please see commit  e849943... 4/10/22 if needed. We have edited the base functions in that file to try and make them nicer, but we need to make sure we can reproduce results (i.e. the changes make things nicer but don't actually change anything).\n\n\n\n","metadata":{"id":"zjR-EnBubM6y"}},{"cell_type":"markdown","source":"With: fc1,fc2,fc3,fc4 distinct. Indexmod=2, K=2 With Max_corr = (sigmoid,relu); \n$a\\sim b$ = 0.2 x N(0,1): 0.8576,0.8364,0.8393\n\n\n","metadata":{"id":"T4bY6DPjb8MY"}},{"cell_type":"markdown","source":"Below applies to prior implementation, we leave it here for now.\n","metadata":{"id":"KjPF34iucYWK"}},{"cell_type":"markdown","source":"All of the below have sin and cos with constant coefficients. If we take `best so far` and give it random coefficients a and b with std=0.2 then get:\n\nWith fc1,fc2,fc3,fc4 distinct. Indexmod=2, K=2 With Max_corr = (sigmoid,relu);a~b = 0.2 x N(0,1) **0.8390, 0.8553** Conclusion: We need to search over the a and b parameters (coefficients of sinusoids) when we do our big search. Or rather search over std the hps controlling how we sample a and b. ","metadata":{"id":"-Rmtuu4nxc13"}},{"cell_type":"markdown","source":"Results (continuing from prior commit):\n\n\nNote these are with 200 learn_epochs etc. Same random seed. See above for other details (and we mention when recording the results below that we varied)\nBT = 0.7581\n\n(These are with fc1,fc2,fc3,fc4 distinct). Indexmod=2, K=2 \n**With Max_corr = (sigmoid,relu): 0.8493,0.8332,0.8392. Best so far.**\nWith Max_corr = (sigmoid,sigmoid): 0.3080,0.3219.   \nWith Max_corr = (relu,relu): 0.8132,0.8142,0.8093.   \n\n(These are with fc1=fc3, fc2=fc4. i.e. just one NN applied)  \nWith Max_corr = (sigmoid,relu): 0.8359,0.8258,0.8303\n\nAbove are all with indexmod=2. Now we try removing the indexmod condition.\nThen get:\nIndexmod=0\nWith Max_corr = (sigmoid,relu): 0.8264,0.8253 \n\nTry indexmod=4\nWith Max_corr = (sigmoid,relu):0.8174\n\n\n\n\n\n","metadata":{"id":"5SYRjUytI8Fw"}},{"cell_type":"markdown","source":"Results on different MBT runs (see above for implementation): tensor(0.8493) (trying to reproduce now) (just changed y=self.sigmoid(self.fc3(y))\nfrom relu in MaxCorr). Performance went to tensor(0.3080)!!! Crazy. Let's change y back to relu and see what happens. result: tensor(0.8332)!! Wow. Similar\nto before (i.e. evidence in favour of reproducibility). All we changed was sigmoid to relu!\n\nTo summarise: Max_Corr had (sigmoid,relu) and got great results (on two diff MBT runs 0.8493 and 0.8332. When we changed relu to sigmoid, got terrible results (0.3080). (As an aside the loss jumped around a lot).","metadata":{"id":"snRrKfwCH6XD"}},{"cell_type":"code","source":"#250 learn_epochs. To beat: (K=10,indexmod=4,std=0.1,convex=(0.2,0.8))\ntem={'seed_0': TensorCategory(0.8364),\n 'seed_1': TensorCategory(0.7424),\n 'seed_2': TensorCategory(0.8947),\n 'seed_3': TensorCategory(0.8392),\n 'seed_4': TensorCategory(0.8133)}\nprint(torch.mean(tensor(list(tem.values())))) #tensor(0.8252)\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPEDQE-rcKjL","outputId":"8e127c85-873f-4a36-d76a-66a57c566f74"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"tensor(0.8252)\n"}]},{"cell_type":"code","source":"","metadata":{"id":"dZPO88U4XMgb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYI6BiCTXCmt","outputId":"c99dc95d-0a71-4fc3-d791-16cee98bfa8d"},"execution_count":null,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":["tensor(0.8487)"]},"metadata":{}}]},{"cell_type":"code","source":"performance_dict","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"id":"hw0VjYxRx1va","outputId":"659f5266-600d-4b32-a834-a84fff7d18b3"},"execution_count":null,"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-c8c02caa2cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperformance_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'performance_dict' is not defined"]}]},{"cell_type":"markdown","source":"","metadata":{"id":"COooHESjoNGb"}}]}