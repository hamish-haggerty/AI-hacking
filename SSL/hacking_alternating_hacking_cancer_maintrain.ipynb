{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamish-haggerty/AI-hacking/blob/master/SSL/hacking_alternating_hacking_cancer_maintrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqZPF94637Fk"
      },
      "source": [
        "# cancer_maintrain\n",
        "\n",
        "> Please add a description. Don't forgot to edit the below cell!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gFWev-_Q37Fm"
      },
      "outputs": [],
      "source": [
        "#| default_exp cancer_maintrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cat536_37Fn"
      },
      "source": [
        "Setup: Surely there is a way to get rid of having to put this cell everywhere. hmmm.\n",
        "\n",
        "Or we can just copy paste / delete this in and out when needed. Either way, getting close to a decent workable workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fO8vhi6b37Fn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c7c755-325f-4129-f844-d19b30919901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#| hide\n",
        "\n",
        "def colab_is_true():\n",
        "\n",
        "    try: \n",
        "        from google.colab import drive\n",
        "\n",
        "        return True \n",
        "    except ModuleNotFoundError:\n",
        "        return False\n",
        "\n",
        "def setup_colab():\n",
        "    import os\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive',force_remount=True)\n",
        "    #os.system('unzip -q \"/content/drive/My Drive/archive (1).zip\"')\n",
        "    os.system('git clone https://github.com/hamish-haggerty/cancer-proj.git')\n",
        "    os.chdir('cancer-proj')\n",
        "    os.system('unzip -q \"/content/drive/My Drive/archive (1).zip\"') #does this work?\n",
        "    os.system('pip install -e .')\n",
        "    os.system('pip install -qU nbdev')\n",
        "    os.system('nbdev_install_quarto')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    on_colab = colab_is_true()\n",
        "    if on_colab:\n",
        "        setup_colab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VNjMrD_W37Fo"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "from nbdev.showdoc import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1RZVlbHF37Fo"
      },
      "outputs": [],
      "source": [
        "#| export\n",
        "from fastai.vision.all import *\n",
        "#| export\n",
        "from base_rbt.all import *\n",
        "from cancer_proj.cancer_dataloading import *\n",
        "from cancer_proj.cancer_metrics import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fnames_dict(train_dir,test_dir,class_names):\n",
        "    \"get dictionary of fnames\"\n",
        "\n",
        "        #files names\n",
        "    fnames = get_image_files(train_dir)\n",
        "\n",
        "    #Extract training set\n",
        "    max_num =100 #maximum number of samples in each class\n",
        "    count_dict = {i:0 for i in class_names}\n",
        "    fnames_train = []\n",
        "    for i in fnames:\n",
        "        #st=extract_text(i.as_posix())\n",
        "        st=label_func(i)\n",
        "        \n",
        "        if count_dict[st]<max_num: #no more than 100 samples per category\n",
        "            fnames_train.append(i)\n",
        "            count_dict[st]+=1\n",
        "                    \n",
        "    #We further partition fnames_train into a tune-valiation set\n",
        "    count_dict2 = {i:0 for i in class_names}\n",
        "    fnames_tune = []\n",
        "    for i in fnames_train:\n",
        "        st = label_func(i)\n",
        "        if count_dict2[st] < 0.8*count_dict[st]:\n",
        "            fnames_tune.append(i)\n",
        "            count_dict2[st]+=1\n",
        "            \n",
        "\n",
        "\n",
        "    fnames_valid = get_difference(fnames_train,fnames_tune)\n",
        "\n",
        "    fnames_test = get_difference(fnames,fnames_train) + get_image_files(test_dir)\n",
        "\n",
        "    fnames_train = fnames_tune\n",
        "\n",
        "    return {'fnames':fnames,'fnames_train':fnames_train,'fnames_tune':fnames_tune,\n",
        "            'fnames_valid':fnames_valid,\n",
        "            'fnames_test':fnames_test\n",
        "            }"
      ],
      "metadata": {
        "id": "oG0ucDMpxaYP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOarq5rB37Fp"
      },
      "source": [
        "For now just get the data however it works. Will fix this later. But want to get `main_train` working for now"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "def get_fnames_dls_dict(train_dir,test_dir,\n",
        "                        device,bs_val,bs=256,bs_tune=256,size=128,n_in=3,\n",
        "                        ):\n",
        "\n",
        "    \"Wrapper that returns a dictionary with the fnames, dls etc\"\n",
        "\n",
        "    #do stuff\n",
        "\n",
        "    class_names = get_file_lists(train_dir)['class_names']\n",
        "    \n",
        "    fnames_dict = get_fnames_dict(train_dir,test_dir,class_names)\n",
        "\n",
        "    data_dict = get_data_dict(fnames_dict,train_dir,test_dir, #basic stuff needed\n",
        "                  device,bs_val,bs=bs,bs_tune=bs_tune,size=size,n_in=n_in #hyperparameters\n",
        "                 )\n",
        "\n",
        "    d = {**fnames_dict,**data_dict}\n",
        "    \n",
        "    return d\n",
        "\n"
      ],
      "metadata": {
        "id": "b13SmrX5L0C8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN4Js6uo37Fq"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pp3x3wbL37Fq"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "#Since we have cloned repository and cd'd into it (and the data itself is not stored in the\n",
        "#repo) we need cd out of it, get the data, then cd back into the repo `cancer-proj`.\n",
        "#This is a bit annoying, can maybe remove this later\n",
        "if on_colab:\n",
        "    #os.chdir('..') #assumes we are currently in cancer-proj directory\n",
        "    train_dir = colab_train_dir\n",
        "    test_dir = colab_test_dir\n",
        "else:\n",
        "    train_dir = local_train_dir\n",
        "    test_dir = local_test_dir\n",
        "    \n",
        "\n",
        "\n",
        "#define general hps\n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#bs=256\n",
        "#bs=698\n",
        "bs=256\n",
        "bs_tune=256\n",
        "size=128\n",
        "bs_val=174\n",
        "\n",
        "#get the data dictionary\n",
        "data_dict = get_fnames_dls_dict(train_dir=train_dir,test_dir=test_dir,\n",
        "                    device=device,bs_val=bs_val,bs=bs,bs_tune=bs_tune,size=size,n_in=3)\n",
        "\n",
        "#get the dataloaders\n",
        "dls_train,dls_tune,dls_valid = data_dict['dls_train'],data_dict['dls_tune'],data_dict['dls_valid']\n",
        "x,y = data_dict['x'],data_dict['y']\n",
        "xval,yval = data_dict['xval'],data_dict['yval']\n",
        "xtune,ytune = data_dict['xtune'],data_dict['ytune']\n",
        "vocab = data_dict['vocab']\n",
        "\n",
        "#If we want to write some tests (make sure the data is same every time etc):\n",
        "fnames,fnames_train,fnames_tune,fnames_valid,fnames_test = data_dict['fnames'],data_dict['fnames_train'],data_dict['fnames_tune'],data_dict['fnames_valid'],data_dict['fnames_test']\n",
        "\n",
        "# if on_colab:\n",
        "#     os.chdir('cancer-proj')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PpIwqfu37Fr"
      },
      "source": [
        "## Load aug pipelines here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ntc4hMMj37Fr"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "\n",
        "aug_dict = create_aug_pipelines(size=size,device=device,Augs=BYOL_Augs,TUNE_Augs=TUNE_Augs,Val_Augs=Val_Augs)\n",
        "aug_pipelines = aug_dict['aug_pipelines']\n",
        "aug_pipelines_tune = aug_dict['aug_pipelines_tune']\n",
        "aug_pipelines_test = aug_dict['aug_pipelines_test'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PP7Sp4P837Fr"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "#show_bt_batch(dls=dls_train,aug=aug_pipelines,n_in=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "foWFxkv_37Fr"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "#show_linear_batch(dls=dls_tune,n_in=3,aug=aug_pipelines_tune,n=2,print_augs=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xY0v8z2rlZ1",
        "outputId": "3a0d3d61-0a0f-4cf5-c146-7a91269a6300"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@patch\n",
        "@delegates(Learner.fit_one_cycle)\n",
        "def linear_fine_tune(self:Learner, epochs, base_lr=2e-3, freeze_epochs=1, lr_mult=100,\n",
        "              pct_start=0.3, div=5.0, **kwargs):\n",
        "    \"Fine tune with `freeze` for `freeze_epochs` then with `unfreeze` from `epochs` using discriminative LR\"\n",
        "    self.freeze()\n",
        "\n",
        "    # for p in self.model[0].parameters():\n",
        "    #     print(p.requires_grad)\n",
        "\n",
        "    # print('should be true and false')\n",
        "    \n",
        "    self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs)\n",
        "    base_lr /= 2\n",
        "\n",
        "    #self.fit(freeze_epochs)\n",
        "\n",
        "    self.unfreeze()\n",
        "\n",
        "    # for p in self.model[0].parameters():\n",
        "    #     print(p.requires_grad)\n",
        "\n",
        "\n",
        "    # print('should be all true..')\n",
        "\n",
        "    self.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div, **kwargs)\n",
        "    #self.fit(epochs)"
      ],
      "metadata": {
        "id": "iuAFrHMYCVGE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle??"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSGhFDmOWiMJ",
        "outputId": "0a0491cb-30a2-4864-9ae3-fd72a4fd4ea1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object `learn.fit_one_cycle` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Test:\n",
        "\n",
        "# bt_model,encoder = create_model(which_model='bt_pretrain',ps=8192,device=device)\n",
        "# #model = sequential(*encoder,nn.Linear(2048,9))\n",
        "\n",
        "# #model = LinearModel(encoder=encoder,indim=2048,outdim=9)\n",
        "\n",
        "# model = sequential(encoder,nn.Linear(2048,9))\n",
        "\n",
        "\n",
        "# # s=0\n",
        "# # #for p in model.encoder.parameters():\n",
        "# # for p in model[-5].parameters():\n",
        "# #     s+=p.sum()\n",
        "\n",
        "# # print(s)\n",
        "\n",
        "# learn = Learner(dls_tune,model,splitter=default_split,cbs = [LinearBt(aug_pipelines=aug_pipelines_tune,n_in=3)],wd=0.0)\n",
        "# #learn.fine_tune(1)\n",
        "# learn.linear_fine_tune(10,freeze_epochs=2,base_lr=0.004)\n",
        "\n",
        "# # s2=0\n",
        "# # #for p in model.encoder.parameters():\n",
        "# # for p in model[-5].parameters():\n",
        "# #     s2+=p.sum()\n",
        "\n",
        "# # print(s2)\n",
        "# # print(s==s2)\n"
      ],
      "metadata": {
        "id": "tt0J1o0wpJws"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EcjObcZ37Fs"
      },
      "source": [
        "## TODO: Can probably put this in `dataloading`. No need to clog this notebook up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KAW1Mwwa37Fs"
      },
      "outputs": [],
      "source": [
        "#| hide\n",
        "\n",
        "@patch\n",
        "def lf(self:BarlowTwins, pred,*yb): return lf_bt(pred,I=self.I,lmb=self.lmb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXoWi7IJ37Fs"
      },
      "source": [
        "## main training api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#show_bt_batch(dls=dls_train,aug=new_aug_pipelines,n_in=3)"
      ],
      "metadata": {
        "id": "7wBerRy6FIkc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_ensemble(yval,scores1,scores2):\n",
        "\n",
        "    N=yval.shape[0]\n",
        "\n",
        "    scores = 0.5*scores1 + 0.5*scores2\n",
        "\n",
        "    ypred = cast(torch.argmax(scores, dim=1),TensorCategory)\n",
        "\n",
        "    correct = (ypred == yval)#.type(torch.FloatTensor)\n",
        "\n",
        "    #correct = (torch.argmax(ypred,dim=1) == yval).type(torch.FloatTensor)\n",
        "    num_correct = correct.sum()\n",
        "    accuracy = num_correct/N\n",
        "    \n",
        "    return ypred,accuracy.item()"
      ],
      "metadata": {
        "id": "LmtCUiv3DBYk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def save_dict_to_gdrive(d,filename):\n",
        "    filename = '/content/drive/My Drive/' + filename + '.pkl'\n",
        "    with open(filename, 'wb') as handle:\n",
        "        pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "\n",
        "def load_dict_from_gdrive(filename):\n",
        "    filepath = '/content/drive/My Drive/' + filename + '.pkl'\n",
        "    with open(filepath, 'rb') as handle:\n",
        "        return pickle.load(handle)\n"
      ],
      "metadata": {
        "id": "Goex9_hrSabi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bt_model,encoder = create_model(which_model='bt_pretrain',ps=8192,device=device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "bfac6a54816e44dc81333f94ab6b60b7",
            "fc748fc8ed21413482b3e87c5e04bd56",
            "97996d9e8850495db6fd9770cc3852a9",
            "3e7568e4d5de4cdab62668cd7c7d075e",
            "90bb7c7c9ad84480b5f51479ac97f917",
            "5d6b454fc1904eff8e610152c743c568",
            "64ea968be13248a58ab240b47d7b1b25",
            "e5f5d992b3244e08bf247a5cf02056a5",
            "65130a6d8356467ab36c449cc5d5cc7c",
            "5484e81927c34ba48b2328e8e6c1ca56",
            "8befcedd0943481783d03a309457d7bc"
          ]
        },
        "id": "SF6ZU2ubZ0RW",
        "outputId": "5f21eab0-7ff9-4987-ddcc-62766c5101b6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/barlowtwins/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/barlowtwins/ep1000_bs2048_lrw0.2_lrb0.0048_lambd0.0051/resnet50.pth\" to /root/.cache/torch/hub/checkpoints/resnet50.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/90.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfac6a54816e44dc81333f94ab6b60b7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_func(model):\n",
        "\n",
        "    return L(list(model.encoder.parameters()),list(model.L.parameters()))\n",
        "\n",
        "\n",
        "def split_encoder_projector(model):\n",
        "\n",
        "    return L(list(model.encoder.parameters()),list(model.projector.parameters()))"
      ],
      "metadata": {
        "id": "01T6t0c5JS6-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@patch\n",
        "@delegates(Learner.fit_one_cycle)\n",
        "def encoder_fine_tune(self:Learner, epochs, base_lr=2e-3, freeze_epochs=1, lr_mult=100,\n",
        "              pct_start=0.3, div=5.0, **kwargs):\n",
        "    \"Fine tune with `freeze` for `freeze_epochs` then with `unfreeze` from `epochs` using discriminative LR\"\n",
        "    self.freeze()\n",
        "\n",
        "    self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs)\n",
        "    base_lr /= 2\n",
        "    self.unfreeze()\n",
        "\n",
        "    self.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div, **kwargs)\n"
      ],
      "metadata": {
        "id": "zb7QOqHuLSPp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_lr=2e-3\n",
        "slice(base_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oBgbtq92GQf",
        "outputId": "48b47e36-c93b-4b98-984c-16a146e1a722"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "slice(None, 0.002, None)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "# bt_model,encoder = create_model(which_model='bt_pretrain',ps=8192,device=device)\n",
        "# learn = Learner(dls_train,bt_model,splitter=split_encoder_projector, cbs=[BarlowTwins(aug_pipelines,n_in=3,lmb=1/8192,print_augs=False)])\n",
        "# learn.encoder_fine_tune(1)"
      ],
      "metadata": {
        "id": "cXRnvFaMK2pk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main purpose is to see if we can get the alternating scheme to work..."
      ],
      "metadata": {
        "id": "SqcUQbV3A1Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "0arEavfvZnVI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LM(nn.Module):\n",
        "    def __init__(self,encoder):\n",
        "        super().__init__()\n",
        "        self.encoder=encoder\n",
        "        self.head=nn.Linear(2048,9)\n",
        "        \n",
        "        self.encoder.cuda()\n",
        "        self.head.cuda()\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.head(self.encoder(x))"
      ],
      "metadata": {
        "id": "niDQX0o3fbO5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_splitter(m):\n",
        "    return L(sequential(*m.encoder),m.head).map(params)\n",
        "\n",
        "# split = my_splitter(lm)\n",
        "# print(len(split))"
      ],
      "metadata": {
        "id": "kvPYzF3TtSQn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_splitter_bt(m):\n",
        "    return L(sequential(*m.encoder),m.projector).map(params)\n",
        "    "
      ],
      "metadata": {
        "id": "Zmx83D_NFL_6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,encoder = create_model(which_model='bt_pretrain',ps=8192,device=device)\n",
        "model = LM(encoder) \n",
        "#model = sequential(encoder,nn.Linear(2048,9))\n",
        "learn = Learner(dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=aug_pipelines_tune,n_in=3)],wd=0.0)\n",
        "#learn = Learner(dls_tune,model,cbs = [LinearBt(aug_pipelines=aug_pipelines_tune,n_in=3)],wd=0.0)\n",
        "#learn.freeze()\n",
        "#learn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIcvDTnDvEYa",
        "outputId": "cc0c9cbf-ee6c-43c0-8318-7ab56444cb9d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@patch\n",
        "@delegates(Learner.fit_one_cycle)\n",
        "def fine_tune(self:Learner, epochs, base_lr=2e-3, freeze_epochs=1, lr_mult=100,\n",
        "              pct_start=0.3, div=5.0, **kwargs):\n",
        "    \"Fine tune with `Learner.freeze` for `freeze_epochs`, then with `Learner.unfreeze` for `epochs`, using discriminative LR.\"\n",
        "    self.freeze()\n",
        "\n",
        "    # print('inside fine_tune')\n",
        "    # print(f'slice(base_lr) is: {slice(base_lr)}')\n",
        "    # print('about to call fit_one_cycle')\n",
        "\n",
        "    self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs)\n",
        "    base_lr /= 2\n",
        "    self.unfreeze()\n",
        "    self.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div, **kwargs)\n"
      ],
      "metadata": {
        "id": "M5dlK2B8Ecw-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@patch\n",
        "def fit_one_cycle(self:Learner, n_epoch, lr_max=None, div=25., div_final=1e5, pct_start=0.25, wd=None,\n",
        "                  moms=None, cbs=None, reset_opt=False, start_epoch=0):\n",
        "    \"Fit `self.model` for `n_epoch` using the 1cycle policy.\"\n",
        "\n",
        "    # print('inside fit_one_cycle')\n",
        "    # print(lr_max)\n",
        "    # assert False\n",
        "    if self.opt is None: self.create_opt()\n",
        "    self.opt.set_hyper('lr', self.lr if lr_max is None else lr_max)\n",
        "    lr_max = np.array([h['lr'] for h in self.opt.hypers])\n",
        "    scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n",
        "              'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n",
        "    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n"
      ],
      "metadata": {
        "id": "1JhKjg5gKe4g"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(learn.opt.set_hyper)"
      ],
      "metadata": {
        "id": "7D7Zpl48QD8u"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,encoder = create_model(which_model='supervised_pretrain',ps=8192,device=device)\n",
        "model = LM(encoder)\n",
        "\n",
        "#model = sequential(self.encoder,model)  \n",
        "\n",
        "\n",
        "#learn = Learner(self.dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "learn = Learner(dls_tune,model,cbs = [LinearBt(aug_pipelines=aug_pipelines_tune,n_in=3)],wd=0.0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "8216f4e521b2444a9c5eba3551c40221",
            "124e0045f1854808a0392fc1206e1655",
            "6dc815cb9d334e53b353307cd94b0780",
            "90842c1f95194713bb9066770881418b",
            "09e05d72749b41a783e063839f4abc59",
            "649a23d4fb78460fb26fb2b2678101b2",
            "4bc8443336d247d4b90c8f9b87e8d50b",
            "5272d0df080241008573929d0c6c940b",
            "fbb98effaa734eefb5bdfdf6a1366864",
            "57c9a292245d42148bd490f300d9b15a",
            "ab82bcdc7536451abc1a6a5c9d4c1247"
          ]
        },
        "id": "FJygYzLrPR6x",
        "outputId": "8a46a2cd-cecc-4c60-f211-2c738b679c43"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8216f4e521b2444a9c5eba3551c40221"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.create_opt()"
      ],
      "metadata": {
        "id": "TzHj1uAiPrx5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.opt.set_hyper??"
      ],
      "metadata": {
        "id": "hxg1TKfBQUbG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_max = 2e-3\n",
        "learn.create_opt()\n",
        "learn.opt.set_hyper('lr', learn.lr if lr_max is None else lr_max)"
      ],
      "metadata": {
        "id": "LHVNSSSOOkGf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_splitter??"
      ],
      "metadata": {
        "id": "4v0iICW6Syc4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Old splitter\n",
        "def my_splitter(m):\n",
        "    return L(sequential(*m.encoder),m.head).map(params)\n",
        "\n",
        "\n",
        "\n",
        "#new splitter\n",
        "# def my_splitter(m):\n",
        "#     return L(m.head,sequential(*m.encoder)).map(params)"
      ],
      "metadata": {
        "id": "ebF40oBtS1LD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=aug_pipelines_tune,n_in=3)],wd=0.0)\n",
        "learn.create_opt()\n",
        "\n",
        "learn.opt.param_groups[1]\n",
        "\n",
        "learn.freeze()\n",
        "learn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ucHXV5EWuHlY",
        "outputId": "6025ab64-2da6-4a20-edd8-76f68876e1b3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LM (Input shape: 256 x 3 x 128 x 128)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     256 x 64 x 64 x 64  \n",
              "Conv2d                                    9408       False     \n",
              "BatchNorm2d                               128        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "MaxPool2d                                                      \n",
              "Conv2d                                    4096       False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 64 x 32 x 32  \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               128        True      \n",
              "Conv2d                                    36864      False     \n",
              "BatchNorm2d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 32 x 32 \n",
              "Conv2d                                    16384      False     \n",
              "BatchNorm2d                               512        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 32 x 32 \n",
              "Conv2d                                    32768      False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 128 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               256        True      \n",
              "Conv2d                                    147456     False     \n",
              "BatchNorm2d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 16 x 16 \n",
              "Conv2d                                    65536      False     \n",
              "BatchNorm2d                               1024       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 16 x 16 \n",
              "Conv2d                                    131072     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 256 x 8 x 8   \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               512        True      \n",
              "Conv2d                                    589824     False     \n",
              "BatchNorm2d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 1024 x 8 x 8  \n",
              "Conv2d                                    262144     False     \n",
              "BatchNorm2d                               2048       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 8 x 8   \n",
              "Conv2d                                    524288     False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "Conv2d                                    2097152    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 512 x 4 x 4   \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "Conv2d                                    2359296    False     \n",
              "BatchNorm2d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 4 x 4  \n",
              "Conv2d                                    1048576    False     \n",
              "BatchNorm2d                               4096       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048 x 1 x 1  \n",
              "AdaptiveAvgPool2d                                              \n",
              "____________________________________________________________________________\n",
              "                     256 x 2048          \n",
              "Flatten                                                        \n",
              "____________________________________________________________________________\n",
              "                     256 x 9             \n",
              "Linear                                    18441      True      \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 23,526,473\n",
              "Total trainable params: 71,561\n",
              "Total non-trainable params: 23,454,912\n",
              "\n",
              "Optimizer used: <function Adam at 0x7fdf1d7e50d0>\n",
              "Loss function: <bound method LinearBt.lf of LinearBt>\n",
              "\n",
              "Model frozen up to parameter group #1\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - CastToTensor\n",
              "  - LinearBt\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKQwA4Tl37Ft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a53f4648-c713-4c05-8b7d-836e69b6dd07"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.218075</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.167498</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.108407</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.044920</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.974721</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.888176</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.790977</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.682189</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.567289</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.449746</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.338323</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.236866</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.140640</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.055510</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.981307</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.918379</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.861257</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.809195</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.768534</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.729164</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.696805</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.664233</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.633876</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.605649</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.578011</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.551168</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.525631</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.503068</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.481082</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.460950</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.440795</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.423172</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.407170</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.391028</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.376470</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.363022</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.349344</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.336553</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.324404</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.312871</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.302162</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.292081</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.283002</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.273931</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.265125</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.256311</td>\n",
              "      <td>None</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.248672</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.241008</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.233965</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.226716</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.220210</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         actinic keratosis       0.64      0.80      0.71        20\n",
            "      basal cell carcinoma       0.88      0.75      0.81        20\n",
            "            dermatofibroma       0.82      0.95      0.88        19\n",
            "                  melanoma       0.32      0.30      0.31        20\n",
            "                     nevus       0.85      0.55      0.67        20\n",
            "pigmented benign keratosis       0.76      0.65      0.70        20\n",
            "      seborrheic keratosis       0.41      0.60      0.49        15\n",
            "   squamous cell carcinoma       0.72      0.65      0.68        20\n",
            "           vascular lesion       0.95      1.00      0.98        20\n",
            "\n",
            "                  accuracy                           0.70       174\n",
            "                 macro avg       0.71      0.69      0.69       174\n",
            "              weighted avg       0.71      0.70      0.70       174\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.215836</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='1' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      2.00% [1/50 00:06&lt;05:01]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.155593</td>\n",
              "      <td>None</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/2 00:00&lt;?]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#| export\n",
        "\n",
        "class main_train:\n",
        "    \"\"\"Instantiate and (optionally) train the encoder. Then fine-tune the supervised model. \n",
        "    Outputs metrics on validation data\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 dls_train, #used for training BT (if pretrain=True)\n",
        "                 dls_tune , #used for tuning\n",
        "                 dls_valid, #used to compute metrics / evaluate results. \n",
        "                 xval, #currently `predict_model` below assumes this is entire validation / test data\n",
        "                 yval,\n",
        "                 aug_pipelines, #the aug pipeline for self-supervised learning\n",
        "                 aug_pipelines_tune, #the aug pipeline for supervised learning\n",
        "                 aug_pipelines_test, #test (or valid) time augmentations \n",
        "                 initial_weights, #Which initial weights to use\n",
        "                 pretrain, #Whether to fit BT\n",
        "                 fit_policy, #policy for fitting BT\n",
        "                 tune_fit_policy,\n",
        "                 num_epochs, #number of BT fit epochs\n",
        "                 numfit, #number of tune_fit epochs\n",
        "                 ps=8192, #projection size\n",
        "                 n_in=3, #color channels\n",
        "                 indim=2048, #dimension output of encoder (2048 for resnet50)\n",
        "                 outdim=9, #number of classes\n",
        "                 print_report=False, #F1 metrics etc\n",
        "                 print_plot=False, #ROC curve\n",
        "                 ):\n",
        "                 store_attr()\n",
        "                 self.vocab = self.dls_valid.vocab\n",
        "\n",
        "\n",
        "                 #if self.model_type == 'res_proj': test_eq(self.fit_policy,'resnet_fine_tune') #I THINK this is only viable option?\n",
        "\n",
        "                 #self.encoder_path = f'/content/drive/My Drive/models/baselineencoder_initial_weights={self.initial_weights}_pretrain={self.pretrain}.pth'\n",
        "                 #self.tuned_model_path = f'/content/drive/My Drive/models/baselinefinetuned_initial_weights={self.initial_weights}_pretrain={self.pretrain}.pth'\n",
        "\n",
        "    @staticmethod\n",
        "    def fit(learn,fit_policy,epochs,initial_weights):\n",
        "\n",
        "\n",
        "        if fit_policy == 'encoder_fine_tune':\n",
        "\n",
        "            #learn.encoder_fine_tune(epochs,freeze_epochs=50)\n",
        "            learn.freeze()\n",
        "            for p in learn.model.encoder.parameters():\n",
        "                print(p.requires_grad)\n",
        "            print('should be true and false')\n",
        "\n",
        "         \n",
        "\n",
        "            learn.fit_one_cycle(2, slice(0.002), pct_start=0.99)\n",
        "            learn.unfreeze()\n",
        "            \n",
        "            for p in learn.model.encoder.parameters():\n",
        "                print(p.requires_grad)\n",
        "            print('should be all True')\n",
        "\n",
        "            learn.fit_one_cycle(2, slice(0.002), pct_start=0.99)\n",
        "            learn.fit_one_cycle(epochs,slice(0.0005,0.0005))\n",
        "\n",
        "\n",
        "        \n",
        "        elif fit_policy == 'fine_tune':\n",
        "            \n",
        "            if initial_weights == 'bt_pretrain':                \n",
        "        \n",
        "\n",
        "                learn.freeze()\n",
        "                learn.fit(10)\n",
        "                learn.unfreeze()\n",
        "                learn.fit(10)\n",
        "                learn.freeze()\n",
        "                learn.fit(10)\n",
        "                learn.unfreeze()\n",
        "                learn.fit(50)\n",
        "\n",
        "\n",
        "            elif initial_weights == 'supervised_pretrain':\n",
        "\n",
        "                #mimic fine_tune, but with a difference...\n",
        "\n",
        "                #learn.fine_tune(epochs)\n",
        "                lr_mult=100\n",
        "                base_lr=2e-3\n",
        "                pct_start=0.3\n",
        "                div=5.0\n",
        "\n",
        "                # def fit_one_cycle(self:Learner, n_epoch, lr_max=None, div=25., div_final=1e5, pct_start=0.25, wd=None,\n",
        "                #   moms=None, cbs=None, reset_opt=False, start_epoch=0)\n",
        "\n",
        "                learn.freeze()\n",
        "\n",
        "                #old\n",
        "                learn.fit_one_cycle(1, slice(base_lr), pct_start=0.99, div=25., div_final=1e5, wd=None,\n",
        "                  moms=None, cbs=None, reset_opt=False, start_epoch=0)\n",
        "\n",
        "                #We put base_lr in first\n",
        "                # learn.fit_one_cycle(1, slice(base_lr,base_lr), pct_start=0.99, div=25., div_final=1e5, wd=None,\n",
        "                #   moms=None, cbs=None, reset_opt=False, start_epoch=0)\n",
        "                \n",
        "                base_lr /= 2\n",
        "\n",
        "                learn.unfreeze()\n",
        "\n",
        "                #Old\n",
        "                # learn.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div, div_final=1e5, wd=None,\n",
        "                #   moms=None, cbs=None, reset_opt=False, start_epoch=0)\n",
        "\n",
        "                learn.fit_one_cycle(epochs, slice(base_lr, base_lr), pct_start=pct_start, div=div, div_final=1e5, wd=None,\n",
        "                  moms=None, cbs=None, reset_opt=False, start_epoch=0)\n",
        "\n",
        "                # learn.freeze()\n",
        "                # learn.fit_one_cycle(2, slice(0.002), pct_start=0.99)\n",
        "                # learn.unfreeze()\n",
        "                # learn.fit_one_cycle(2, slice(0.002), pct_start=0.99)\n",
        "                # learn.fit_one_cycle(epochs,slice(0.001,0.002))\n",
        "\n",
        "        else: raise Exception('Fit policy not of expected form')\n",
        "\n",
        "    def train_encoder(self):\n",
        "        \"create encoder and (optionally, if pretrain=True) train with BT algorith, according to fit_policy\"\n",
        "\n",
        "        try: #get existing encoder and plonk on new projector\n",
        "            encoder = self.encoder\n",
        "\n",
        "            encoder.cpu()\n",
        "            bt_model = create_barlow_twins_model(encoder, hidden_size=self.ps,projection_size=self.ps,nlayers=3)\n",
        "            bt_model.cuda()\n",
        "\n",
        "        except AttributeError: #otherwise, create\n",
        "            bt_model,encoder = create_model(which_model=self.initial_weights,ps=self.ps,device=device)\n",
        "\n",
        "\n",
        "        if self.pretrain: #train encoder according to fit policy\n",
        "\n",
        "            \n",
        "            learn = Learner(self.dls_train,bt_model,splitter=my_splitter_bt,cbs=[BarlowTwins(self.aug_pipelines,n_in=self.n_in,lmb=1/self.ps,print_augs=False)])\n",
        "            main_train.fit(learn,self.fit_policy,epochs=self.num_epochs,initial_weights=self.initial_weights)\n",
        "\n",
        "\n",
        "        #unfreeze_upto_last_block(bt_model.encoder)\n",
        "        #print('unfroze last block...')\n",
        "\n",
        "\n",
        "            #torch.save(encoder.state_dict(), self.encoder_path)\n",
        "\n",
        "        self.encoder = bt_model.encoder\n",
        "\n",
        "\n",
        "    def fine_tune(self):\n",
        "        \"fine tune in supervised fashion, according to tune_fit_policy\"\n",
        "\n",
        "        #encoder = pickle.loads(pickle.dumps(self.encoder)) #We might want to pretrain once and fine tune several times (varying e.g. tune augs)\n",
        "\n",
        "        try: \n",
        "            encoder = self.encoder\n",
        "        \n",
        "        except AttributeError:\n",
        "            _,self.encoder = create_model(which_model=self.initial_weights,ps=self.ps,device=device)\n",
        "\n",
        "\n",
        "        #model = LinearModel(encoder=self.encoder,indim=self.indim,outdim=self.outdim) #create 'linear' model (encoder + linear head)\n",
        "        #model = sequential(self.encoder,nn.Linear(2048,9))\n",
        "        model = LM(self.encoder)\n",
        "\n",
        "        #model = sequential(self.encoder,model)  \n",
        "\n",
        "\n",
        "        learn = Learner(self.dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "        #learn = Learner(self.dls_tune,model,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
        "\n",
        "\n",
        "        main_train.fit(learn,fit_policy=self.tune_fit_policy,epochs=self.numfit,initial_weights=self.initial_weights) #fine tuning (don't confuse this with fit policy!)\n",
        "        #hacky_fine_tune(model,epochs=self.numfit)\n",
        "\n",
        "\n",
        "\n",
        "        scores,preds, acc = predict_model(self.xval,self.yval,model=model,aug_pipelines_test=self.aug_pipelines_test,numavg=3)\n",
        "\n",
        "        #metrics dict will have f1 score, auc etc etc\n",
        "        metrics = classification_report_wrapper(preds, self.yval, self.vocab, print_report=self.print_report)\n",
        "        metrics['acc'] = acc\n",
        "        auc_dict = plot_roc(self.yval,preds,self.vocab,print_plot=self.print_plot)\n",
        "        metrics['auc_dict'] = auc_dict\n",
        "\n",
        "        metrics['scores'] = scores\n",
        "        metrics['preds'] = preds\n",
        "\n",
        "        metrics['xval'] = self.yval\n",
        "        metrics['yval'] = self.yval\n",
        "        \n",
        "        #torch.save(model.state_dict(), self.tuned_model_path)\n",
        "        return metrics #\n",
        "\n",
        "    def __call__(self):\n",
        "\n",
        "        self.train_encoder() #train (or extract) the encoder\n",
        "        metrics = self.fine_tune()\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "if __name__ == '__main__' and on_colab:\n",
        "\n",
        "    initial_weights = 'supervised_pretrain'\n",
        "    pretrain=False\n",
        "    numfit=50\n",
        "    num_epochs=10\n",
        "\n",
        "    num=5\n",
        "    avg_acc=0\n",
        "    d={}\n",
        "    for _ in range(num):\n",
        "\n",
        "        main = main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
        "                aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
        "                initial_weights=initial_weights,pretrain=pretrain,fit_policy='encoder_fine_tune',tune_fit_policy='fine_tune',num_epochs=num_epochs,numfit=numfit,\n",
        "                print_report=True,\n",
        "                ps=8192\n",
        "                        )\n",
        "    \n",
        "        metrics = main()\n",
        "        avg_acc += metrics['acc']\n",
        "        d[_]=metrics['acc']\n",
        "\n",
        "    print(avg_acc/num)\n",
        "    #print('old supervised baseline (with fine tune). Be careful with editing: we need to edit learn as well, i.e. needs splitter')\n",
        "    print('Splitter in the natural order; we just modified fine_tune so that the learning rates are closer to what we have found to empirically work. Please see above.')\n",
        "\n",
        "    # metrics = main.train_encoder()\n",
        "    # metrics = main.fine_tune()\n",
        "    # metrics = main.train_encoder()\n",
        "    # metrics = main.fine_tune()\n",
        "\n",
        "    # torch.cuda.empty_cache()\n",
        "    # gc.collect()\n",
        "\n",
        "    # main.numfit=50\n",
        "    # metrics = main.fine_tune()\n",
        "\n",
        "    #metrics = main.fine_tune()\n",
        "    #metrics = main.fine_tune()\n",
        "\n",
        "    #avg_acc += metrics['acc']\n",
        "\n",
        "    #print(metrics['acc'])\n",
        "\n",
        "    print(avg_acc/num)\n",
        "    # metrics = main()\n",
        "    # metrics=main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#old supervised baseline (with fine tune)\n",
        "#d"
      ],
      "metadata": {
        "id": "geL1pTt-eUIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#old supervised baseline (with fine tune)\n",
        "\n",
        "tem = {0: 0.6724137663841248,\n",
        " 1: 0.7126436829566956,\n",
        " 2: 0.6724137663841248,\n",
        " 3: 0.6321839094161987,\n",
        " 4: 0.6896551847457886}\n",
        " \n",
        "from statistics import mean\n",
        "mean(list(tem.values()))"
      ],
      "metadata": {
        "id": "RpLaYifCfbQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Avg of 3 runs with fine_tune: 0.68; 0.7,0.68,0.69"
      ],
      "metadata": {
        "id": "yQFytJF_GgQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K-AFeBMoChME"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bfac6a54816e44dc81333f94ab6b60b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc748fc8ed21413482b3e87c5e04bd56",
              "IPY_MODEL_97996d9e8850495db6fd9770cc3852a9",
              "IPY_MODEL_3e7568e4d5de4cdab62668cd7c7d075e"
            ],
            "layout": "IPY_MODEL_90bb7c7c9ad84480b5f51479ac97f917"
          }
        },
        "fc748fc8ed21413482b3e87c5e04bd56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d6b454fc1904eff8e610152c743c568",
            "placeholder": "​",
            "style": "IPY_MODEL_64ea968be13248a58ab240b47d7b1b25",
            "value": "100%"
          }
        },
        "97996d9e8850495db6fd9770cc3852a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f5d992b3244e08bf247a5cf02056a5",
            "max": 94355933,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65130a6d8356467ab36c449cc5d5cc7c",
            "value": 94355933
          }
        },
        "3e7568e4d5de4cdab62668cd7c7d075e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5484e81927c34ba48b2328e8e6c1ca56",
            "placeholder": "​",
            "style": "IPY_MODEL_8befcedd0943481783d03a309457d7bc",
            "value": " 90.0M/90.0M [00:02&lt;00:00, 49.7MB/s]"
          }
        },
        "90bb7c7c9ad84480b5f51479ac97f917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6b454fc1904eff8e610152c743c568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ea968be13248a58ab240b47d7b1b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5f5d992b3244e08bf247a5cf02056a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65130a6d8356467ab36c449cc5d5cc7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5484e81927c34ba48b2328e8e6c1ca56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8befcedd0943481783d03a309457d7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8216f4e521b2444a9c5eba3551c40221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_124e0045f1854808a0392fc1206e1655",
              "IPY_MODEL_6dc815cb9d334e53b353307cd94b0780",
              "IPY_MODEL_90842c1f95194713bb9066770881418b"
            ],
            "layout": "IPY_MODEL_09e05d72749b41a783e063839f4abc59"
          }
        },
        "124e0045f1854808a0392fc1206e1655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_649a23d4fb78460fb26fb2b2678101b2",
            "placeholder": "​",
            "style": "IPY_MODEL_4bc8443336d247d4b90c8f9b87e8d50b",
            "value": "100%"
          }
        },
        "6dc815cb9d334e53b353307cd94b0780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5272d0df080241008573929d0c6c940b",
            "max": 102540417,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbb98effaa734eefb5bdfdf6a1366864",
            "value": 102540417
          }
        },
        "90842c1f95194713bb9066770881418b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57c9a292245d42148bd490f300d9b15a",
            "placeholder": "​",
            "style": "IPY_MODEL_ab82bcdc7536451abc1a6a5c9d4c1247",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 84.9MB/s]"
          }
        },
        "09e05d72749b41a783e063839f4abc59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "649a23d4fb78460fb26fb2b2678101b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc8443336d247d4b90c8f9b87e8d50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5272d0df080241008573929d0c6c940b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbb98effaa734eefb5bdfdf6a1366864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57c9a292245d42148bd490f300d9b15a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab82bcdc7536451abc1a6a5c9d4c1247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}