{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yo-BAdXXHNCo"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq self-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9G11-FLRHNCu"
   },
   "outputs": [],
   "source": [
    "#default_exp vision.barlow_twins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvstWtu2HNCv"
   },
   "source": [
    "# Barlow Twins\n",
    "\n",
    "> Barlow Twins: [Barlow Twins: Self-Supervised Learning via Redundancy Reduction](https://arxiv.org/pdf/2103.03230.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamishhaggerty/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "T-Dv0CLtHNC0"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAXzI-h7HNC1"
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaPRyeWjHNC3"
   },
   "source": [
    "#### Barlow Twins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XaSNrOKHNC3"
   },
   "source": [
    "![SimCLR Framework](https://github.com/KeremTurgutlu/self_supervised/blob/master/nbs/images/barlow_twins.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zC_BU-F5HNC4"
   },
   "source": [
    "**Absract**: Self-supervised learning (SSL) is rapidly closing\n",
    "the gap with supervised methods on large computer\n",
    "vision benchmarks. A successful approach\n",
    "to SSL is to learn representations which are invariant\n",
    "to distortions of the input sample. However, a\n",
    "recurring issue with this approach is the existence\n",
    "of trivial constant representations. Most current\n",
    "methods avoid such collapsed solutions by careful\n",
    "implementation details. We propose an objective\n",
    "function that naturally avoids such collapse by\n",
    "measuring the cross-correlation matrix between\n",
    "the outputs of two identical networks fed with distorted\n",
    "versions of a sample, and making it as close\n",
    "to the identity matrix as possible. This causes the\n",
    "representation vectors of distorted versions of a\n",
    "sample to be similar, while minimizing the redundancy\n",
    "between the components of these vectors.\n",
    "The method is called BARLOW TWINS, owing to\n",
    "neuroscientist H. Barlowâ€™s redundancy-reduction\n",
    "principle applied to a pair of identical networks.\n",
    "BARLOW TWINS does not require large batches\n",
    "nor asymmetry between the network twins such\n",
    "as a predictor network, gradient stopping, or a\n",
    "moving average on the weight updates. It allows\n",
    "the use of very high-dimensional output vectors.\n",
    "BARLOW TWINS outperforms previous methods\n",
    "on ImageNet for semi-supervised classification in\n",
    "the low-data regime, and is on par with current\n",
    "state of the art for ImageNet classification with\n",
    "a linear classifier head, and for transfer tasks of\n",
    "classification and object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxOKnel-HNC6"
   },
   "source": [
    "**Own Summary**: Barlow Twins uses 2 augmented views of the same image such as SimCLR but it introduces a new loss function which is inspired by [Information Bottleneck](https://en.wikipedia.org/wiki/Information_bottleneck_method). This loss function doesn't rely on large batch size or negative sample requirement as opposed to InfoNCE loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtGUZBhTHNC8"
   },
   "source": [
    "Like most other self-supervised vision algorithms Barlow Twins model consists of an `encoder` and a `projector (MLP)` layer. The definition of this module is fairly simple as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oC9_TO-_HNC9"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"An encoder followed by a projector\"\n",
    "    def __init__(self,encoder,projector): self.encoder,self.projector = encoder,projector\n",
    "    def forward(self,x): return self.projector(self.encoder(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWXAH9b7HNC_"
   },
   "source": [
    "Instead of directly using `BarlowTwinsModel` by passing both an `encoder` and a `projector`, `create_barlow_twins_model` function can be used by minimally passing a predefined `encoder` and the expected input channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWphRZloHNDA"
   },
   "source": [
    "In the paper it's mentioned that MLP layer consists of 3 layers with first 2 layers having batchnorm followed by ReLU. The following function will create a 3 layer MLP projector with batchnorm and ReLU by default. Alternatively, you can change `bn` and `nlayers`. It is also noted in the paper that using larger hidden and projection size increases the downstream task performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wad0jYq1HNDA"
   },
   "source": [
    "**Quote from the paper**: Architecture The encoder consists of a ResNet-50 network\n",
    "(He et al., 2016) (without the final classification layer)\n",
    "followed by a projector network. The projector network\n",
    "has three linear layers, each with 8192 output units. The\n",
    "first two layers of the projector are followed by a batch\n",
    "normalization layer and rectified linear units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RDMsWT3tHNDB"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    return BarlowTwinsModel(encoder, projector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQZ54QUBHNDC"
   },
   "source": [
    "You can use `self_supervised.layers` module to create an encoder. It supports all **timm** and **fastai** models available out of the box.\n",
    "\n",
    "We define number of input channels with `n_in`, projector/mlp's hidden size with `hidden_size`,  projector/mlp's final projection size with `projection_size` and projector/mlp's number of layers with `nlayers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eRkG-BlPHNDC",
    "outputId": "0ad4a09a-f314-4936-d143-3bcef5c4153d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = create_encoder(\"tf_efficientnet_b0_ns\", n_in=3, pretrained=False, pool_type=PoolingType.CatAvgMax)\n",
    "model = create_barlow_twins_model(encoder, hidden_size=2048, projection_size=128, nlayers=2)\n",
    "out = model(torch.randn((2,3,224,224))); out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tb0OKL5mHNDD"
   },
   "source": [
    "## BarlowTwins Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYAP6cqLHNDE"
   },
   "source": [
    "The following parameters can be passed;\n",
    "\n",
    "- **aug_pipelines** list of augmentation pipelines List[Pipeline] created using functions from `self_supervised.augmentations` module. Each `Pipeline` should be set to `split_idx=0`. You can simply use `get_simclr_aug_pipelines` utility to get aug_pipelines.\n",
    "- **lmb** $\\lambda$ is the weight for redundancy reduction term in the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiQYtQzQHNDE"
   },
   "source": [
    "<center><img src='https://github.com/KeremTurgutlu/self_supervised/blob/master/nbs/images/barlow_twins_loss.png?raw=1'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgKDWp82HNDF"
   },
   "source": [
    "BarlowTwins algorithm uses 2 views of a given image, and `BarlowTwins` callback expects a list of 2 augmentation pipelines in `aug_pipelines`.\n",
    "\n",
    "You can simply use helper function `get_barlow_twins_aug_pipelines()` which will allow augmentation related arguments such as size, rotate, jitter...and will return a list of 2 pipelines, which we can be passed to the callback. This function uses `get_multi_aug_pipelines` which then `get_batch_augs`. For more information you may refer to `self_supervised.augmentations` module.\n",
    "\n",
    "Also, you may choose to pass your own list of aug_pipelines which needs to be List[Pipeline, Pipeline] where Pipeline(..., split_idx=0). Here, `split_idx=0` forces augmentations to be applied in training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J_UcuQl9HNDG"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size, **kwargs): return get_multi_aug_pipelines(n=2, size=size, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "y-SeLea4HNDG",
    "outputId": "c8c079c5-8eb6-410c-841c-9d5cad37660a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline: RandomResizedCrop -> RandomHorizontalFlip,\n",
       " Pipeline: RandomResizedCrop -> RandomHorizontalFlip]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=False, jitter=False, bw=False, blur=False, stats=None, cuda=False)\n",
    "aug_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uq_wOgweHNDH"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines, lmb=5e-3, print_augs=False):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        \n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "                    \n",
    "            \n",
    "    def before_batch(self):\n",
    "        xi,xj = self.aug1(self.x), self.aug2(self.x)\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "        \n",
    "    \n",
    "    def lf(self, pred, *yb):\n",
    "        bs,nf = pred.size(0)//2,pred.size(1)\n",
    "        z1, z2 = pred[:bs],pred[bs:]\n",
    "        \n",
    "        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "        \n",
    "        C = (z1norm.T @ z2norm) / bs \n",
    "        cdiff = (C - self.I)**2\n",
    "        loss = (cdiff*self.I + cdiff*(1-self.I)*self.lmb).sum() \n",
    "        return loss\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1):\n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:] \n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]] \n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUV08KefHNDI"
   },
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "B1krKC58HNDI",
    "outputId": "d2260761-46bf-48df-c3b1-17dd0c102fdb"
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)\n",
    "tds = Datasets(items, [PILImageBW.create, [parent_label, Categorize()]], splits=GrandparentSplitter()(items))\n",
    "dls = tds.dataloaders(bs=5, after_item=[ToTensor(), IntToFloatTensor()], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5AaPoAHUHNDI",
    "outputId": "347e72eb-451c-44ba-e638-affc62fe9bee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip\n",
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip\n"
     ]
    }
   ],
   "source": [
    "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
    "model = create_barlow_twins_model(fastai_encoder, hidden_size=1024, projection_size=1024)\n",
    "aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=False, jitter=False, bw=False, blur=False, stats=None, cuda=False)\n",
    "learn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True),ShortEpochCallback(0.001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNvVeSMbHNDJ"
   },
   "source": [
    "Also, with `show_one()` method you can inspect data augmentations as a sanity check. You can use existing augmentation functions from `augmentations` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VFH-GN08HNDJ",
    "outputId": "01b0862d-c330-4274-a447-79fe26f9ebae"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x1080 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "learn._split(b)\n",
    "learn('before_batch')\n",
    "axes = learn.barlow_twins.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AFF2EPm9HNDK",
    "outputId": "1cd1927b-1c16-4a24-da58-78b22304c31c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='1' class='' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.71% [1/141 00:01<03:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:222\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:164\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:213\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:164\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:207\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:164\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:170\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:195\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    193\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:164\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/learner.py:181\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb): \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_backward\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_events(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mstep, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m, CancelStepException)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/_tensor.py:355\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/overrides.py:1394\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1388\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1389\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in PyTorch 1.11, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1390\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1394\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/torch_core.py:341\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): convert,types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m),(torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 341\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert: res \u001b[38;5;241m=\u001b[39m convert(res)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, TensorBase): res\u001b[38;5;241m.\u001b[39mset_meta(\u001b[38;5;28mself\u001b[39m, as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/_tensor.py:1142\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1142\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8Xigc5LHNDK",
    "outputId": "6a149f59-50b6-4f0a-f95c-c1a889c9af52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(2616.7854)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.recorder.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uM3dOEEHHNDL"
   },
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X37VlUbZHNDL",
    "outputId": "0b76f8c7-a61a-4886-cf75-cde98eea72b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01 - augmentations.ipynb.\n",
      "Converted 02 - layers.ipynb.\n",
      "Converted 03 - distributed.ipynb.\n",
      "Converted 10 - simclr.ipynb.\n",
      "Converted 11 - moco.ipynb.\n",
      "Converted 12 - byol.ipynb.\n",
      "Converted 13 - swav.ipynb.\n",
      "Converted 20 - clip.ipynb.\n",
      "Converted 21 - clip-moco.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Go3YW0EBHNDL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsOH7whYHNDL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "14 - barlow_twins.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
