{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8jFsEXz_61O",
    "outputId": "7a884ca7-e8fc-422c-d878-0c87e7a13488"
   },
   "outputs": [],
   "source": [
    "!pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0\n",
    "!pip install fastai==2.6.3 --no-deps\n",
    "!pip install self_supervised\n",
    "\n",
    "!pip install pytest\n",
    "!pip install ipytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Pk01WY_Dag8s"
   },
   "outputs": [],
   "source": [
    "import fastai\n",
    "import self_supervised\n",
    "import torch\n",
    "if torch.cuda.is_available():device='cuda'\n",
    "else:device='cpu'\n",
    "assert(fastai.__version__ == '2.6.3') #Check that version is 2.6.3\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import inspect\n",
    "import warnings\n",
    "import random\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AOjr_YCLag8t"
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import inspect\n",
    "import warnings\n",
    "import random\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import ipytest\n",
    "ipytest.autoconfig()\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger('PIL').setLevel(logging.WARNING)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "XTSdKC6bag8t"
   },
   "outputs": [],
   "source": [
    "#Like most other SSL algorithms BT's model consists of an encoder and projector (MLP) layer.\n",
    "#Definition is straightforward:\n",
    "#https://colab.research.google.com/github/KeremTurgutlu/self_supervised/blob/master/nbs/14%20-%20barlow_twins.ipynb#scrollTo=1M6QcUChcvpz\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):self.encoder,self.projector = encoder,projector\n",
    "        \n",
    "    def forward(self,x): return self.projector(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ZL3EE07Pag8u"
   },
   "outputs": [],
   "source": [
    "#HOWEVER instead of directly using the above, by passing both an encoder and a projector, create_barlow_twins_model\n",
    "#function can be used by minimally passing a predefined encoder and the expected input channels.\n",
    "\n",
    "#In the paper it's mentioned that MLP layer consists of 3 layers... following function will create a 3 layer\n",
    "#MLP projector with batchnorm and ReLU by default. Alternatively, you can change bn and nlayers. \n",
    "\n",
    "#Questions: Why torch.no_grad() when doing this?\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "#Similar to above. Simple API to make the BT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "DFjGL-COag8v"
   },
   "outputs": [],
   "source": [
    "#BarlowTwins Callback\n",
    "#The following parameters can be passed:\n",
    "# - aug_pipelines\n",
    "# Imb lambda is the weight for redundancy reduction term in the loss function\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(n=2,size=size,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "xx4KsywAag8v"
   },
   "outputs": [],
   "source": [
    "#Uniform random number between a and b\n",
    "def Unif(a,b):\n",
    "    return (b-a)*torch.rand(1).item()+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "l6gBw66Iag8y"
   },
   "outputs": [],
   "source": [
    "def random_sinusoid(x,std=0.15):\n",
    "    \n",
    "    t=torch.normal(mean=0,std=std,size=(1,1)).item()\n",
    "    s=torch.normal(mean=0,std=std,size=(1,1)).item()\n",
    "    \n",
    "    u=torch.normal(mean=0,std=1,size=(1,1)).item()\n",
    "    v=torch.normal(mean=0,std=1,size=(1,1)).item()\n",
    "    \n",
    "    a=torch.normal(mean=0,std=1,size=(1,1)).item()\n",
    "    b=torch.normal(mean=0,std=1,size=(1,1)).item()\n",
    "    \n",
    "    return torch.sin(t*math.pi*x+u) + torch.cos(s*math.pi*x + v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sinusoid_new(x,std=0.1,seed=0):\n",
    "\n",
    "    seed_everything(seed=seed)\n",
    "    \n",
    "    t=(std) * torch.randn(1,500).to(device)\n",
    "    #s=(std) * torch.randn(1,500).to(device)\n",
    "    \n",
    "    #u=torch.randn(1,500).to(device)\n",
    "    #v=torch.randn(1,500).to(device)\n",
    "\n",
    "    return torch.sin(t*x[:,]*math.pi)# + u) + torch.cos(s*x[:,]*math.pi + v)\n",
    "\n",
    "    #return torch.sin(t*math.pi*x+u) + torch.cos(s*math.pi*x + v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "li3BQ1ukX0XB"
   },
   "outputs": [],
   "source": [
    "def Exp_sample(scale=3.,loc=1.8):\n",
    "    \n",
    "    Expo = torch.distributions.exponential.Exponential\n",
    "    E = Expo(torch.tensor([scale]))\n",
    "#     if random.random()<0.5:\n",
    "#         return 1\n",
    "#     else:\n",
    "    return loc+E.sample().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MDYVO2u1U4We"
   },
   "outputs": [],
   "source": [
    "def p_norm(x,p):\n",
    "\n",
    "    eps=1e-8\n",
    "    if p<1:\n",
    "        x=x+eps\n",
    "    return (1/p)*torch.abs(x).pow(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max_Corr(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.fc1 = nn.Linear(500,1)\n",
    "        #self.fc2 = nn.Linear(500,1)\n",
    "        self.t = nn.Parameter(0.1*torch.randn(1,500),requires_grad=True)\n",
    "        self.s = nn.Parameter(0.1*torch.randn(1,500),requires_grad=True)\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        \n",
    "        return (torch.sin(self.t*x[:,]*math.pi),torch.sin(self.s*y[:,]*math.pi))\n",
    "        \n",
    "        \n",
    "        #return (torch.sin(cast(self.fc1(x[:,])*math.pi,Tensor)),torch.sin(cast(self.fc2(y[:,])*math.pi,Tensor)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "a2Exs2s3ag8z"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines, lmb=5e-3, print_augs=False):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "\n",
    "    def update_seed(self):\n",
    "\n",
    "        #if self.index%8 == 0: #every `indexmod` index update the seed (best we have found so far)\n",
    "\n",
    "        self.seed = np.random.randint(0,10000)\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self.index=-1\n",
    "            \n",
    "    def before_batch(self):\n",
    "        xi,xj = self.aug1(self.x), self.aug2(self.x)\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "\n",
    "        self.index=self.index+1\n",
    "\n",
    "        self.update_seed()\n",
    "\n",
    "        \n",
    "        #Uncomment to run standard BT\n",
    "    # def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n",
    "    #     bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #     z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    #     z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    #     z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "        \n",
    "    #     C = (z1norm.T @ z2norm) / bs \n",
    "    #     cdiff = (C - self.I)**2\n",
    "    #     loss = (cdiff*self.I + cdiff*(1-self.I)*self.lmb).sum() \n",
    "    #     return loss\n",
    "\n",
    "\n",
    "    def lf(self, pred, *yb): #pred is (bs+bs)*projection_size\n",
    "        bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "        #All standard, from BT\n",
    "        z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "        \n",
    "        max_corr=inner_step(z1norm,z2norm,I=self.I)\n",
    "        z1norm_2,z2norm_2 = max_corr(z1norm,z2norm)\n",
    "        \n",
    "        Ctem = (z1norm_2.T @ z2norm_2) / bs\n",
    "        cdiff_2 = Ctem.pow(2)\n",
    "\n",
    "        \n",
    "        C = (z1norm.T @ z2norm) / bs \n",
    "        cdiff = (C - self.I)**2\n",
    "\n",
    "\n",
    "\n",
    "        #{'Pr': 0.45546983480453496, 'dist': 'Exp', 'loc': 0.49445648193359376, 'scale': 2.5828861594200134, 'percent_correct': 0.8277832269668579} #Best so far\n",
    "\n",
    "        #self.update_seed()\n",
    "\n",
    "        #input('hi')\n",
    "\n",
    "        #polyprob=0.1\n",
    "        #polyprob=0.45546\n",
    "        #polyprob=1.0\n",
    "#         polyprob=0.0\n",
    "#         temrand = random.random()\n",
    "#         if temrand < polyprob: #With some probability we want off diag terms to be (quadratic) say.\n",
    "\n",
    "#             K=10\n",
    "#             cdiff_2=0\n",
    "#             for i in range(K):\n",
    "#             #p=Exp_sample(loc=1.5,scale=2.0)\n",
    "#             # #p=Unif(1.0,2.5)\n",
    "#                 z1norm_2 = random_sinusoid_new(z1norm,std=0.1,seed=self.seed+i)\n",
    "#                 z2norm_2 = random_sinusoid_new(z2norm,std=0.1,seed=2*self.seed+i)\n",
    "#                 C_2 = (z1norm_2.T @ z2norm_2) / bs\n",
    "#                 #cdiff_2 = (C_2)**2 #don't need to subtract I as only looking at off diag terms\n",
    "#                 cdiff_2 = cdiff_2 + (C_2)**2\n",
    "            \n",
    "#             cdiff_2=(1/K)*cdiff_2\n",
    "\n",
    "#             #symmetrize loss - so copy paste above block but swap place of 1 and 2\n",
    "#             #p=Exp_sample(loc=1.5,scale=2.0)\n",
    "#             #p=Unif(1.0,2.5)\n",
    "            \n",
    "#             # cdiff_2_sym=0\n",
    "#             # for i in range(K):\n",
    "#             #     z1norm_2 = random_sinusoid_new(z1norm,std=0.1,seed=4*self.seed+i)\n",
    "#             #     z2norm_2 = random_sinusoid_new(z2norm,std=0.1,seed=8*self.seed+i)\n",
    "\n",
    "#             #     C_2_sym = (z1norm_2.T @ z2norm_2) / bs\n",
    "#             #     cdiff_2_sym = cdiff_2_sym + C_2_sym**2\n",
    "            \n",
    "#             # cdiff_2_sym=(1/K)*cdiff_2_sym\n",
    "\n",
    "#             cdiff_2 = cdiff_2 #+ 0.5*cdiff_2_sym #Symmetrized random loss\n",
    "\n",
    "#             cdiff_2 = 0.2*cdiff +  0.8*cdiff_2 #convex comb of BT loss with random loss -> assumes polyprob=1.0\n",
    "            \n",
    "#         else:\n",
    "#             cdiff_2 = cdiff\n",
    "            \n",
    "            \n",
    "            \n",
    "        l2 = cdiff_2*(1-self.I)*self.lmb #Is either the standard term - or not.\n",
    "\n",
    "        loss = (cdiff*self.I + l2).sum() \n",
    "        return loss\n",
    "\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1):\n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:] \n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]] \n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vbS1WtLiag80",
    "outputId": "9ea77dd3-d3df-4261-c22e-dcd436cd9e78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n",
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>93.401398</td>\n",
       "      <td>None</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>42.383896</td>\n",
       "      <td>None</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>25.414484</td>\n",
       "      <td>None</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16.841518</td>\n",
       "      <td>None</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12.166798</td>\n",
       "      <td>None</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>9.206956</td>\n",
       "      <td>None</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.179511</td>\n",
       "      <td>None</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.711948</td>\n",
       "      <td>None</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.671018</td>\n",
       "      <td>None</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.147277</td>\n",
       "      <td>None</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Debugging cell - delete later (similar to cell below)\n",
    "ps=500\n",
    "hs=500\n",
    "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
    "model = create_barlow_twins_model(fastai_encoder, hidden_size=hs,projection_size=ps)# projection_size=1024)\n",
    "aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=(device=='cuda'))\n",
    "learn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
    "learn.fit(10) #300                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Y5FN3Safag80"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"\"\n",
    "    Seed everything.\n",
    "    \"\"\"   \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def tune_set(items0,bs_tune=20):\n",
    "    items0=items0.shuffle()\n",
    "    d = {'0':0,'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0,'8':0,'9':0}\n",
    "    ITEMS=[]\n",
    "    for i in items0:\n",
    "        s=str(i).split('/training/')[1][0]\n",
    "        if d[s] is 0 or d[s] is 1:\n",
    "            ITEMS.append(i)\n",
    "            d[s]+=1\n",
    "    #items0=ITEMS\n",
    "\n",
    "    for i in items0:\n",
    "        if i not in ITEMS:\n",
    "            ITEMS.append(i)\n",
    "            \n",
    "    split = IndexSplitter(list(range(bs_tune)))\n",
    "\n",
    "    tds_tune = Datasets(ITEMS, [PILImageBW.create, [parent_label, Categorize()]], splits=split(ITEMS)) #Or do we want this?\n",
    "    dls_tune = tds_tune.dataloaders(bs=bs_tune,num_workers=0, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n",
    "    \n",
    "    return dls_tune\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xv4RE3O0ag81",
    "outputId": "c37cb7e8-0b16-4a16-c8f7-5756906fb01a"
   },
   "outputs": [],
   "source": [
    "#TODO: Do this in a slicker way. Write more tests \n",
    "#Get the dataloader and set batch size \n",
    "ts=16384 #training set size\n",
    "bs=512 #training batch size\n",
    "\n",
    "tune_s=2000 #we choose (say) 20 guys (randomly) out of theses 2000 to tune on\n",
    "bs_tune=20 #With MNIST this is also the size of the tune set\n",
    "\n",
    "bs_test=578 #Batch size for test set\n",
    "\n",
    "#Get the data\n",
    "path = untar_data(URLs.MNIST)\n",
    "items = get_image_files(path/'training') #i.e. NOT testing!!!\n",
    "items.sort() \n",
    "\n",
    "#Set random seed when defining/extracting training set, tuning set testing set for reproducibility\n",
    "seed=42\n",
    "seed_everything(seed=seed)\n",
    "items=items.shuffle()\n",
    "\n",
    "#Training set (for BT)\n",
    "items1 = items[0:ts] #train BT on these guys\n",
    "split = RandomSplitter(valid_pct=0.0)\n",
    "#tds = Datasets(items,splits=split(items)) #Do we want this?\n",
    "tds = Datasets(items1, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items1)) #Or do we want this?\n",
    "dls = tds.dataloaders(bs=bs,num_workers=0, after_item=[ToTensor(), IntToFloatTensor()], device=device)\n",
    "\n",
    "#We use items0 to extract tuning set, via the function `tune_set` above\n",
    "items0 = items[ts:ts+tune_s] #for fine tuning - just choose 2000 guys to extract 20 for fine tuning \n",
    "\n",
    "#Evaluate linear classifier on this guy\n",
    "test_bs=578\n",
    "items2 = items[ts+tune_s:] #test on the remaining set\n",
    "split = RandomSplitter(valid_pct=0.0) #randomly split training set into training and validation\n",
    "tds_test = Datasets(items2, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items2)) #Or do we want this?\n",
    "dls_test = tds_test.dataloaders(bs=bs_test,num_workers=0, after_item=[ToTensor(), IntToFloatTensor()], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                         [100%]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -qq\n",
    "#Test dataloaders\n",
    "\n",
    "labeller = using_attr(RegexLabeller(pat = r'(\\d+).png$'), 'name')\n",
    "\n",
    "def verify_DatasetShape(dls_obj,batch_size,ds_settype='train'):\n",
    "    \"\"\"\"Helper function to verify shape of a dls object given the batch size; ds_settype is either `train` or \n",
    "        `valid`. The idea is we want the batch_size to divide the length of the dlsobj.\n",
    "    \"\"\"\n",
    "    \n",
    "    tem = len(getattr(dls_obj,ds_settype)) #length of dlsobj.train or dlsobj.valid depending on settpe\n",
    "    return tem*batch_size == len(getattr(dls_obj,ds_settype+'_ds'))\n",
    "\n",
    "def verify_first_item(items,expected):\n",
    "    \"\"\"Helper function to verify first element of items is as expected, given random seed of 42\n",
    "    \"\"\"\n",
    "    if seed==42:\n",
    "        return labeller(items[0]) == expected\n",
    "    else:\n",
    "        logging.debug('The seed is not 42 - is this ok?')\n",
    "        return False\n",
    "\n",
    "dls_tune=tune_set(items0,bs_tune=bs_tune) #used for generic tests below\n",
    "\n",
    "def test_first_item():\n",
    "    \"\"\"\"Verify that the first item of each dls_obj is as expected\n",
    "    \"\"\"\n",
    "    \n",
    "    assert verify_first_item(items1,'19825')\n",
    "    \n",
    "    assert verify_first_item(items0,'40684')\n",
    "    \n",
    "    assert verify_first_item(items2,'43064')\n",
    "    \n",
    "def test_shape_dlsobjects():\n",
    "    \"\"\"\"Test the shape of each dlsobj\n",
    "    \"\"\"\n",
    "    \n",
    "    assert verify_DatasetShape(dls,batch_size=bs,ds_settype='train')\n",
    "    \n",
    "    assert verify_DatasetShape(dls_tune,batch_size=bs_tune,ds_settype='valid')\n",
    "    \n",
    "    assert verify_DatasetShape(dls_test,batch_size=bs_test,ds_settype='train')\n",
    "    \n",
    "def test_length_dlsobjects():\n",
    "    \"\"\"\"Test the length of each dlsobj that we use\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(dls.train_ds) == ts and len(dls_tune.valid_ds) == bs_tune and len(dls_test.train_ds)==41616\n",
    "    \n",
    "def test1_tune_set():\n",
    "    \"\"\"Check whether the function `tune_set` gives us the expected values\"\"\"\n",
    "    \n",
    "    tune_seed=10\n",
    "    expected = {10:0.12255,11:0.153564,12:0.12781,13:0.129523,14:0.13019}\n",
    "    for i in range(5):\n",
    "        seed=tune_seed+i\n",
    "        seed_everything(seed=seed)\n",
    "        dls_tune=tune_set(items0,bs_tune=20)\n",
    "        x_mean=0\n",
    "        for x,y in dls_tune.valid:\n",
    "            x_mean += x.mean()\n",
    "\n",
    "        assert abs(x_mean-expected[seed])<0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "AKbw2pxMag82",
    "outputId": "07e65765-a9ae-42b5-9e8a-c05f4dab18b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n",
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianBlur -- {'p': 0.5, 's': 8, 'same_on_batch': False} -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#A \"reasonable\" composite augmentation: initially copy pasted BT. We run this cell a few times to check it makes sense\n",
    "#Also define encoder and model\n",
    "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
    "model = create_barlow_twins_model(fastai_encoder, hidden_size=10,projection_size=10)# projection_size=1024)\n",
    "#So aside from size, randomresizedcrop takes in two args: resize_scale and resize_ratio. So we want to put in \n",
    "#values for these which is tantamount to doing nothing\n",
    "#So if we choose resize_scale=(1,1) then the images look the same.\n",
    "#IMPORTANT: So this aug pipelines, insofar as I can tell at the moment, is tantamount to \"do nothing\"\n",
    "aug_pipelines = get_barlow_twins_aug_pipelines(size=28, rotate=True,flip_p=0,resize_scale=(0.7,1), jitter=False, bw=False,blur=True,blur_p=0.5,blur_s=8, stats=None, cuda=False)\n",
    "#learn = Learner(dls, model,ShortEpochCallback(0.001), cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
    "learn = Learner(dls, model, cbs=[BarlowTwins(aug_pipelines, print_augs=True)])\n",
    "\n",
    "#dls.valid.bs = len(dls.valid_ds) #Set the validation dataloader batch size to be the length of the validation dataset\n",
    "\n",
    "b = dls.one_batch()\n",
    "learn._split(b)\n",
    "learn('before_batch')\n",
    "axes = learn.barlow_twins.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Kujpa-Lvag82"
   },
   "outputs": [],
   "source": [
    "#Simple linear classifier\n",
    "class LinearClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,zdim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(zdim,10) #As 10 classes for mnist\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = cast(self.fc1(x),Tensor) #so we have to use cross entropy loss. cast is because using old version fastai \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turnoffgrad_model(fastai_encoder):\n",
    "    for p in fastai_encoder.parameters():\n",
    "        p.requires_grad=False\n",
    "        \n",
    "    return fastai_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "QJTzqSefag83"
   },
   "outputs": [],
   "source": [
    "#NB: Will give same random 20-tune set (for fixed random seed), only if the cell\n",
    "#\"#Get the dataloader and set batch size\" is the same. Perhaps later we can make this cell a function of that one. \n",
    "#Functions to train and evaluate head\n",
    "fastai_encoder.eval()\n",
    "encoder_nograd = turnoffgrad_model(fastai_encoder) \n",
    "def train_head(encoder_nograd,tune_seed=10,bs_tune=20): #The seed choses a different (20) samples for training the head. 2 of each class\n",
    "    \"\"\"Train head on a tune_set, chosen through given tune_seed for reproducibility if needed\n",
    "    \"\"\"\n",
    "    seed_everything(seed=tune_seed) #Set the random seed, so that we choose a `fixed` tune set (i.e. as a function\n",
    "                                    # of the tune_seed)\n",
    "    \n",
    "    dls_tune=tune_set(items0,bs_tune=bs_tune) #different random tune set each time (but as a function of tune_seed)\n",
    " \n",
    "    N=len(dls_tune.valid)*bs_tune \n",
    "    assert N == len(dls_tune.valid_ds) #Check that the tune set (valid) is divided by the batch size\n",
    "    assert len(dls_tune.valid_ds) == bs_tune\n",
    "\n",
    "    zdim=1024 #see above\n",
    "    head = LinearClassifier(zdim=zdim)\n",
    "    head.to(device)\n",
    "    optimizer = torch.optim.Adam(head.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(200):\n",
    "        #for x,y in dls_tune.valid: #Slows massively on colab but not on kaggle. Weird. \n",
    "        x,y=dls_tune.valid.one_batch() #Same every time since dataset only has length=batch size = 20.\n",
    "                                        #Will need to fix this for CIFAR10 etc\n",
    "\n",
    "        loss = criterion(head(encoder_nograd(x)),y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return head\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_head(head):\n",
    "    \"\"\"Evaluate the (typically trained) head on on the test set\n",
    "    \"\"\"\n",
    "    N=len(dls_test.train)*bs_test \n",
    "    assert N == len(dls_test.train_ds)\n",
    "\n",
    "    num_correct=0\n",
    "    for x,y in dls_test.train:\n",
    "    #for i in range(3):\n",
    "\n",
    "        ypred = head(encoder_nograd(x))\n",
    "        correct = (torch.argmax(ypred,dim=1) == y).type(torch.FloatTensor)\n",
    "        num_correct += correct.sum()\n",
    "    \n",
    "    return num_correct/N\n",
    "\n",
    "def eval_encoder(encoder_nograd,tune_seed=10):\n",
    "    \"\"\"\"Evaluate the encoder, which means to train and evaluate the head - basically wrap functions train_head\n",
    "        and eval_head\n",
    "    \"\"\"\n",
    "    head=train_head(encoder_nograd,tune_seed=tune_seed)\n",
    "    pct_correct = eval_head(head)\n",
    "    return pct_correct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VULhbDWawO_J",
    "outputId": "130dedb3-22ab-4efa-a972-5f889a8501be"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [225]\u001b[0m, in \u001b[0;36meval_encoder\u001b[0;34m(encoder_nograd, tune_seed)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m\"\"\"\"Evaluate the encoder, which means to train and evaluate the head - basically wrap functions train_head\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    and eval_head\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m head\u001b[38;5;241m=\u001b[39mtrain_head(encoder_nograd,tune_seed\u001b[38;5;241m=\u001b[39mtune_seed)\n\u001b[0;32m---> 58\u001b[0m pct_correct \u001b[38;5;241m=\u001b[39m \u001b[43meval_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pct_correct\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [225]\u001b[0m, in \u001b[0;36meval_head\u001b[0;34m(head)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m N \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(dls_test\u001b[38;5;241m.\u001b[39mtrain_ds)\n\u001b[1;32m     43\u001b[0m num_correct\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m dls_test\u001b[38;5;241m.\u001b[39mtrain:\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#for i in range(3):\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     ypred \u001b[38;5;241m=\u001b[39m head(encoder_nograd(x))\n\u001b[1;32m     48\u001b[0m     correct \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39margmax(ypred,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/data/load.py:125\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_iter()\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idxs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_idxs() \u001b[38;5;66;03m# called in context of main process (not workers/subprocesses)\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m _loaders[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfake_l\u001b[38;5;241m.\u001b[39mnum_workers\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfake_l):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# pin_memory causes tuples to be converted to lists, so convert them back to tuples\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpin_memory \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(b) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m: b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(b)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: b \u001b[38;5;241m=\u001b[39m to_device(b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:39\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/data/load.py:136\u001b[0m, in \u001b[0;36mDataLoader.create_batches\u001b[0;34m(self, samps)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m    135\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m o:o \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_item, samps))\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunkify(res))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/basics.py:219\u001b[0m, in \u001b[0;36mchunked\u001b[0;34m(it, chunk_sz, drop_last, n_chunks)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(it, Iterator): it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(it)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_sz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(res)\u001b[38;5;241m==\u001b[39mchunk_sz \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m drop_last): \u001b[38;5;28;01myield\u001b[39;00m res\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res)\u001b[38;5;241m<\u001b[39mchunk_sz: \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastai/data/load.py:151\u001b[0m, in \u001b[0;36mDataLoader.do_item\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m SkipItemException: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/transform.py:200\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, o)\u001b[0m\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, o): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompose_tfms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/transform.py:150\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tfms:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_enc: f \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdecode\n\u001b[0;32m--> 150\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/transform.py:73\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencodes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/transform.py:83\u001b[0m, in \u001b[0;36mTransform._call\u001b[0;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, x, split_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split_idx\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/transform.py:90\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[0;32m---> 90\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/transform.py:90\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     88\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[0;32m---> 90\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/transform.py:88\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_tuple(x):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 88\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[1;32m     90\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/dispatch.py:107\u001b[0m, in \u001b[0;36mTypeDispatch.returns\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreturns\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet the return type of annotation of `x`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m anno_ret(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/dispatch.py:133\u001b[0m, in \u001b[0;36mTypeDispatch.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFind first matching type that is a super-class of `k`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m k \u001b[38;5;241m=\u001b[39m L(k)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m2\u001b[39m: k\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m    134\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuncs\u001b[38;5;241m.\u001b[39mall_matches(k[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m r:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/old_fastai/lib/python3.10/site-packages/fastcore/foundation.py:86\u001b[0m, in \u001b[0;36mCollBase.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tune_seed=10\n",
    "performance_dict={}\n",
    "for num in range(1):\n",
    "    \n",
    "    pct_correct = eval_encoder(encoder_nograd,tune_seed=tune_seed+num)\n",
    "    performance_dict[f'seed_{num}'] = pct_correct \n",
    "\n",
    "print(torch.mean(tensor(list(performance_dict.values()))))\n",
    "performance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
